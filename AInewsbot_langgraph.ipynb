{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c703a9",
   "metadata": {},
   "source": [
    "### Newsbot to write a daily AI news summary using langgraph\n",
    "- Save a list of HTML files from sources.yaml (tech news sites)\n",
    "- Extract URLs for the news stories\n",
    "- Filter URLs to remove duplicates, articles seen before, and non-AI articles (using a ChatGPT prompt)\n",
    "- Perform headline topic analysis and sort by topic to help the AI structure the response by topic\n",
    "- Scrape and summarize individual articles\n",
    "- Compose and email the summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74032f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to selectively re-import as needed\n",
    "import sys\n",
    "del sys.modules['ainb_llm']\n",
    "del sys.modules['ainb_const']\n",
    "# del sys.modules['ainb_utilities']\n",
    "# del sys.modules['ainb_webscrape']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562be45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import yaml\n",
    "import sqlite3\n",
    "import json\n",
    "from collections import Counter\n",
    "import uuid\n",
    "from typing import TypedDict, Annotated\n",
    "\n",
    "import operator\n",
    "import pickle\n",
    "\n",
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import (ChatPromptTemplate, MessagesPlaceholder, PromptTemplate,\n",
    "                                    SystemMessagePromptTemplate, HumanMessagePromptTemplate)\n",
    "# from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "# from langchain.memory import ChatMessageHistory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "# from langchain.tools import BaseTool, StructuredTool, tool\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import SimpleJsonOutputParser, JsonOutputParser, StrOutputParser\n",
    "# from langchain.callbacks.base import AsyncCallbackHandler, BaseCallbackHandler\n",
    "# from langchain_core.outputs import LLMResult\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import bs4\n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "import multiprocessing\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "from IPython.display import HTML, Image, Markdown, display\n",
    "import markdown\n",
    "\n",
    "# import smtplib\n",
    "# from email.mime.multipart import MIMEMultipart\n",
    "# from email.mime.text import MIMEText\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import trafilatura\n",
    "\n",
    "VERBOSE=1\n",
    "from ainb_const import (DOWNLOAD_DIR, PAGES_DIR,\n",
    "                        MODEL, LOWCOST_MODEL, HIGHCOST_MODEL, CANONICAL_TOPICS,\n",
    "                        SOURCECONFIG, FILTER_PROMPT, TOPIC_PROMPT,\n",
    "                        SUMMARIZE_SYSTEM_PROMPT, SUMMARIZE_USER_PROMPT, FINAL_SUMMARY_PROMPT, TOP_CATEGORIES_PROMPT,\n",
    "                        MAX_INPUT_TOKENS, MAX_OUTPUT_TOKENS, MAX_RETRIES, TEMPERATURE, SQLITE_DB,\n",
    "                        HOSTNAME_SKIPLIST, SITE_NAME_SKIPLIST,\n",
    "                       )\n",
    "from ainb_utilities import (log, delete_files, filter_unseen_urls_db, insert_article,\n",
    "                            nearest_neighbor_sort, agglomerative_cluster_sort, traveling_salesman_sort_scipy,\n",
    "                            unicode_to_ascii, send_gmail)\n",
    "from ainb_webscrape import (get_driver, quit_drivers, launch_drivers, get_file, get_url, parse_file,\n",
    "                            get_og_tags, get_path_from_url, trimmed_href, process_source_queue_factory,\n",
    "                            process_url_queue_factory, get_google_news_redirects)\n",
    "from ainb_llm import (paginate_df, process_pages, fetch_pages, fetch_openai, fetch_all_summaries,\n",
    "                      fetch_openai_summary, trunc_tokens, categorize_headline, categorize_df, clean_topics)\n",
    "\n",
    "\n",
    "import asyncio\n",
    "# need this to run async in jupyter since it already has an asyncio event loop running\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ba13ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain         0.3.0\n",
      "OpenAI            1.47.0\n",
      "trafilatura       1.12.2\n",
      "bs4               4.12.3\n",
      "numpy             1.26.4\n",
      "pandas            2.2.3\n",
      "sklearn           1.5.2\n",
      "umap              0.5.6\n"
     ]
    }
   ],
   "source": [
    "print(f\"LangChain         {langchain.__version__}\")\n",
    "print(f\"OpenAI            {openai.__version__}\")\n",
    "# print(f\"smtplib           {smtplib.sys.version}\")\n",
    "print(f\"trafilatura       {trafilatura.__version__}\")\n",
    "# print(f\"bs4               {bs4.__version__}\")\n",
    "print(f\"numpy             {np.__version__}\")\n",
    "print(f\"pandas            {pd.__version__}\")\n",
    "print(f\"sklearn           {sklearn.__version__}\")\n",
    "print(f\"umap              {umap.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ed3b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:13,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ascoltami. Sei bellissima. Sei perfetta e ti amo.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 34, 'total_tokens': 50, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_e375328146', 'finish_reason': 'stop', 'logprobs': None}, id='run-b7293b0d-c8f9-4a85-b6dc-c98c24647781-0', usage_metadata={'input_tokens': 34, 'output_tokens': 16, 'total_tokens': 50})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a basic LLM call with langchain\n",
    "MODEL=\"gpt-4o\"\n",
    "model = ChatOpenAI(model=MODEL)\n",
    "\n",
    "model.invoke([\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content='Listen to me. You are beautiful. You are perfect and I love you.'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ff6dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:22,734 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ciao'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use template\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt_template | model | parser\n",
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6382e44e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:26,832 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Écoute-moi. Tu es parfait(e). Tu es magnifique et je t'aime."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:28,776 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hör mir zu. Du bist makellos. Du bist exquisit und ich liebe dich."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:29,390 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escúchame. Eres perfecta. Eres preciosa y te amo."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:29,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascoltami. Sei incredibile. Sei magnifico e ti amo."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:30,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figyelj rám. Elragadó vagy. Lenyűgöző vagy, és szeretlek.\n",
      "\n",
      "Elapsed seconds: 4.318126\n"
     ]
    }
   ],
   "source": [
    "prompt_inputs = [\n",
    "    {\"language\": \"French\", \"adjective1\": \"flawless\", \"adjective2\": \"beautiful\"},\n",
    "    {\"language\": \"German\", \"adjective1\": \"immaculate\", \"adjective2\": \"exquisite\"},\n",
    "    {\"language\": \"Spanish\", \"adjective1\": \"perfect\", \"adjective2\": \"gorgeous\"},\n",
    "    {\"language\": \"Italian\", \"adjective1\": \"amazing\", \"adjective2\": \"magnificent\"},\n",
    "    {\"language\": \"Hungarian\", \"adjective1\": \"ravishing\", \"adjective2\": \"stunning\"},\n",
    "]\n",
    "\n",
    "system_template = 'Translate the following into {language}:'\n",
    "user_template = 'Listen to me. You are {adjective1}. You are {adjective2} and I love you.'\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template),\n",
    "     (\"user\", user_template)]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "start_time = datetime.now()\n",
    "for tpl in prompt_inputs:\n",
    "    response = \"\"\n",
    "    # stream tokens as they are generated\n",
    "    for r in chain.stream(tpl):\n",
    "        print(r, end=\"\")\n",
    "        response += r\n",
    "end_time = datetime.now()\n",
    "\n",
    "difference = end_time - start_time\n",
    "total_seconds = difference.total_seconds()\n",
    "print(f\"\\n\\nElapsed seconds: {total_seconds:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "659782d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:32,668 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-09-23 17:50:32,672 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-09-23 17:50:32,678 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-09-23 17:50:32,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-09-23 17:50:33,012 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Elapsed seconds: 0.837595\n",
      "Écoute-moi. Tu es parfait(e). Tu es magnifique et je t'aime.\n",
      "Hör mir zu. Du bist makellos. Du bist exquisit und ich liebe dich.\n",
      "Escúchame. Eres perfecto/a. Eres maravilloso/a y te amo.\n",
      "Ascoltami. Sei fantastico. Sei magnifico e ti amo.\n",
      "Hallgass rám. Te elbűvölő vagy. Te lenyűgöző vagy, és szeretlek.\n"
     ]
    }
   ],
   "source": [
    "# same but send all at once using asyncio\n",
    "\n",
    "async def async_langchain(chain, input_dict):\n",
    "    response = await chain.ainvoke(input_dict)\n",
    "    return response\n",
    "\n",
    "\n",
    "prompt_templates = [\n",
    "    {\"language\": \"French\", \"adjective1\": \"flawless\", \"adjective2\": \"beautiful\"},\n",
    "    {\"language\": \"German\", \"adjective1\": \"immaculate\", \"adjective2\": \"exquisite\"},\n",
    "    {\"language\": \"Spanish\", \"adjective1\": \"perfect\", \"adjective2\": \"gorgeous\"},\n",
    "    {\"language\": \"Italian\", \"adjective1\": \"amazing\", \"adjective2\": \"magnificent\"},\n",
    "    {\"language\": \"Hungarian\", \"adjective1\": \"ravishing\", \"adjective2\": \"stunning\"},\n",
    "]\n",
    "\n",
    "start_time = datetime.now()\n",
    "tasks = []\n",
    "for d in prompt_templates:\n",
    "    task = asyncio.create_task(async_langchain(chain, d))\n",
    "    tasks.append(task)\n",
    "responses = await asyncio.gather(*tasks)\n",
    "end_time = datetime.now()\n",
    "\n",
    "\n",
    "difference = end_time - start_time\n",
    "total_seconds = difference.total_seconds()\n",
    "print(f\"\\n\\nElapsed seconds: {total_seconds:.6f}\")\n",
    "print(\"\\n\".join(responses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f02beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "N_BROWSERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e94b7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to maintain settings and state within graph\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    AIdf: dict                #  the current working set of headlines (pandas dataframe not supported)\n",
    "    before_date: str          #  ignore stories before this date for deduplication (force reprocess since)\n",
    "    do_download: bool         #  if False use existing files, else download from sources\n",
    "    sources: dict             #  sources to scrap\n",
    "    sources_reverse: dict     #  map file names to sources\n",
    "    headline_str: str         #  headline text email\n",
    "    bullets: str              #  bullet point summary email\n",
    "    summary: str              #  final summary\n",
    "    n_edits: int              #  count edit iterations so we don't keep editing forever\n",
    "    edit_complete: bool       #  edit will update if no more edits to make\n",
    "    # message thread with OpenAI\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc712e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:47,397 - AInewsbot - INFO - Initialized 17 items in sources from sources.yaml\n",
      "2024-09-23 17:50:47,397 - AInewsbot - INFO - Ars Technica -> https://arstechnica.com/ -> Ars Technica.html\n",
      "2024-09-23 17:50:47,398 - AInewsbot - INFO - Bloomberg Tech -> https://www.bloomberg.com/technology -> Bloomberg Technology.html\n",
      "2024-09-23 17:50:47,398 - AInewsbot - INFO - Business Insider -> https://www.businessinsider.com/tech -> Business Insider Tech.html\n",
      "2024-09-23 17:50:47,398 - AInewsbot - INFO - FT Tech -> https://www.ft.com/technology -> FT Technology.html\n",
      "2024-09-23 17:50:47,399 - AInewsbot - INFO - Feedly AI -> https://feedly.com/i/aiFeeds?options=eyJsYXllcnMiOlt7InBhcnRzIjpbeyJpZCI6Im5scC9mL3RvcGljLzMwMDAifV0sInNlYXJjaEhpbnQiOiJ0ZWNobm9sb2d5IiwidHlwZSI6Im1hdGNoZXMiLCJzYWxpZW5jZSI6ImFib3V0In1dLCJidW5kbGVzIjpbeyJ0eXBlIjoic3RyZWFtIiwiaWQiOiJ1c2VyLzYyZWViYjlmLTcxNTEtNGY5YS1hOGM3LTlhNTdiODIwNTMwOC9jYXRlZ29yeS9HYWRnZXRzIn1dfQ -> Feedly AI.html\n",
      "2024-09-23 17:50:47,399 - AInewsbot - INFO - Google News -> https://news.google.com/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGRqTVhZU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen -> Google News - Technology - Artificial intelligence.html\n",
      "2024-09-23 17:50:47,399 - AInewsbot - INFO - Hacker News -> https://news.ycombinator.com/ -> Hacker News Page 1.html\n",
      "2024-09-23 17:50:47,400 - AInewsbot - INFO - Hacker News 2 -> https://news.ycombinator.com/?p=2 -> Hacker News Page 2.html\n",
      "2024-09-23 17:50:47,400 - AInewsbot - INFO - HackerNoon -> https://hackernoon.com/ -> HackerNoon.html\n",
      "2024-09-23 17:50:47,401 - AInewsbot - INFO - NYT Tech -> https://www.nytimes.com/section/technology -> New York Times Technology.html\n",
      "2024-09-23 17:50:47,401 - AInewsbot - INFO - Reddit -> https://www.reddit.com/r/ChatGPT+ChatGPTCoding+MacOS+MachineLearning+OpenAI+ProgrammerHumor+Windows10+battlestations+buildapc+cordcutters+dataisbeautiful+gadgets+hardware+linux+msp+programming+realtech+software+talesfromtechsupport+tech+technews+technology+techsupportgore+windows/top/?sort=top&t=day -> Reddit multiple subreddits.html\n",
      "2024-09-23 17:50:47,401 - AInewsbot - INFO - Techmeme -> https://www.techmeme.com/river -> Techmeme.html\n",
      "2024-09-23 17:50:47,402 - AInewsbot - INFO - The Register -> https://www.theregister.com/ -> The Register.html\n",
      "2024-09-23 17:50:47,402 - AInewsbot - INFO - The Verge -> https://www.theverge.com/ai-artificial-intelligence -> The Verge AI.html\n",
      "2024-09-23 17:50:47,402 - AInewsbot - INFO - VentureBeat -> https://venturebeat.com/category/ai/ -> VentureBeat AI.html\n",
      "2024-09-23 17:50:47,403 - AInewsbot - INFO - WSJ Tech -> https://www.wsj.com/tech -> WSJ Technology.html\n",
      "2024-09-23 17:50:47,403 - AInewsbot - INFO - WaPo Tech -> https://www.washingtonpost.com/business/technology/ -> Washington Post Technology.html\n",
      "2024-09-23 17:50:47,403 - AInewsbot - INFO - Initialized 17 items in sources_reverse\n"
     ]
    }
   ],
   "source": [
    "# Initialize reading configurations from YAML file\n",
    "\n",
    "def fn_initialize(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Initializes the agent state by loading source configurations from SOURCECONFIG (sources.yaml) .\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state of the agent.\n",
    "        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: The updated state of the agent.\n",
    "\n",
    "    Raises:\n",
    "        yaml.YAMLError: If there is an error while loading the YAML file.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #  load sources to scrape from sources.yaml\n",
    "    with open(SOURCECONFIG, \"r\") as stream:\n",
    "        try:\n",
    "            state['sources'] = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "    log(f\"Initialized {len(state['sources'])} items in sources from {SOURCECONFIG}\")\n",
    "\n",
    "    # make a reverse dict to map file titles to source names\n",
    "    state['sources_reverse'] = {}\n",
    "    for k, v in state['sources'].items():\n",
    "        log(f\"{k} -> {v['url']} -> {v['title']}.html\")\n",
    "        v['sourcename'] = k\n",
    "        # map filename (title) to source name\n",
    "        state['sources_reverse'][v['title']] = k\n",
    "\n",
    "    log(f\"Initialized {len(state['sources_reverse'])} items in sources_reverse\")\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    test_state = AgentState()\n",
    "    fn_initialize(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83608da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:50:56,883 - AInewsbot - INFO - Web fetch disabled, using existing files in htmldata\n",
      "2024-09-23 17:50:56,885 - AInewsbot - INFO - Found 17 previously downloaded files\n",
      "2024-09-23 17:50:56,885 - AInewsbot - INFO - htmldata/New York Times Technology (09_23_2024 05_32_41 PM).html\n",
      "2024-09-23 17:50:56,886 - AInewsbot - INFO - htmldata/Hacker News Page 2 (09_23_2024 05_32_29 PM).html\n",
      "2024-09-23 17:50:56,886 - AInewsbot - INFO - htmldata/HackerNoon (09_23_2024 05_32_39 PM).html\n",
      "2024-09-23 17:50:56,887 - AInewsbot - INFO - htmldata/WSJ Technology (09_23_2024 05_33_19 PM).html\n",
      "2024-09-23 17:50:56,887 - AInewsbot - INFO - htmldata/Bloomberg Technology (09_23_2024 05_32_17 PM).html\n",
      "2024-09-23 17:50:56,888 - AInewsbot - INFO - htmldata/FT Technology (09_23_2024 05_32_17 PM).html\n",
      "2024-09-23 17:50:56,888 - AInewsbot - INFO - htmldata/Washington Post Technology (09_23_2024 05_33_14 PM).html\n",
      "2024-09-23 17:50:56,888 - AInewsbot - INFO - htmldata/Feedly AI (09_23_2024 05_33_37 PM).html\n",
      "2024-09-23 17:50:56,889 - AInewsbot - INFO - htmldata/Reddit multiple subreddits (09_23_2024 05_33_11 PM).html\n",
      "2024-09-23 17:50:56,889 - AInewsbot - INFO - htmldata/VentureBeat AI (09_23_2024 05_33_03 PM).html\n",
      "2024-09-23 17:50:56,890 - AInewsbot - INFO - htmldata/Google News - Technology - Artificial intelligence (09_23_2024 05_32_39 PM).html\n",
      "2024-09-23 17:50:56,890 - AInewsbot - INFO - htmldata/Hacker News Page 1 (09_23_2024 05_32_28 PM).html\n",
      "2024-09-23 17:50:56,890 - AInewsbot - INFO - htmldata/Business Insider Tech (09_23_2024 05_32_16 PM).html\n",
      "2024-09-23 17:50:56,891 - AInewsbot - INFO - htmldata/The Register (09_23_2024 05_32_52 PM).html\n",
      "2024-09-23 17:50:56,891 - AInewsbot - INFO - htmldata/Ars Technica (09_23_2024 05_32_19 PM).html\n",
      "2024-09-23 17:50:56,891 - AInewsbot - INFO - htmldata/The Verge AI (09_23_2024 05_33_02 PM).html\n",
      "2024-09-23 17:50:56,891 - AInewsbot - INFO - htmldata/Techmeme (09_23_2024 05_32_50 PM).html\n"
     ]
    }
   ],
   "source": [
    "# scrape sources with selenium and save local files in DOWNLOAD_DIR (htmldata)\n",
    "def fn_download_sources(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Scrapes sources and saves HTML files.\n",
    "    If state[\"do_download\"] is True, deletes all files in DOWNLOAD_DIR (htmldata) and scrapes fresh copies.\n",
    "    If state[\"do_download\"] is False, uses existing files in DOWNLOAD_DIR.\n",
    "    Uses state[\"sources\"] for config info on sources to scrape\n",
    "    For each source, saves the current filename to state[\"sources\"][sourcename]['latest']\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state of the agent.\n",
    "        do_delete (bool, optional): Whether to delete files in DOWNLOAD_DIR. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: The updated state of the agent.\n",
    "    \"\"\"\n",
    "\n",
    "    if state[\"do_download\"]:\n",
    "        # empty download directory\n",
    "        delete_files(DOWNLOAD_DIR)\n",
    "\n",
    "        # save each file specified from sources\n",
    "        log(f\"Saving HTML files using {N_BROWSERS} browsers\")\n",
    "\n",
    "        # Create a queue for multiprocessing and populate it\n",
    "        queue = multiprocessing.Queue()\n",
    "        for item in state[\"sources\"].values():\n",
    "            queue.put(item)\n",
    "\n",
    "        # Function to take the queue and pop entries off and process until none are left\n",
    "        # lets you create an array of functions with different args\n",
    "        callable = process_source_queue_factory(queue)\n",
    "\n",
    "        saved_pages = launch_drivers(N_BROWSERS, callable)\n",
    "        for sourcename, file in saved_pages:\n",
    "            log(f\"Downloaded {sourcename} to {file}\")\n",
    "            state['sources'][sourcename]['latest'] = file\n",
    "        log(f\"Saved {len(saved_pages)} HTML files\")\n",
    "\n",
    "    else:   # don't delete, just get list of existing files\n",
    "        log(f\"Web fetch disabled, using existing files in {DOWNLOAD_DIR}\")\n",
    "        # Get the current date\n",
    "        datestr = datetime.now().strftime(\"%m_%d_%Y\")\n",
    "        files = [os.path.join(DOWNLOAD_DIR, file)\n",
    "                 for file in os.listdir(DOWNLOAD_DIR)]\n",
    "        # filter files with today's date ending in .html\n",
    "        files = [\n",
    "            file for file in files if datestr in file and file.endswith(\".html\")]\n",
    "        log(f\"Found {len(files)} previously downloaded files\")\n",
    "        for file in files:\n",
    "            log(file)\n",
    "\n",
    "        saved_pages = []\n",
    "        for file in files:\n",
    "            filename = os.path.basename(file)\n",
    "            # locate date like '01_14_2024' in filename\n",
    "            position = filename.find(\" (\" + datestr)\n",
    "            basename = filename[:position]\n",
    "            # match to source name\n",
    "            sourcename = state[\"sources_reverse\"].get(basename)\n",
    "            if sourcename is None:\n",
    "                log(f\"Skipping {basename}, no sourcename metadata\")\n",
    "                continue\n",
    "            state[\"sources\"][sourcename]['latest'] = file\n",
    "\n",
    "    return state\n",
    "\n",
    "if DEBUG:\n",
    "    test_state[\"do_download\"] = False\n",
    "#     test_state[\"before_date\"] = '2024-09-22 12:00:00'\n",
    "    _ = fn_download_sources(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65845bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:54:30,412 - AInewsbot - INFO - Parsing html files\n",
      "2024-09-23 17:54:30,414 - AInewsbot - INFO - Ars Technica -> htmldata/Ars Technica (09_23_2024 05_32_19 PM).html\n",
      "2024-09-23 17:54:30,444 - AInewsbot - INFO - parse_file - found 252 raw links\n",
      "2024-09-23 17:54:30,448 - AInewsbot - INFO - parse_file - found 28 filtered links\n",
      "2024-09-23 17:54:30,448 - AInewsbot - INFO - 28 links found\n",
      "2024-09-23 17:54:30,448 - AInewsbot - INFO - Bloomberg Tech -> htmldata/Bloomberg Technology (09_23_2024 05_32_17 PM).html\n",
      "2024-09-23 17:54:30,474 - AInewsbot - INFO - parse_file - found 210 raw links\n",
      "2024-09-23 17:54:30,477 - AInewsbot - INFO - parse_file - found 27 filtered links\n",
      "2024-09-23 17:54:30,478 - AInewsbot - INFO - 27 links found\n",
      "2024-09-23 17:54:30,478 - AInewsbot - INFO - Business Insider -> htmldata/Business Insider Tech (09_23_2024 05_32_16 PM).html\n",
      "2024-09-23 17:54:30,502 - AInewsbot - INFO - parse_file - found 309 raw links\n",
      "2024-09-23 17:54:30,505 - AInewsbot - INFO - parse_file - found 51 filtered links\n",
      "2024-09-23 17:54:30,505 - AInewsbot - INFO - 51 links found\n",
      "2024-09-23 17:54:30,505 - AInewsbot - INFO - FT Tech -> htmldata/FT Technology (09_23_2024 05_32_17 PM).html\n",
      "2024-09-23 17:54:30,532 - AInewsbot - INFO - parse_file - found 485 raw links\n",
      "2024-09-23 17:54:30,537 - AInewsbot - INFO - parse_file - found 118 filtered links\n",
      "2024-09-23 17:54:30,538 - AInewsbot - INFO - 118 links found\n",
      "2024-09-23 17:54:30,538 - AInewsbot - INFO - Feedly AI -> htmldata/Feedly AI (09_23_2024 05_33_37 PM).html\n",
      "2024-09-23 17:54:30,567 - AInewsbot - INFO - parse_file - found 256 raw links\n",
      "2024-09-23 17:54:30,570 - AInewsbot - INFO - parse_file - found 67 filtered links\n",
      "2024-09-23 17:54:30,570 - AInewsbot - INFO - 67 links found\n",
      "2024-09-23 17:54:30,570 - AInewsbot - INFO - Google News -> htmldata/Google News - Technology - Artificial intelligence (09_23_2024 05_32_39 PM).html\n",
      "2024-09-23 17:54:30,610 - AInewsbot - INFO - parse_file - found 184 raw links\n",
      "2024-09-23 17:54:30,611 - AInewsbot - INFO - parse_file - found 72 filtered links\n",
      "2024-09-23 17:54:30,612 - AInewsbot - INFO - 72 links found\n",
      "2024-09-23 17:54:30,612 - AInewsbot - INFO - Hacker News -> htmldata/Hacker News Page 1 (09_23_2024 05_32_28 PM).html\n",
      "2024-09-23 17:54:30,622 - AInewsbot - INFO - parse_file - found 256 raw links\n",
      "2024-09-23 17:54:30,625 - AInewsbot - INFO - parse_file - found 26 filtered links\n",
      "2024-09-23 17:54:30,625 - AInewsbot - INFO - 26 links found\n",
      "2024-09-23 17:54:30,625 - AInewsbot - INFO - Hacker News 2 -> htmldata/Hacker News Page 2 (09_23_2024 05_32_29 PM).html\n",
      "2024-09-23 17:54:30,636 - AInewsbot - INFO - parse_file - found 261 raw links\n",
      "2024-09-23 17:54:30,639 - AInewsbot - INFO - parse_file - found 25 filtered links\n",
      "2024-09-23 17:54:30,639 - AInewsbot - INFO - 25 links found\n",
      "2024-09-23 17:54:30,639 - AInewsbot - INFO - HackerNoon -> htmldata/HackerNoon (09_23_2024 05_32_39 PM).html\n",
      "2024-09-23 17:54:30,686 - AInewsbot - INFO - parse_file - found 593 raw links\n",
      "2024-09-23 17:54:30,693 - AInewsbot - INFO - parse_file - found 102 filtered links\n",
      "2024-09-23 17:54:30,694 - AInewsbot - INFO - 102 links found\n",
      "2024-09-23 17:54:30,694 - AInewsbot - INFO - NYT Tech -> htmldata/New York Times Technology (09_23_2024 05_32_41 PM).html\n",
      "2024-09-23 17:54:30,704 - AInewsbot - INFO - parse_file - found 76 raw links\n",
      "2024-09-23 17:54:30,706 - AInewsbot - INFO - parse_file - found 18 filtered links\n",
      "2024-09-23 17:54:30,706 - AInewsbot - INFO - 18 links found\n",
      "2024-09-23 17:54:30,706 - AInewsbot - INFO - Reddit -> htmldata/Reddit multiple subreddits (09_23_2024 05_33_11 PM).html\n",
      "2024-09-23 17:54:30,789 - AInewsbot - INFO - parse_file - found 664 raw links\n",
      "2024-09-23 17:54:30,798 - AInewsbot - INFO - parse_file - found 438 filtered links\n",
      "2024-09-23 17:54:30,798 - AInewsbot - INFO - 438 links found\n",
      "2024-09-23 17:54:30,798 - AInewsbot - INFO - Techmeme -> htmldata/Techmeme (09_23_2024 05_32_50 PM).html\n",
      "2024-09-23 17:54:30,813 - AInewsbot - INFO - parse_file - found 306 raw links\n",
      "2024-09-23 17:54:30,817 - AInewsbot - INFO - parse_file - found 123 filtered links\n",
      "2024-09-23 17:54:30,817 - AInewsbot - INFO - 123 links found\n",
      "2024-09-23 17:54:30,817 - AInewsbot - INFO - The Register -> htmldata/The Register (09_23_2024 05_32_52 PM).html\n",
      "2024-09-23 17:54:30,834 - AInewsbot - INFO - parse_file - found 195 raw links\n",
      "2024-09-23 17:54:30,838 - AInewsbot - INFO - parse_file - found 88 filtered links\n",
      "2024-09-23 17:54:30,838 - AInewsbot - INFO - 88 links found\n",
      "2024-09-23 17:54:30,838 - AInewsbot - INFO - The Verge -> htmldata/The Verge AI (09_23_2024 05_33_02 PM).html\n",
      "2024-09-23 17:54:30,866 - AInewsbot - INFO - parse_file - found 314 raw links\n",
      "2024-09-23 17:54:30,869 - AInewsbot - INFO - parse_file - found 33 filtered links\n",
      "2024-09-23 17:54:30,869 - AInewsbot - INFO - 33 links found\n",
      "2024-09-23 17:54:30,869 - AInewsbot - INFO - VentureBeat -> htmldata/VentureBeat AI (09_23_2024 05_33_03 PM).html\n",
      "2024-09-23 17:54:31,012 - AInewsbot - INFO - parse_file - found 328 raw links\n",
      "2024-09-23 17:54:31,016 - AInewsbot - INFO - parse_file - found 44 filtered links\n",
      "2024-09-23 17:54:31,016 - AInewsbot - INFO - 44 links found\n",
      "2024-09-23 17:54:31,016 - AInewsbot - INFO - WSJ Tech -> htmldata/WSJ Technology (09_23_2024 05_33_19 PM).html\n",
      "2024-09-23 17:54:31,047 - AInewsbot - INFO - parse_file - found 515 raw links\n",
      "2024-09-23 17:54:31,054 - AInewsbot - INFO - parse_file - found 46 filtered links\n",
      "2024-09-23 17:54:31,054 - AInewsbot - INFO - 46 links found\n",
      "2024-09-23 17:54:31,054 - AInewsbot - INFO - WaPo Tech -> htmldata/Washington Post Technology (09_23_2024 05_33_14 PM).html\n",
      "2024-09-23 17:54:31,067 - AInewsbot - INFO - parse_file - found 159 raw links\n",
      "2024-09-23 17:54:31,069 - AInewsbot - INFO - parse_file - found 27 filtered links\n",
      "2024-09-23 17:54:31,069 - AInewsbot - INFO - 27 links found\n",
      "2024-09-23 17:54:31,069 - AInewsbot - INFO - Saved 1333 links\n"
     ]
    }
   ],
   "source": [
    "def fn_extract_urls(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Extracts news URLs from the latest HTML files matching the patterns defined in the state['sources'] configuration info.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state of the agent.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: The updated state of the agent with the extracted URLs stored in state['AIdf'].\n",
    "    \"\"\"\n",
    "    # Parse news URLs and titles from downloaded HTML files\n",
    "    log(\"Parsing html files\")\n",
    "    all_urls = []\n",
    "    for sourcename, sourcedict in state['sources'].items():\n",
    "        filename = sourcedict.get('latest')\n",
    "        if not filename:\n",
    "            log(f\"no filename found for {sourcename}\")\n",
    "            continue\n",
    "\n",
    "        log(sourcename + ' -> ' + filename)\n",
    "        links = parse_file(state['sources'][sourcename])\n",
    "        log(f\"{len(links)} links found\")\n",
    "        all_urls.extend(links)\n",
    "\n",
    "    log(f\"Saved {len(all_urls)} links\")\n",
    "\n",
    "    # make a pandas dataframe of all the links found\n",
    "    AIdf = (\n",
    "        pd.DataFrame(all_urls)\n",
    "        .groupby(\"url\")\n",
    "        .first()\n",
    "        .reset_index()\n",
    "        .sort_values(\"src\")[[\"src\", \"title\", \"url\"]]\n",
    "        .reset_index(drop=True)\n",
    "        .reset_index(drop=False)\n",
    "        .rename(columns={\"index\": \"id\"})\n",
    "    )\n",
    "    state['AIdf'] = AIdf.to_dict()\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    _ = fn_extract_urls(test_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a36eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ars Technica</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bloomberg Tech</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT Tech</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedly AI</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google News</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hacker News</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hacker News 2</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HackerNoon</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYT Tech</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reddit</th>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Techmeme</th>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Register</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Verge</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VentureBeat</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSJ Tech</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WaPo Tech</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  title  url\n",
       "src                              \n",
       "Ars Technica       28     28   28\n",
       "Bloomberg Tech     21     21   21\n",
       "Business Insider   51     51   51\n",
       "FT Tech            63     63   63\n",
       "Feedly AI          65     65   65\n",
       "Google News        68     68   68\n",
       "Hacker News        26     26   26\n",
       "Hacker News 2      24     24   24\n",
       "HackerNoon         95     95   95\n",
       "NYT Tech           18     18   18\n",
       "Reddit            236    236  236\n",
       "Techmeme          118    118  118\n",
       "The Register       71     71   71\n",
       "The Verge          29     29   29\n",
       "VentureBeat        41     41   41\n",
       "WSJ Tech           22     22   22\n",
       "WaPo Tech          22     22   22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s/b 17 if some missing, maybe got a robot block, download manually and then re-run\n",
    "print(len(pd.DataFrame(test_state[\"AIdf\"]).groupby('src').count()))\n",
    "pd.DataFrame(test_state[\"AIdf\"]).groupby('src').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f4ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_site_name(session, row):\n",
    "    \"\"\"\n",
    "    Asynchronously gets a name for a website based on its URL from OpenAI.\n",
    "\n",
    "    Args:\n",
    "        session(aiohttp.ClientSession): The aiohttp session used to make the request.\n",
    "        row(object): An object containing the hostname attribute, which is the URL of the site.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the URL and the site name in the format:\n",
    "            {\"url\": \"www.example.com\", \"site_name\": \"Example Site\"}.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If there is an error during the request or response processing.\n",
    "    \"\"\"\n",
    "\n",
    "    cat_prompt = f\"\"\"\n",
    "based on this url and your knowledge of the Web, what is the name of the site? https://{row.hostname}\n",
    "\n",
    "return the response as a json object of the form {{\"url\": \"www.yankodesign.com\", \"site_name\": \"Yanko Design\"}}\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": cat_prompt\n",
    "             }]\n",
    "\n",
    "        payload = {\"model\":  LOWCOST_MODEL,\n",
    "                   \"response_format\": {\"type\": \"json_object\"},\n",
    "                   \"messages\": messages,\n",
    "                   \"temperature\": 0\n",
    "                   }\n",
    "        response = await fetch_openai(session, payload)\n",
    "        response_dict = json.loads(\n",
    "            response[\"choices\"][0][\"message\"][\"content\"])\n",
    "        return response_dict\n",
    "    except Exception as exc:\n",
    "        print(exc)\n",
    "\n",
    "\n",
    "async def fetch_missing_site_names(AIdf):\n",
    "    \"\"\"fetch all missing site names\"\"\"\n",
    "    tasks = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for row in AIdf.loc[AIdf['site_name'] == \"\"].itertuples():\n",
    "            task = asyncio.create_task(get_site_name(session, row))\n",
    "            tasks.append(task)\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "    return responses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd53332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 17:54:38,665 - AInewsbot - INFO - Querying SQLite with where_clause: WHERE timestamp < '2024-09-23 10:00:00'\n",
      "2024-09-23 17:54:38,790 - AInewsbot - INFO - URLs in orig_df: 998\n",
      "2024-09-23 17:54:38,793 - AInewsbot - INFO - Existing URLs in DB: 149940\n",
      "2024-09-23 17:54:38,826 - AInewsbot - INFO - New URLs in df filtered by URL: 400\n",
      "2024-09-23 17:54:38,906 - AInewsbot - INFO - Existing src+title: 26\n",
      "2024-09-23 17:54:38,906 - AInewsbot - INFO - New URLs in df filtered by src+title: 374\n",
      "2024-09-23 17:54:38,915 - AInewsbot - INFO - Found 366 unique AI headlines\n",
      "2024-09-23 17:54:38,923 - AInewsbot - INFO - Applying prompt to 8 pages using gpt-4o-mini\n",
      "2024-09-23 17:54:38,923 - AInewsbot - INFO - sent 50 items \n",
      "2024-09-23 17:54:38,924 - AInewsbot - INFO - sent 50 items \n",
      "2024-09-23 17:54:38,924 - AInewsbot - INFO - sent 50 items \n",
      "2024-09-23 17:54:38,924 - AInewsbot - INFO - sent 50 items \n",
      "2024-09-23 17:54:38,925 - AInewsbot - INFO - sent 50 items \n",
      "2024-09-23 17:54:38,925 - AInewsbot - INFO - sent 50 items \n",
      "2024-09-23 17:54:38,925 - AInewsbot - INFO - sent 50 items \n",
      "2024-09-23 17:54:38,926 - AInewsbot - INFO - sent 16 items \n",
      "2024-09-23 17:54:40,590 - AInewsbot - INFO - got dict with 16 items \n",
      "2024-09-23 17:54:43,412 - AInewsbot - INFO - got dict with 50 items \n",
      "2024-09-23 17:54:44,141 - AInewsbot - INFO - got dict with 50 items \n",
      "2024-09-23 17:54:44,580 - AInewsbot - INFO - got dict with 50 items \n",
      "2024-09-23 17:54:44,584 - AInewsbot - INFO - got dict with 50 items \n",
      "2024-09-23 17:54:44,585 - AInewsbot - INFO - got dict with 50 items \n",
      "2024-09-23 17:54:44,586 - AInewsbot - INFO - got dict with 50 items \n",
      "2024-09-23 17:54:45,399 - AInewsbot - INFO - got dict with 50 items \n",
      "2024-09-23 17:54:45,404 - AInewsbot - INFO - Processed 366 responses.\n",
      "2024-09-23 17:54:45,429 - AInewsbot - INFO - Found 95 AI headlines\n",
      "2024-09-23 17:54:45,433 - AInewsbot - INFO - No missing site names\n"
     ]
    }
   ],
   "source": [
    "# filter and clean URLs for new AI stories\n",
    "\n",
    "def fn_filter_urls(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Filters the URLs in state[\"AIdf\"] to include only those that have not been previously seen,\n",
    "    and are related to AI according to the response from a ChatGPT prompt.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state of the agent.\n",
    "        before_date (str, optional): The date before which the URLs should be filtered. Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "\n",
    "\n",
    "        AgentState: The updated state of the agent with the filtered URLs stored in state[\"AIdf\"].\n",
    "\n",
    "    \"\"\"\n",
    "    # filter to URL not previously seen\n",
    "    AIdf = pd.DataFrame(state[\"AIdf\"])\n",
    "\n",
    "    AIdf = filter_unseen_urls_db(AIdf, before_date=state[\"before_date\"])\n",
    "\n",
    "    if len(AIdf) == 0:\n",
    "        log(\"No new URLs, returning\")\n",
    "        return state\n",
    "\n",
    "    # dedupe identical headlines\n",
    "    # filter similar titles differing by type of quote or something\n",
    "    AIdf['title'] = AIdf['title'].apply(unicode_to_ascii)\n",
    "    AIdf['title_clean'] = AIdf['title'].map(lambda s: \"\".join(s.split()))\n",
    "    AIdf = AIdf.sort_values(\"src\") \\\n",
    "        .groupby(\"title_clean\") \\\n",
    "        .first() \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .drop(columns=['id']) \\\n",
    "        .reset_index() \\\n",
    "        .rename(columns={'index': 'id'})\n",
    "    log(f\"Found {len(AIdf)} unique AI headlines\")\n",
    "\n",
    "    # structured response format\n",
    "    json_schema = {\n",
    "        \"name\": \"json_schema\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"isai_array\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"id\": {\n",
    "                                        \"type\": \"number\"\n",
    "                                    },\n",
    "                                    \"isAI\": {\n",
    "                                        \"type\": \"boolean\"\n",
    "                                    }\n",
    "                                },\n",
    "                        \"required\": [\"id\", \"isAI\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"isai_array\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # filter AI-related headlines using a prompt\n",
    "    pages = paginate_df(AIdf)\n",
    "    enriched_urls = asyncio.run(fetch_pages(pages, prompt=FILTER_PROMPT, json_schema=json_schema))\n",
    "    filter_df = pd.DataFrame(enriched_urls)\n",
    "\n",
    "    # merge returned df with isAI column into original df on id column\n",
    "    AIdf = pd.merge(AIdf, filter_df, on=\"id\", how=\"outer\")\n",
    "\n",
    "    # set hostname based on actualurl\n",
    "    AIdf['actual_url'] = AIdf['url']    # ideally resolve redirects but Google News blocks\n",
    "    AIdf['hostname']=AIdf['actual_url'].apply(lambda url: urlparse(url).netloc)\n",
    "\n",
    "    # update SQLite database with all seen URLs (we are doing this using url and ignoring redirects)\n",
    "    conn = sqlite3.connect(SQLITE_DB)\n",
    "    cursor = conn.cursor()\n",
    "    for row in AIdf.itertuples():\n",
    "        insert_article(conn, cursor, row.src, row.hostname, row.title,\n",
    "                       row.url, row.actual_url, row.isAI, datetime.now().date())\n",
    "\n",
    "    # keep headlines that are related to AI\n",
    "    AIdf = AIdf.loc[AIdf[\"isAI\"]==1] \\\n",
    "        .reset_index(drop=True)  \\\n",
    "        .reset_index()  \\\n",
    "        .drop(columns=[\"id\"])  \\\n",
    "        .rename(columns={'index': 'id'})\n",
    "\n",
    "    log(f\"Found {len(AIdf)} AI headlines\")\n",
    "\n",
    "    # update actual URLs for Google News redirects\n",
    "    # I think Google changed something so this no longer works, instead of a 301 redirct\n",
    "    # get a javascript page that redirects. Also tomorrow we might see different URLs for same stories\n",
    "    # AIdf = get_google_news_redirects(AIdf)\n",
    "\n",
    "    conn = sqlite3.connect('articles.db')\n",
    "    query = \"select * from sites\"\n",
    "    sites_df = pd.read_sql_query(query, conn)\n",
    "    sites_dict = {row.hostname:row.site_name for row in sites_df.itertuples()}\n",
    "    conn.close()\n",
    "\n",
    "    # get clean site_name\n",
    "    AIdf['site_name'] = AIdf['hostname'].apply(lambda hostname: sites_dict.get(hostname, hostname))\n",
    "\n",
    "    # if any missing clean site names, populate them using OpenAI\n",
    "    missing_site_names =  len(AIdf.loc[AIdf['site_name']==\"\"])\n",
    "    if missing_site_names:\n",
    "        log(f\"Asking OpenAI for {missing_site_names} missing site names\")\n",
    "        responses = asyncio.run(fetch_missing_site_names(AIdf))\n",
    "        # update site_dict from responses\n",
    "        new_urls = []\n",
    "        for r in responses:\n",
    "            if r['url'].startswith('https://'):\n",
    "                r['url'] = r['url'][8:]\n",
    "            new_urls.append(r['url'])\n",
    "            sites_dict[r['url']] = r['site_name']\n",
    "            log(f\"Looked up {r['url']} -> {r['site_name']}\")\n",
    "        # update sites table with new names\n",
    "        for url in new_urls:\n",
    "            sqlstr = \"INSERT OR IGNORE INTO sites (hostname, site_name) VALUES (?, ?);\"\n",
    "            log(f\"Updated {url}, '->', {sites_dict[url]}\")\n",
    "            conn.execute(sqlstr, (url, sites_dict[url]))\n",
    "            conn.commit()\n",
    "        # reapply to AIdf with updated sites\n",
    "        AIdf['site_name'] = AIdf['hostname'].apply(lambda hostname: sites_dict.get(hostname, hostname))\n",
    "    else:\n",
    "        log(\"No missing site names\")\n",
    "\n",
    "    # drop banned slop sites\n",
    "    AIdf = AIdf.loc[~AIdf[\"hostname\"].str.lower().isin(HOSTNAME_SKIPLIST)]\n",
    "    AIdf = AIdf.loc[~AIdf[\"site_name\"].str.lower().isin(SITE_NAME_SKIPLIST)]\n",
    "\n",
    "    state[\"AIdf\"] = AIdf.to_dict()\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    before_date=\"2024-09-23 10:00:00\"\n",
    "    test_state[\"before_date\"] = before_date\n",
    "#     test_state[\"before_date\"] = None\n",
    "    _ = fn_filter_urls(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dc63443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.DataFrame(test_state['AIdf']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac3129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:04:05,935 - AInewsbot - INFO - start free-form topic extraction\n",
      "2024-09-23 18:04:05,935 - AInewsbot - INFO - Applying prompt to 2 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:05,936 - AInewsbot - INFO - sent 50 items \n",
      "2024-09-23 18:04:05,936 - AInewsbot - INFO - sent 45 items \n",
      "2024-09-23 18:04:16,223 - AInewsbot - INFO - got dict with 45 items \n",
      "2024-09-23 18:04:22,680 - AInewsbot - INFO - got dict with 50 items \n",
      "2024-09-23 18:04:22,682 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:22,683 - AInewsbot - INFO - 95 free-form topics extracted\n",
      "2024-09-23 18:04:22,686 - AInewsbot - INFO - ['andy serkis', 'entertainment', 'characters', 'film', 'chatgpt', 'humor', 'social media', 'creativity', 'cloudflare', 'data scraping', 'blocking', 'tools', 'linkedin', 'data privacy', 'data usage', 'privacy', 'opt out', 'instagram', 'openai', 'sam altman', 'blog post', 'siri', 'apple', 'update', 'business', 'education', 'meta connect 2024', 'generative ai', 'investors', 'china', 'us', 'robots', 'innovation', 'nvidia', 'google', 'chatbots']\n",
      "2024-09-23 18:04:22,686 - AInewsbot - INFO - Start canonical topic classification\n",
      "2024-09-23 18:04:22,696 - AInewsbot - INFO - AI doom, topic 1 of 154\n",
      "2024-09-23 18:04:22,698 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:22,699 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:22,699 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:22,700 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:22,701 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:22,701 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:24,535 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:24,617 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:24,753 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:25,303 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:26,015 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:26,017 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:26,018 - AInewsbot - INFO - AMD, topic 2 of 154\n",
      "2024-09-23 18:04:26,019 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:26,020 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:26,023 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:26,025 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:26,026 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:26,027 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:27,801 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:28,175 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:28,183 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:28,515 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:29,135 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:29,142 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:29,144 - AInewsbot - INFO - Agriculture, topic 3 of 154\n",
      "2024-09-23 18:04:29,147 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:29,150 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:29,153 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:29,156 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:29,158 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:29,160 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:31,150 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:31,692 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:31,743 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:31,828 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:31,904 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:31,906 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:31,907 - AInewsbot - INFO - Alibaba, topic 4 of 154\n",
      "2024-09-23 18:04:31,907 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:31,908 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:31,909 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:31,910 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:31,912 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:31,913 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:34,525 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:34,867 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:34,901 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:34,947 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:34,971 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:34,973 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:34,974 - AInewsbot - INFO - Amazon, topic 5 of 154\n",
      "2024-09-23 18:04:34,974 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:34,975 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:34,976 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:34,977 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:34,978 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:34,980 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:37,020 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:37,267 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:37,479 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:37,644 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:37,682 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:37,684 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:37,685 - AInewsbot - INFO - Andrew Ng, topic 6 of 154\n",
      "2024-09-23 18:04:37,686 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:37,687 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:37,688 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:37,689 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:37,690 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:37,691 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:39,131 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:39,581 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:39,586 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:39,588 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:39,589 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:39,592 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:39,593 - AInewsbot - INFO - Anthropic, topic 7 of 154\n",
      "2024-09-23 18:04:39,595 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:39,596 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:39,597 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:39,598 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:39,599 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:39,600 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:41,669 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:41,817 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:41,979 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:42,451 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:42,494 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:42,497 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:42,498 - AInewsbot - INFO - Apple, topic 8 of 154\n",
      "2024-09-23 18:04:42,499 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:42,501 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:42,502 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:42,503 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:42,504 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:42,506 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:44,392 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:44,722 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:44,861 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:44,977 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:45,289 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:45,292 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:45,293 - AInewsbot - INFO - Art & Design, topic 9 of 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:04:45,294 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:45,295 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:45,297 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:45,300 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:45,301 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:45,303 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:47,157 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:47,203 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:47,228 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:47,231 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:47,235 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:47,237 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:47,238 - AInewsbot - INFO - Artificial General Intelligence, topic 10 of 154\n",
      "2024-09-23 18:04:47,238 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:47,239 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:47,240 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:47,241 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:47,241 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:47,242 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:49,151 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:49,719 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:49,722 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:49,820 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:49,837 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:49,839 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:49,840 - AInewsbot - INFO - Authors & Writing, topic 11 of 154\n",
      "2024-09-23 18:04:49,840 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:49,841 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:49,842 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:49,844 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:49,845 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:49,848 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:51,771 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:52,164 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:52,171 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:52,190 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:52,195 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:52,198 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:52,199 - AInewsbot - INFO - Autonomous vehicles, topic 12 of 154\n",
      "2024-09-23 18:04:52,200 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:52,201 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:52,202 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:52,204 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:52,205 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:52,206 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:54,303 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:54,664 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:54,765 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:55,248 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:55,455 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:55,458 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:55,459 - AInewsbot - INFO - Baidu, topic 13 of 154\n",
      "2024-09-23 18:04:55,460 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:55,462 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:55,463 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:55,464 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:55,465 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:55,467 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:04:56,939 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:04:57,605 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:58,017 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:58,051 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:58,233 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:04:58,237 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:04:58,238 - AInewsbot - INFO - Bias and Fairness, topic 14 of 154\n",
      "2024-09-23 18:04:58,239 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:04:58,240 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:58,241 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:58,242 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:58,243 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:04:58,246 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:05:00,371 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:00,511 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:01,335 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:05:01,339 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:02,112 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:02,116 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:05:02,117 - AInewsbot - INFO - Big Tech, topic 15 of 154\n",
      "2024-09-23 18:05:02,118 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:05:02,120 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:02,121 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:02,122 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:02,122 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:02,123 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:05:03,774 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:05:04,160 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:04,208 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:04,246 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:04,389 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:04,393 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:05:04,396 - AInewsbot - INFO - Bill Gates, topic 16 of 154\n",
      "2024-09-23 18:05:04,401 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:05:04,402 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:04,403 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:04,404 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:04,405 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:04,407 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:05:06,411 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:05:06,423 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:06,821 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:06,823 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:06,824 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:06,825 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:05:06,826 - AInewsbot - INFO - Books & Publishing, topic 17 of 154\n",
      "2024-09-23 18:05:06,826 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:05:06,827 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:06,829 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:06,830 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:06,832 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:06,833 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:05:08,767 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:08,830 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:05:09,147 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:09,160 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:09,251 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:09,254 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:05:09,255 - AInewsbot - INFO - Brain-Computer Interfaces, topic 18 of 154\n",
      "2024-09-23 18:05:09,256 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:05:09,258 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:09,260 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:09,261 - AInewsbot - INFO - sent 20 items \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:05:09,262 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:09,264 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:05:11,554 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:11,567 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:11,611 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:12,265 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:05:12,791 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:12,793 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:05:12,793 - AInewsbot - INFO - Bubble, topic 19 of 154\n",
      "2024-09-23 18:05:12,794 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:05:12,795 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:12,797 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:12,799 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:12,801 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:12,802 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:05:15,014 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:05:15,424 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:15,428 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:15,430 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:15,431 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:15,432 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:05:15,433 - AInewsbot - INFO - ChatGPT, topic 20 of 154\n",
      "2024-09-23 18:05:15,434 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:05:15,435 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:15,436 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:15,438 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:15,439 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:15,441 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:05:17,167 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:05:18,294 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:18,296 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:18,397 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:19,314 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:19,316 - AInewsbot - INFO - Processed 95 responses.\n",
      "2024-09-23 18:05:19,317 - AInewsbot - INFO - Chatbots, topic 21 of 154\n",
      "2024-09-23 18:05:19,318 - AInewsbot - INFO - Applying prompt to 5 pages using gpt-4o-mini\n",
      "2024-09-23 18:05:19,319 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:19,320 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:19,321 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:19,322 - AInewsbot - INFO - sent 20 items \n",
      "2024-09-23 18:05:19,323 - AInewsbot - INFO - sent 15 items \n",
      "2024-09-23 18:05:21,464 - AInewsbot - INFO - got dict with 15 items \n",
      "2024-09-23 18:05:22,081 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:22,084 - AInewsbot - INFO - got dict with 20 items \n",
      "2024-09-23 18:05:22,085 - AInewsbot - INFO - got dict with 20 items \n"
     ]
    }
   ],
   "source": [
    "# Function for topic extraction\n",
    "\n",
    "def clean_topics(row, lcategories):\n",
    "    \"\"\"\n",
    "    Cleans the extracted_topics and assigned_topics by removing certain common topics and combining them into a single list.\n",
    "\n",
    "    Args:\n",
    "        row (pandas.Series): The row containing the extracted_topics and assigned_topics.\n",
    "        lcategories (set): The set of lowercase categories.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned and combined list of topics.\n",
    "    \"\"\"\n",
    "    extracted_topics = [x.title() for x in row.extracted_topics if x.lower() not in {\"technology\", \"ai\", \"artificial intelligence\"}]\n",
    "    assigned_topics = [x.title() for x in row.assigned_topics if x.lower() in lcategories]\n",
    "    combined = sorted(list(set(extracted_topics + assigned_topics)))\n",
    "    combined = [s.replace(\"Ai\", \"AI\") for s in combined]\n",
    "    combined = [s.replace(\"Genai\", \"Gen AI\") for s in combined]\n",
    "    combined = [s.replace(\"Openai\", \"OpenAI\") for s in combined]\n",
    "\n",
    "    return combined\n",
    "\n",
    "\n",
    "async def do_cat(AIdf, categories):\n",
    "    \"\"\"\n",
    "    Sends a prompt to ChatGPT to select topics for the title for each row in AIdf\n",
    "    which match the topics in categories.\n",
    "\n",
    "    Args:\n",
    "        AIdf (pandas.DataFrame): The DataFrame containing the headlines.\n",
    "        categories (list): The list of topics to match with the headlines.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are the row IDs and the values are lists\n",
    "        of selected topics for each headline.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    catdict = {}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i, row in enumerate(AIdf.itertuples()):\n",
    "            tasks = []\n",
    "            log(f\"Categorizing headline {row.id+1} of {len(AIdf)}\")\n",
    "            h = row.title\n",
    "            log(h)\n",
    "            for c in categories:\n",
    "                task = asyncio.create_task(categorize_headline(h, c, session))\n",
    "                tasks.append(task)\n",
    "            responses = await asyncio.gather(*tasks)\n",
    "            catdict[row.id] = [item for sublist in responses for item in sublist]\n",
    "            log(str(catdict[row.id]))\n",
    "\n",
    "    return catdict\n",
    "\n",
    "\n",
    "def fn_topic_analysis(state: AgentState) -> AgentState:\n",
    "\n",
    "    \"\"\"\n",
    "    Extracts and selects topics for each headline in the state['AIdf'] dataframe, scrubs them, and stores them back in the dataframe.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state of the agent.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: The updated state of the agent with the extracted and selected topics stored in state['AIdf'].\n",
    "    \"\"\"\n",
    "    AIdf = pd.DataFrame(state[\"AIdf\"])\n",
    "    pages = paginate_df(AIdf)\n",
    "    # apply topic extraction prompt to AI headlines\n",
    "    log(\"start free-form topic extraction\")\n",
    "    json_schema = {\n",
    "        \"name\": \"extracted_topics\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"extracted_topics\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"id\": {\n",
    "                                \"type\": \"number\",\n",
    "                            },\n",
    "                            \"topics\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                },\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\"id\", \"topics\"],\n",
    "                        \"additionalProperties\": False,\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"extracted_topics\"],\n",
    "            \"additionalProperties\": False,\n",
    "        }\n",
    "    }\n",
    "    response = asyncio.run(fetch_pages(pages, prompt=TOPIC_PROMPT, json_schema=json_schema))\n",
    "    topic_df = pd.DataFrame(response)\n",
    "    topic_df = topic_df.rename(columns={'topics': 'extracted_topics'})\n",
    "\n",
    "    log(f\"{len(topic_df)} free-form topics extracted\")\n",
    "    all_topics = [item.lower() for row in topic_df.itertuples() for item in row.extracted_topics]\n",
    "    item_counts = Counter(all_topics)\n",
    "    filtered_topics = [item for item in item_counts if item_counts[item] >= 2 and item not in {'technology', 'ai', 'artificial intelligence'}]\n",
    "    categories = sorted(CANONICAL_TOPICS)\n",
    "    # use categories that are canonical or show up twice in freeform\n",
    "    lcategories = set([c.lower() for c in categories] + [c.lower() for c in filtered_topics])\n",
    "    # new topics\n",
    "    log([c for c in filtered_topics if c not in categories])\n",
    "\n",
    "    catdict = asyncio.run(categorize_headline(AIdf, categories=categories, maxpagelen=20))\n",
    "    topic_df['assigned_topics'] = topic_df['id'].apply(lambda id: catdict.get(id, \"\"))\n",
    "\n",
    "    topic_df[\"topics\"] = topic_df.apply(lambda t: clean_topics(t, lcategories), axis=1)\n",
    "    topic_df[\"topic_str\"] = topic_df.apply(lambda row: \", \".join(row.topics), axis=1)\n",
    "\n",
    "    try: # for idempotency\n",
    "        AIdf = AIdf.drop(columns=['topic_str', 'title_topic_str'])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    AIdf = pd.merge(AIdf, topic_df[[\"id\", \"topic_str\"]], on=\"id\", how=\"outer\")\n",
    "    AIdf['title_topic_str'] = AIdf.apply(lambda row: f'{row.title} (Topics: {row.topic_str})', axis=1)\n",
    "\n",
    "    state[\"AIdf\"] = AIdf.to_dict()\n",
    "    return state\n",
    "\n",
    "if DEBUG:\n",
    "    _ = fn_topic_analysis(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "426fbbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:17,455 - AInewsbot - INFO - Fetching embeddings for 28 headlines\n",
      "2024-09-23 18:21:18,036 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-09-23 18:21:19,179 - AInewsbot - INFO - Sort with nearest_neighbor_sort sort\n",
      "2024-09-23 18:21:19,185 - AInewsbot - INFO - Perform dimensionality reduction\n",
      "2024-09-23 18:21:20,534 - AInewsbot - INFO - Cluster with DBSCAN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>When robots can't riddle: What puzzles reveal about the depths of our own minds (Topics: Artificial General Intelligence, Cognition, Cognitive Science, Consciousness, Ethics, Human Mind, Puzzles, Robots, Safety And Alignment, Science, Singularity, Society &amp; Culture)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How to Survive the AI Apocalypse (Topics: AI Doom, Apocalypse, Future, Gen AI, Safety And Alignment, Singularity, Survival)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Exploring \"Clarity Windows\" in AI: The Unpredictable Moments of Perceived Consciousness (Topics: Artificial General Intelligence, Clarity Windows, Cognitive Science, Consciousness, Ethics, Gen AI, Perception, Perplexity, Safety And Alignment, Science, Singularity)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AI Uprising: Can Machines Really Outthink Humans? (Topics: AI Doom, Artificial General Intelligence, Cognitive Science, Gen AI, Human Intelligence, Machines, Safety And Alignment, Science, Singularity, Uprising)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The AI Revolution: Reimagining Governance, Society, and Human Consciousness in the 21st Century (Topics: 21St Century, Cognitive Science, Consciousness, Ethics, Gen AI, Governance, Human Consciousness, Singularity, Society, Society &amp; Culture)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                                                                                              title_topic_str  \n",
       "0  When robots can't riddle: What puzzles reveal about the depths of our own minds (Topics: Artificial General Intelligence, Cognition, Cognitive Science, Consciousness, Ethics, Human Mind, Puzzles, Robots, Safety And Alignment, Science, Singularity, Society & Culture)  \n",
       "1                                                                                                                                                 How to Survive the AI Apocalypse (Topics: AI Doom, Apocalypse, Future, Gen AI, Safety And Alignment, Singularity, Survival)  \n",
       "2    Exploring \"Clarity Windows\" in AI: The Unpredictable Moments of Perceived Consciousness (Topics: Artificial General Intelligence, Clarity Windows, Cognitive Science, Consciousness, Ethics, Gen AI, Perception, Perplexity, Safety And Alignment, Science, Singularity)  \n",
       "3                                                         AI Uprising: Can Machines Really Outthink Humans? (Topics: AI Doom, Artificial General Intelligence, Cognitive Science, Gen AI, Human Intelligence, Machines, Safety And Alignment, Science, Singularity, Uprising)  \n",
       "4                          The AI Revolution: Reimagining Governance, Society, and Human Consciousness in the 21st Century (Topics: 21St Century, Cognitive Science, Consciousness, Ethics, Gen AI, Governance, Human Consciousness, Singularity, Society, Society & Culture)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:21,292 - AInewsbot - INFO - I dub this cluster: Artificial Intelligence and Human Cognition\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Andy Serkis says screen industries should embrace AI at Labour party conference (Topics: Andy Serkis, Conference, Entertainment, Ethics, Gen AI, Governance, Hollywood, Jobs &amp; Careerslabor Market, Labour Party, Opinion, Policy And Regulation, Politics, Screen Industries, Tv &amp; Film &amp; Movies, Uk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Andy Serkis Teases New Project Featuring AI Characters (Topics: Andy Serkis, Characters, Entertainment, Film, Gen AI, Hollywood, Teaser, Tv &amp; Film &amp; Movies)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Andy Serkis teases his next project, which will feature AI characters (Topics: Andy Serkis, Characters, Entertainment, Film, Gen AI, Hollywood, Tv &amp; Film &amp; Movies)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Andy Serkis Thinks AI Is 'Magic' (Topics: Andy Serkis, Entertainment, Gen AI, Hollywood, Magic, Opinion, Tv &amp; Film &amp; Movies)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "5   5   \n",
       "6   6   \n",
       "7   7   \n",
       "8   8   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                          title_topic_str  \n",
       "5  Andy Serkis says screen industries should embrace AI at Labour party conference (Topics: Andy Serkis, Conference, Entertainment, Ethics, Gen AI, Governance, Hollywood, Jobs & Careerslabor Market, Labour Party, Opinion, Policy And Regulation, Politics, Screen Industries, Tv & Film & Movies, Uk)  \n",
       "6                                                                                                                                            Andy Serkis Teases New Project Featuring AI Characters (Topics: Andy Serkis, Characters, Entertainment, Film, Gen AI, Hollywood, Teaser, Tv & Film & Movies)  \n",
       "7                                                                                                                                     Andy Serkis teases his next project, which will feature AI characters (Topics: Andy Serkis, Characters, Entertainment, Film, Gen AI, Hollywood, Tv & Film & Movies)  \n",
       "8                                                                                                                                                                            Andy Serkis Thinks AI Is 'Magic' (Topics: Andy Serkis, Entertainment, Gen AI, Hollywood, Magic, Opinion, Tv & Film & Movies)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:21,813 - AInewsbot - INFO - I dub this cluster: AI in Entertainment and Film\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ChatGPT was like \"miss me with that sh** (Topics: Chatbots, Chatgpt, Code Assistants, Gen AI, Humor, Language Models, OpenAI, Opinion, Social Media, Virtual Assistants)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>The following ChatGPT prompt guidance that produced Mini Corgi Surfers (Topics: Chatbots, Chatgpt, Code Assistants, Creativity, Gen AI, Language Models, OpenAI, Prompt Guidance)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Chat GPT Orgasmic Groans (Topics: Chatbots, Chatgpt, Entertainment, Gen AI, Humor, Language Models, OpenAI, Opinion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>I love ChatGPT (Topics: Chatbots, Chatgpt, Code Assistants, Enthusiasm, Gen AI, Language Models, OpenAI, Opinion, Virtual Assistants)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "9    9   \n",
       "10  10   \n",
       "11  11   \n",
       "12  12   \n",
       "\n",
       "                                                                                                                                                                      title_topic_str  \n",
       "9            ChatGPT was like \"miss me with that sh** (Topics: Chatbots, Chatgpt, Code Assistants, Gen AI, Humor, Language Models, OpenAI, Opinion, Social Media, Virtual Assistants)  \n",
       "10  The following ChatGPT prompt guidance that produced Mini Corgi Surfers (Topics: Chatbots, Chatgpt, Code Assistants, Creativity, Gen AI, Language Models, OpenAI, Prompt Guidance)  \n",
       "11                                                               Chat GPT Orgasmic Groans (Topics: Chatbots, Chatgpt, Entertainment, Gen AI, Humor, Language Models, OpenAI, Opinion)  \n",
       "12                                              I love ChatGPT (Topics: Chatbots, Chatgpt, Code Assistants, Enthusiasm, Gen AI, Language Models, OpenAI, Opinion, Virtual Assistants)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:22,223 - AInewsbot - INFO - I dub this cluster: ChatGPT and Generative AI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>New Cloudflare Tools Let Sites Detect and Block AI Bots for Free (Topics: Big Tech, Blocking, Cloudflare, Customer Service, Cybersecurity, Detection, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy &amp; Surveillance, Products, Safety And Alignment, Science, Tools)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Cloudflare's new marketplace lets websites charge AI bots for scraping (Topics: Big Tech, Cloudflare, Customer Service, Cybersecurity, Data Scraping, Deals, Economics, Ethics, Finance, Gen AI, Intellectual Property, Legal Issues, Marketplace, Policy And Regulation, Privacy, Privacy &amp; Surveillance, Products, Websites)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Cloudflare rolls out Bot Management, a suite of free AI auditing tools meant to help monitor and selectively block AI data-scraping bots, to all its customers (Topics: Big Tech, Bot Management, Cloudflare, Customer Service, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy &amp; Surveillance, Products, Safety And Alignment, Science, Tools)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Cloudflare moves to end free, endless AI scraping with one-click blocking (Topics: Big Tech, Blocking, Cloudflare, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy &amp; Surveillance)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Cloudflare is arming content creators with free weapons in the battle against AI bot crawlers (Topics: Big Tech, Cloudflare, Content Creators, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy &amp; Surveillance, Tools)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "13  13   \n",
       "14  14   \n",
       "15  15   \n",
       "16  16   \n",
       "17  17   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                 title_topic_str  \n",
       "13                                                                                                          New Cloudflare Tools Let Sites Detect and Block AI Bots for Free (Topics: Big Tech, Blocking, Cloudflare, Customer Service, Cybersecurity, Detection, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Safety And Alignment, Science, Tools)  \n",
       "14                                                                                Cloudflare's new marketplace lets websites charge AI bots for scraping (Topics: Big Tech, Cloudflare, Customer Service, Cybersecurity, Data Scraping, Deals, Economics, Ethics, Finance, Gen AI, Intellectual Property, Legal Issues, Marketplace, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Websites)  \n",
       "15  Cloudflare rolls out Bot Management, a suite of free AI auditing tools meant to help monitor and selectively block AI data-scraping bots, to all its customers (Topics: Big Tech, Bot Management, Cloudflare, Customer Service, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Safety And Alignment, Science, Tools)  \n",
       "16                                                                                                                                                               Cloudflare moves to end free, endless AI scraping with one-click blocking (Topics: Big Tech, Blocking, Cloudflare, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance)  \n",
       "17                                                                                                                            Cloudflare is arming content creators with free weapons in the battle against AI bot crawlers (Topics: Big Tech, Cloudflare, Content Creators, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Tools)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:23,047 - AInewsbot - INFO - I dub this cluster: Cloudflare and AI Bot Management\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Social media platforms are using what you create for artificial intelligence. Heres how to opt out (Topics: Bias And Fairness, Big Tech, Data Usage, Ethics, Gen AI, Intellectual Property, Legal Issues, Opt Out, Policy And Regulation, Privacy, Privacy &amp; Surveillance, Safety And Alignment, Social Media, Society &amp; Culture)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>LinkedIn, Facebook, and Instagram are hoovering up your data to train their AI. Heres how to stop it (Topics: Bias And Fairness, Big Tech, Cybersecurity, Data Privacy, Ethics, Facebook, Gen AI, Instagram, Intellectual Property, Legal Issues, Linkedin, Meta, Policy And Regulation, Privacy, Privacy &amp; Surveillance, Safety And Alignment, Society &amp; Culture)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>LinkedIn is training AI on you  unless you opt out with this setting (Topics: Bias And Fairness, Big Tech, Cybersecurity, Data Privacy, Ethics, Gen AI, Intellectual Property, Jobs &amp; Careerslabor Market, Linkedin, Policy And Regulation, Privacy, Privacy &amp; Surveillance, Safety And Alignment, Science, User Settings)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Social media platforms are using what you create for AI. Heres how to opt out (Topics: Bias And Fairness, Big Tech, Data Usage, Ethics, Gen AI, Intellectual Property, Legal Issues, Opt Out, Policy And Regulation, Privacy, Privacy &amp; Surveillance, Safety And Alignment, Social Media, Society &amp; Culture)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "18  18   \n",
       "19  19   \n",
       "20  20   \n",
       "21  21   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                       title_topic_str  \n",
       "18                                   Social media platforms are using what you create for artificial intelligence. Heres how to opt out (Topics: Bias And Fairness, Big Tech, Data Usage, Ethics, Gen AI, Intellectual Property, Legal Issues, Opt Out, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Social Media, Society & Culture)  \n",
       "19  LinkedIn, Facebook, and Instagram are hoovering up your data to train their AI. Heres how to stop it (Topics: Bias And Fairness, Big Tech, Cybersecurity, Data Privacy, Ethics, Facebook, Gen AI, Instagram, Intellectual Property, Legal Issues, Linkedin, Meta, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Society & Culture)  \n",
       "20                                          LinkedIn is training AI on you  unless you opt out with this setting (Topics: Bias And Fairness, Big Tech, Cybersecurity, Data Privacy, Ethics, Gen AI, Intellectual Property, Jobs & Careerslabor Market, Linkedin, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Science, User Settings)  \n",
       "21                                                        Social media platforms are using what you create for AI. Heres how to opt out (Topics: Bias And Fairness, Big Tech, Data Usage, Ethics, Gen AI, Intellectual Property, Legal Issues, Opt Out, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Social Media, Society & Culture)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:23,760 - AInewsbot - INFO - I dub this cluster: Data Privacy and AI Ethics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Sam Altman catapults past founder mode into god mode with latest AI post (Topics: Big Tech, Blog Post, Founder, Gen AI, OpenAI, Opinion, Sam Altman, Singularity)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>OpenAI CEO Sam Altman anticipates superintelligence soon, defends AI in rare personal blog post (Topics: Artificial General Intelligence, Big Tech, Blog Post, Ethics, Gen AI, OpenAI, Opinion, Safety And Alignment, Sam Altman, Science, Singularity, Superintelligence)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Sam Altman may be in his villain era, but no one seems to care (Topics: Opinion, Public Perception, Sam Altman)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "22  22   \n",
       "23  23   \n",
       "24  24   \n",
       "\n",
       "                                                                                                                                                                                                                                                               title_topic_str  \n",
       "22                                                                                                           Sam Altman catapults past founder mode into god mode with latest AI post (Topics: Big Tech, Blog Post, Founder, Gen AI, OpenAI, Opinion, Sam Altman, Singularity)  \n",
       "23  OpenAI CEO Sam Altman anticipates superintelligence soon, defends AI in rare personal blog post (Topics: Artificial General Intelligence, Big Tech, Blog Post, Ethics, Gen AI, OpenAI, Opinion, Safety And Alignment, Sam Altman, Science, Singularity, Superintelligence)  \n",
       "24                                                                                                                                                             Sam Altman may be in his villain era, but no one seems to care (Topics: Opinion, Public Perception, Sam Altman)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:24,420 - AInewsbot - INFO - I dub this cluster: Sam Altman and AI Perspectives\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Some of Siri's long-awaited AI enhancements could reach users by January (Topics: Big Tech, Chatbots, Enhancements, Gen AI, Siri, Speech Recognition &amp; Synthesis, Update, Virtual Assistants)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Siri May Not Get Its Apple Intelligence Update Until January 2025 (Topics: Apple, Big Tech, Chatbots, Siri, Speech Recognition &amp; Synthesis, Update, Virtual Assistants)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>The 5 best Apple Intelligence tools you can try right now in iOS 18.1 public beta (Topics: Apple, Big Tech, Ios 18.1, Products, Review, Tools)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  \\\n",
       "25  25   \n",
       "26  26   \n",
       "27  27   \n",
       "\n",
       "                                                                                                                                                                                  title_topic_str  \n",
       "25  Some of Siri's long-awaited AI enhancements could reach users by January (Topics: Big Tech, Chatbots, Enhancements, Gen AI, Siri, Speech Recognition & Synthesis, Update, Virtual Assistants)  \n",
       "26                        Siri May Not Get Its Apple Intelligence Update Until January 2025 (Topics: Apple, Big Tech, Chatbots, Siri, Speech Recognition & Synthesis, Update, Virtual Assistants)  \n",
       "27                                                 The 5 best Apple Intelligence tools you can try right now in iOS 18.1 public beta (Topics: Apple, Big Tech, Ios 18.1, Products, Review, Tools)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:25,191 - AInewsbot - INFO - I dub this cluster: AI Enhancements in Virtual Assistants\n"
     ]
    }
   ],
   "source": [
    "async def write_topic_name(session, topic_list_str, max_retries=3, model=LOWCOST_MODEL):\n",
    "    \"\"\"\n",
    "    Generates a name for a cluster based on a list of headline topics.\n",
    "\n",
    "    Parameters:\n",
    "    session (aiohttp.ClientSession): The client session for making async HTTP requests.\n",
    "    topic_list_str (str): A string containing the list of headline topics.\n",
    "    max_retries (int, optional): The maximum number of retries in case of an error. Defaults to 3.\n",
    "    model (str, optional): The model to use for generating the topic name. Defaults to LOWCOST_MODEL.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the generated topic name.\n",
    "\n",
    "    Example Usage:\n",
    "    title_topic_str_list = \"Headline 1 (Topic: Topic 1)\\n\\nHeadline 2 (Topic: Topic 2)\"\n",
    "    result = await write_topic_name(session, title_topic_str_list)\n",
    "    print(result)\n",
    "\n",
    "    Output:\n",
    "    {\"topic_title\": \"Generated Topic Name\"}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    TOPIC_WRITER_PROMPT = f\"\"\"\n",
    "You are a topic writing assistant. I will provide a list of headlines with extracted topics in parentheses.\n",
    "Your task is to propose a name for a topic that very simply, clearly and accurately captures all the provided\n",
    "headlines in less than 7 words. You will output a JSON object with the key \"topic_title\".\n",
    "\n",
    "Example Input:\n",
    "In the latest issue of Caixins weekly magazine: CATL Bets on 'Skateboard Chassis' and Battery Swaps to Dispell Market Concerns (powered by AI) (Topics: Battery Swaps, Catl, China, Market Concerns, Skateboard Chassis)\n",
    "\n",
    "AI, cheap EVs, future Chevy  the week (Topics: Chevy, Evs)\n",
    "\n",
    "Electric Vehicles and AI: Driving the Consumer & World Forward (Topics: Consumer, Electric Vehicles, Technology)\n",
    "\n",
    "Example Output:\n",
    "{{\"topic_title\": \"Electric Vehicles\"}}\n",
    "\n",
    "Task\n",
    "Propose the name for the overall topic based on the following provided headlines and individual topics:\n",
    "\n",
    "{topic_list_str}\n",
    "\"\"\"\n",
    "\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            messages=[\n",
    "                      {\"role\": \"user\", \"content\": TOPIC_WRITER_PROMPT\n",
    "                      }]\n",
    "\n",
    "            payload = {\"model\":  model,\n",
    "                       \"response_format\": {\"type\": \"json_object\"},\n",
    "                       \"messages\": messages,\n",
    "                       \"temperature\": 0\n",
    "                       }\n",
    "#             print(topic_list_str)\n",
    "            response = asyncio.run(fetch_openai(session, payload))\n",
    "            response_dict = json.loads(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            return response_dict\n",
    "\n",
    "            break\n",
    "        except Exception as exc:\n",
    "            log(f\"Error: {exc}\")\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "async def afn_topic_clusters(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Fetches embeddings for the headlines, creates clusters of similar articles using DBSCAN, and sorts\n",
    "    using the clusters and a traveling salesman shortest traversal in embedding space.\n",
    "\n",
    "    Parameters:\n",
    "    state (AgentState): The state of the agent.\n",
    "\n",
    "    Returns:\n",
    "    AgentState: The updated state of the agent.\n",
    "\n",
    "    \"\"\"\n",
    "    AIdf = pd.DataFrame(state[\"AIdf\"])\n",
    "\n",
    "    log(f\"Fetching embeddings for {len(AIdf)} headlines\")\n",
    "    embedding_model = 'text-embedding-3-large'\n",
    "    client = OpenAI()\n",
    "    response = client.embeddings.create(input=AIdf['title_topic_str'].tolist(),\n",
    "                                        model=embedding_model)\n",
    "    embedding_df = pd.DataFrame([e.model_dump()['embedding'] for e in response.data])\n",
    "\n",
    "    # greedy traveling salesman sort\n",
    "    log(f\"Sort with nearest_neighbor_sort sort\")\n",
    "    sorted_indices = nearest_neighbor_sort(embedding_df)\n",
    "    AIdf['sort_order'] = sorted_indices\n",
    "\n",
    "    # do dimensionality reduction on embedding_df and cluster analysis\n",
    "    log(f\"Perform dimensionality reduction\")\n",
    "    with open(\"reducer.pkl\", 'rb') as file:\n",
    "        # Load the model from the file\n",
    "        reducer = pickle.load(file)\n",
    "    reduced_data = reducer.transform(embedding_df)\n",
    "    log(f\"Cluster with DBSCAN\")\n",
    "    dbscan = DBSCAN(eps=0.4, min_samples=3)  # Adjust eps and min_samples as needed\n",
    "    AIdf['cluster'] = dbscan.fit_predict(reduced_data)\n",
    "    AIdf.loc[AIdf['cluster'] == -1, 'cluster'] = 999\n",
    "\n",
    "    # sort first by clusters found by DBSCAN, then by semantic ordering\n",
    "    AIdf = AIdf.sort_values(['cluster', 'sort_order']) \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .reset_index() \\\n",
    "        .drop(columns=[\"id\"]) \\\n",
    "        .rename(columns={'index': 'id'})\n",
    "\n",
    "    # show clusters\n",
    "    cluster_topics = []\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            for i in range(30):\n",
    "                tmpdf = AIdf.loc[AIdf['cluster']==i][[\"id\", \"title_topic_str\"]]\n",
    "                if len(tmpdf) ==0:\n",
    "                    break\n",
    "                display(tmpdf)\n",
    "                title_topic_str_list = (\"\\n\\n\".join(tmpdf['title_topic_str'].to_list()))\n",
    "                cluster_topic = await write_topic_name(session, title_topic_str_list)\n",
    "                cluster_topic = cluster_topic['topic_title']\n",
    "                cluster_topics.append(cluster_topic)\n",
    "                log(f\"I dub this cluster: {cluster_topic}\")\n",
    "    state[\"cluster_topics\"] = cluster_topics\n",
    "    AIdf[\"cluster_name\"] = AIdf['cluster'].apply(lambda i: cluster_topics[i] if i < len(cluster_topics) else \"\")\n",
    "    state[\"AIdf\"] = AIdf.to_dict()\n",
    "    return state\n",
    "\n",
    "# TODO: could add a quality rating for stories based on site reputation, length, complexity of story\n",
    "# could then add the quality rating to the summaries and tell the prompt to favor high-quality stories\n",
    "# could put summaries into vector store and retrieve stories by topic. but then you will have to deal\n",
    "# with duplicates across categories, ask the prompt to dedupe\n",
    "\n",
    "def fn_topic_clusters(state: AgentState) -> AgentState:\n",
    "    \"call async afn_topic_clusters on state\"\n",
    "    asyncio.run(afn_topic_clusters(state))\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    _ = fn_topic_clusters(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f796cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:21:43,715 - AInewsbot - INFO - Queuing URLs for scraping\n",
      "2024-09-23 18:21:43,725 - AInewsbot - INFO - fetching 28 pages using 4 browsers\n",
      "2024-09-23 18:21:43,727 - AInewsbot - INFO - get_driver - 32827 Initializing webdriver\n",
      "2024-09-23 18:21:43,729 - AInewsbot - INFO - get_driver - 32827 Initializing webdriver\n",
      "2024-09-23 18:21:43,729 - AInewsbot - INFO - get_driver - 32827 Initializing webdriver\n",
      "2024-09-23 18:21:43,729 - AInewsbot - INFO - get_driver - 32827 Initializing webdriver\n",
      "2024-09-23 18:21:59,573 - AInewsbot - INFO - get_driver - Initialized webdriver profile\n",
      "2024-09-23 18:21:59,574 - AInewsbot - INFO - get_driver - Initialized webdriver service\n",
      "2024-09-23 18:21:59,771 - AInewsbot - INFO - get_driver - Initialized webdriver profile\n",
      "2024-09-23 18:21:59,772 - AInewsbot - INFO - get_driver - Initialized webdriver service\n",
      "2024-09-23 18:22:00,033 - AInewsbot - INFO - get_driver - Initialized webdriver profile\n",
      "2024-09-23 18:22:00,034 - AInewsbot - INFO - get_driver - Initialized webdriver service\n",
      "2024-09-23 18:22:00,242 - AInewsbot - INFO - get_driver - Initialized webdriver profile\n",
      "2024-09-23 18:22:00,243 - AInewsbot - INFO - get_driver - Initialized webdriver service\n",
      "2024-09-23 18:22:30,993 - AInewsbot - INFO - get_driver - Initialized webdriver\n",
      "2024-09-23 18:22:30,998 - AInewsbot - INFO - Processing https://news.google.com/read/CBMijwFBVV95cUxQY0tRMGJuaExMS01mQnNPdzEyeDYzTmtIUnhETWJvcUdnR3pYRmJZNWdFTjRqUUR0cGM1Z0hZWXN3Q2liazE2NGxNSW80ZzFoU1NtRWVMZ0dCeWY5ckdxTWtvWFBzaE9iSk9ZZ0xIcXVBem5rLXBrNndvMHpOZEpDeHpfMHgwcVVhcmVlT1hYMA\n",
      "2024-09-23 18:22:30,999 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMijwFBVV95cUxQY0tRMGJuaExMS01mQnNPdzEyeDYzTmtIUnhETWJvcUdnR3pYRmJZNWdFTjRqUUR0cGM1Z0hZWXN3Q2liazE2NGxNSW80ZzFoU1NtRWVMZ0dCeWY5ckdxTWtvWFBzaE9iSk9ZZ0xIcXVBem5rLXBrNndvMHpOZEpDeHpfMHgwcVVhcmVlT1hYMA) - starting get_url https://news.google.com/read/CBMijwFBVV95cUxQY0tRMGJuaExMS01mQnNPdzEyeDYzTmtIUnhETWJvcUdnR3pYRmJZNWdFTjRqUUR0cGM1Z0hZWXN3Q2liazE2NGxNSW80ZzFoU1NtRWVMZ0dCeWY5ckdxTWtvWFBzaE9iSk9ZZ0xIcXVBem5rLXBrNndvMHpOZEpDeHpfMHgwcVVhcmVlT1hYMA\n",
      "2024-09-23 18:22:34,114 - AInewsbot - INFO - get_driver - Initialized webdriver\n",
      "2024-09-23 18:22:34,140 - AInewsbot - INFO - Processing https://hackernoon.com/how-to-survive-the-ai-apocalypse\n",
      "2024-09-23 18:22:34,142 - AInewsbot - INFO - get_url(https://hackernoon.com/how-to-survive-the-ai-apocalypse) - starting get_url https://hackernoon.com/how-to-survive-the-ai-apocalypse\n",
      "2024-09-23 18:22:38,524 - AInewsbot - INFO - get_driver - Initialized webdriver\n",
      "2024-09-23 18:22:38,552 - AInewsbot - INFO - Processing https://hackernoon.com/exploring-clarity-windows-in-ai-the-unpredictable-moments-of-perceived-consciousness\n",
      "2024-09-23 18:22:38,553 - AInewsbot - INFO - get_url(https://hackernoon.com/exploring-clarity-windows-in-ai-the-unpredictable-moments-of-perceived-consciousness) - starting get_url https://hackernoon.com/exploring-clarity-windows-in-ai-the-unpredictable-moments-of-perceived-consciousness\n",
      "2024-09-23 18:22:41,788 - AInewsbot - INFO - get_driver - Initialized webdriver\n",
      "2024-09-23 18:22:41,813 - AInewsbot - INFO - Processing https://news.google.com/read/CBMikgFBVV95cUxOdlJWckhNWWZLSFk5NEMycGg4SFJ5MEoyWjlURUFRczE5YlFpZUZ3UzNZTzEwVnRwdmhVdkF6Qy1jYlRFNTE0aGVQdE9aR195b2dBOTBOOTVHQ3ZlN01SZmt4dEdoY3AydE5VQllXa1NhbkljaW9tWnZjYTJTZDlBQk95NlhKcklvX0FseXdNZWJ5QQ\n",
      "2024-09-23 18:22:41,817 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMikgFBVV95cUxOdlJWckhNWWZLSFk5NEMycGg4SFJ5MEoyWjlURUFRczE5YlFpZUZ3UzNZTzEwVnRwdmhVdkF6Qy1jYlRFNTE0aGVQdE9aR195b2dBOTBOOTVHQ3ZlN01SZmt4dEdoY3AydE5VQllXa1NhbkljaW9tWnZjYTJTZDlBQk95NlhKcklvX0FseXdNZWJ5QQ) - starting get_url https://news.google.com/read/CBMikgFBVV95cUxOdlJWckhNWWZLSFk5NEMycGg4SFJ5MEoyWjlURUFRczE5YlFpZUZ3UzNZTzEwVnRwdmhVdkF6Qy1jYlRFNTE0aGVQdE9aR195b2dBOTBOOTVHQ3ZlN01SZmt4dEdoY3AydE5VQllXa1NhbkljaW9tWnZjYTJTZDlBQk95NlhKcklvX0FseXdNZWJ5QQ\n",
      "2024-09-23 18:22:42,245 - AInewsbot - INFO - get_url(When robots can't riddle: What puzzles reveal about the depths of our own minds) - Saving When_robots_can_t_riddle__What_puzzles_reveal_about_the_depths_of_our_own_minds_20240923_182242.html as utf-8\n",
      "2024-09-23 18:22:42,247 - AInewsbot - INFO - Processing https://hackernoon.com/the-ai-revolution-reimagining-governance-society-and-human-consciousness-in-the-21st-century\n",
      "2024-09-23 18:22:42,248 - AInewsbot - INFO - get_url(https://hackernoon.com/the-ai-revolution-reimagining-governance-society-and-human-consciousness-in-the-21st-century) - starting get_url https://hackernoon.com/the-ai-revolution-reimagining-governance-society-and-human-consciousness-in-the-21st-century\n",
      "2024-09-23 18:22:45,697 - AInewsbot - INFO - get_url(How to Survive the AI Apocalypse) - Saving How_to_Survive_the_AI_Apocalypse_20240923_182245.html as utf-8\n",
      "2024-09-23 18:22:45,699 - AInewsbot - INFO - Processing https://news.google.com/read/CBMixwFBVV95cUxQLWZDeFZITWFmdzBOTzFCcVNMQmpya0V5Nndybk5ZM0lfaDJyc2taV25MT2tSOWNCWEY4NE40dnFsR0Q3WDR2cnpqTlFVMFVnd1VIMklkeEloc2ZrOTJSTHhZTlF1OXUwR05RR3M3Rm1PY25kUVVsU0xiQlNtYzc0U2dJTDRaUVdSRFNiRzI4c3ZrdHBUN0RqQmZXRzk2VkhuQlhRa3BuRFhBV211TlBWUTlHdEFiSU00aVRWMllZNkU1MFhNaUIw\n",
      "2024-09-23 18:22:45,699 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMixwFBVV95cUxQLWZDeFZITWFmdzBOTzFCcVNMQmpya0V5Nndybk5ZM0lfaDJyc2taV25MT2tSOWNCWEY4NE40dnFsR0Q3WDR2cnpqTlFVMFVnd1VIMklkeEloc2ZrOTJSTHhZTlF1OXUwR05RR3M3Rm1PY25kUVVsU0xiQlNtYzc0U2dJTDRaUVdSRFNiRzI4c3ZrdHBUN0RqQmZXRzk2VkhuQlhRa3BuRFhBV211TlBWUTlHdEFiSU00aVRWMllZNkU1MFhNaUIw) - starting get_url https://news.google.com/read/CBMixwFBVV95cUxQLWZDeFZITWFmdzBOTzFCcVNMQmpya0V5Nndybk5ZM0lfaDJyc2taV25MT2tSOWNCWEY4NE40dnFsR0Q3WDR2cnpqTlFVMFVnd1VIMklkeEloc2ZrOTJSTHhZTlF1OXUwR05RR3M3Rm1PY25kUVVsU0xiQlNtYzc0U2dJTDRaUVdSRFNiRzI4c3ZrdHBUN0RqQmZXRzk2VkhuQlhRa3BuRFhBV211TlBWUTlHdEFiSU00aVRWMllZNkU1MFhNaUIw\n",
      "2024-09-23 18:22:50,018 - AInewsbot - INFO - get_url(Exploring \"Clarity Windows\" in AI: The Unpredictable Moments of Perceived Consciousness) - Saving Exploring__Clarity_Windows__in_AI__The_Unpredictable_Moments_of_Perceived_Consciousness_20240923_182250.html as utf-8\n",
      "2024-09-23 18:22:50,020 - AInewsbot - INFO - Processing https://news.google.com/read/CBMioAFBVV95cUxNOUxxM0p1dnlhSGotLVQwX2JJYzhCUE9obnFtTWprczNFVkxwYnZFN1dYTktCaTBtQ2RZRWhjUVYwb3huQlRELXc0UnNrc0UxcGc3UXdpd1RjVThaRVpLX3RsUmlmdVlWTUlGM1BqMEhOcG1XZXZyMGk0RHBEazFhemNSSXI1eEp1ZDhma1VtQUpmQjJabm5GRjE2WTh4UWx1\n",
      "2024-09-23 18:22:50,020 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMioAFBVV95cUxNOUxxM0p1dnlhSGotLVQwX2JJYzhCUE9obnFtTWprczNFVkxwYnZFN1dYTktCaTBtQ2RZRWhjUVYwb3huQlRELXc0UnNrc0UxcGc3UXdpd1RjVThaRVpLX3RsUmlmdVlWTUlGM1BqMEhOcG1XZXZyMGk0RHBEazFhemNSSXI1eEp1ZDhma1VtQUpmQjJabm5GRjE2WTh4UWx1) - starting get_url https://news.google.com/read/CBMioAFBVV95cUxNOUxxM0p1dnlhSGotLVQwX2JJYzhCUE9obnFtTWprczNFVkxwYnZFN1dYTktCaTBtQ2RZRWhjUVYwb3huQlRELXc0UnNrc0UxcGc3UXdpd1RjVThaRVpLX3RsUmlmdVlWTUlGM1BqMEhOcG1XZXZyMGk0RHBEazFhemNSSXI1eEp1ZDhma1VtQUpmQjJabm5GRjE2WTh4UWx1\n",
      "2024-09-23 18:22:52,936 - AInewsbot - INFO - get_url(AI Uprising: Can Machines Really Outthink Humans?) - Saving AI_Uprising__Can_Machines_Really_Outthink_Humans__20240923_182252.html as utf-8\n",
      "2024-09-23 18:22:52,939 - AInewsbot - INFO - Processing https://news.google.com/read/CBMiXEFVX3lxTE1Va09UVC1iUWM2cDRJX21qMlMxNnZoRlo2NVRheDBtZnhvcXliWjI0cUZjdXJ0bE9BU252MUszRVZlVzBJYjFlYjNHbEx2TUR6dW1FWjRTeWg2OWtV0gFiQVVfeXFMUGpIOXQzUUxuSGljUjhvUENWX05TQzRnT0RrQnl4UFdxSzEtNTFQWDhhbE40azFodTdGUjNnTmFiSVRUWVhjR1dCQU4zYTc2V0dBNFdZcE92elQzUFNCNkY3enc\n",
      "2024-09-23 18:22:52,939 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMiXEFVX3lxTE1Va09UVC1iUWM2cDRJX21qMlMxNnZoRlo2NVRheDBtZnhvcXliWjI0cUZjdXJ0bE9BU252MUszRVZlVzBJYjFlYjNHbEx2TUR6dW1FWjRTeWg2OWtV0gFiQVVfeXFMUGpIOXQzUUxuSGljUjhvUENWX05TQzRnT0RrQnl4UFdxSzEtNTFQWDhhbE40azFodTdGUjNnTmFiSVRUWVhjR1dCQU4zYTc2V0dBNFdZcE92elQzUFNCNkY3enc) - starting get_url https://news.google.com/read/CBMiXEFVX3lxTE1Va09UVC1iUWM2cDRJX21qMlMxNnZoRlo2NVRheDBtZnhvcXliWjI0cUZjdXJ0bE9BU252MUszRVZlVzBJYjFlYjNHbEx2TUR6dW1FWjRTeWg2OWtV0gFiQVVfeXFMUGpIOXQzUUxuSGljUjhvUENWX05TQzRnT0RrQnl4UFdxSzEtNTFQWDhhbE40azFodTdGUjNnTmFiSVRUWVhjR1dCQU4zYTc2V0dBNFdZcE92elQzUFNCNkY3enc\n",
      "2024-09-23 18:22:53,580 - AInewsbot - INFO - get_url(The AI Revolution: Reimagining Governance, Society, and Human Consciousness in the 21st Century) - Saving The_AI_Revolution__Reimagining_Governance__Society__and_Human_Consciousness_in_the_21st_Century_20240923_182253.html as utf-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:22:53,582 - AInewsbot - INFO - Processing https://news.google.com/read/CBMikwFBVV95cUxQa1ZKYlNCdl9IYXkyMDhPTFlVeGJEWVhlT2YwWFFkTUxqVmF3REEyRmFIcWRieVQzQ2dEWEpzOHZ3MEk4UjhlWnh5RXJycjlNbGNtdm5QN0h0V0tTalcwdlVvYTA2bzlOMFc5b1dIbFc0cmVrMmhEZmkzaHlZSDRCTFFpWTBNSUdBVnhKZFRCQkdRanM\n",
      "2024-09-23 18:22:53,582 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMikwFBVV95cUxQa1ZKYlNCdl9IYXkyMDhPTFlVeGJEWVhlT2YwWFFkTUxqVmF3REEyRmFIcWRieVQzQ2dEWEpzOHZ3MEk4UjhlWnh5RXJycjlNbGNtdm5QN0h0V0tTalcwdlVvYTA2bzlOMFc5b1dIbFc0cmVrMmhEZmkzaHlZSDRCTFFpWTBNSUdBVnhKZFRCQkdRanM) - starting get_url https://news.google.com/read/CBMikwFBVV95cUxQa1ZKYlNCdl9IYXkyMDhPTFlVeGJEWVhlT2YwWFFkTUxqVmF3REEyRmFIcWRieVQzQ2dEWEpzOHZ3MEk4UjhlWnh5RXJycjlNbGNtdm5QN0h0V0tTalcwdlVvYTA2bzlOMFc5b1dIbFc0cmVrMmhEZmkzaHlZSDRCTFFpWTBNSUdBVnhKZFRCQkdRanM\n",
      "2024-09-23 18:22:56,559 - AInewsbot - INFO - get_url(Andy Serkis says screen industries should embrace AI at Labour party conference) - Saving Andy_Serkis_says_screen_industries_should_embrace_AI_at_Labour_party_conference_20240923_182256.html as utf-8\n",
      "2024-09-23 18:22:56,561 - AInewsbot - INFO - Processing https://www.reddit.com/r/ChatGPT/comments/1fn7t3e/chatgpt_was_like_miss_me_with_that_sh/\n",
      "2024-09-23 18:22:56,561 - AInewsbot - INFO - get_url(https://www.reddit.com/r/ChatGPT/comments/1fn7t3e/chatgpt_was_like_miss_me_with_that_sh/) - starting get_url https://www.reddit.com/r/ChatGPT/comments/1fn7t3e/chatgpt_was_like_miss_me_with_that_sh/\n",
      "2024-09-23 18:23:00,811 - AInewsbot - INFO - get_url(Andy Serkis Teases New Project Featuring AI Characters) - Saving Andy_Serkis_Teases_New_Project_Featuring_AI_Characters_20240923_182300.html as utf-8\n",
      "2024-09-23 18:23:00,815 - AInewsbot - INFO - Processing https://www.reddit.com/r/ChatGPT/comments/1fndqmq/the_following_chatgpt_prompt_guidance_that/\n",
      "2024-09-23 18:23:00,822 - AInewsbot - INFO - get_url(https://www.reddit.com/r/ChatGPT/comments/1fndqmq/the_following_chatgpt_prompt_guidance_that/) - starting get_url https://www.reddit.com/r/ChatGPT/comments/1fndqmq/the_following_chatgpt_prompt_guidance_that/\n",
      "2024-09-23 18:23:03,364 - AInewsbot - INFO - get_url(Andy Serkis teases his next project, which will feature AI characters) - Saving Andy_Serkis_teases_his_next_project__which_will_feature_AI_characters_20240923_182303.html as utf-8\n",
      "2024-09-23 18:23:03,367 - AInewsbot - INFO - Processing https://www.reddit.com/r/ChatGPT/comments/1fnlfdd/chat_gpt_orgasmic_groans/\n",
      "2024-09-23 18:23:03,370 - AInewsbot - INFO - get_url(https://www.reddit.com/r/ChatGPT/comments/1fnlfdd/chat_gpt_orgasmic_groans/) - starting get_url https://www.reddit.com/r/ChatGPT/comments/1fnlfdd/chat_gpt_orgasmic_groans/\n",
      "2024-09-23 18:23:03,919 - AInewsbot - INFO - get_url(Andy Serkis Thinks AI Is 'Magic') - Saving Andy_Serkis_Thinks_AI_Is__Magic__20240923_182303.html as utf-8\n",
      "2024-09-23 18:23:03,921 - AInewsbot - INFO - Processing https://www.reddit.com/r/ChatGPT/comments/1fnng20/i_love_chatgpt/\n",
      "2024-09-23 18:23:03,923 - AInewsbot - INFO - get_url(https://www.reddit.com/r/ChatGPT/comments/1fnng20/i_love_chatgpt/) - starting get_url https://www.reddit.com/r/ChatGPT/comments/1fnng20/i_love_chatgpt/\n",
      "2024-09-23 18:23:07,544 - AInewsbot - INFO - get_url(ChatGPT was like \"miss me with that sh**) - Saving ChatGPT_was_like__miss_me_with_that_sh___20240923_182307.html as utf-8\n",
      "2024-09-23 18:23:07,545 - AInewsbot - INFO - Processing https://news.google.com/read/CBMidEFVX3lxTE5lNU1maURqZTVENExBN1RNcVVIVVRZUjYwbWdYQ0R3OWlLVy14RXBHVm1SU0t2emdRUU5mejRQbkVDWFpNRm4wa2VxS2tOWFg4Rnl2dkdCaHllYm1OdnItQWdjTm0wbnNqSDFqcG1GRlJwWGxM\n",
      "2024-09-23 18:23:07,546 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMidEFVX3lxTE5lNU1maURqZTVENExBN1RNcVVIVVRZUjYwbWdYQ0R3OWlLVy14RXBHVm1SU0t2emdRUU5mejRQbkVDWFpNRm4wa2VxS2tOWFg4Rnl2dkdCaHllYm1OdnItQWdjTm0wbnNqSDFqcG1GRlJwWGxM) - starting get_url https://news.google.com/read/CBMidEFVX3lxTE5lNU1maURqZTVENExBN1RNcVVIVVRZUjYwbWdYQ0R3OWlLVy14RXBHVm1SU0t2emdRUU5mejRQbkVDWFpNRm4wa2VxS2tOWFg4Rnl2dkdCaHllYm1OdnItQWdjTm0wbnNqSDFqcG1GRlJwWGxM\n",
      "2024-09-23 18:23:12,242 - AInewsbot - INFO - get_url(The following ChatGPT prompt guidance that produced Mini Corgi Surfers) - Saving The_following_ChatGPT_prompt_guidance_that_produced_Mini_Corgi_Surfers_20240923_182312.html as utf-8\n",
      "2024-09-23 18:23:12,244 - AInewsbot - INFO - Processing https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/\n",
      "2024-09-23 18:23:12,245 - AInewsbot - INFO - get_url(https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/) - starting get_url https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/\n",
      "2024-09-23 18:23:14,971 - AInewsbot - INFO - get_url(Chat GPT Orgasmic Groans) - Saving Chat_GPT_Orgasmic_Groans_20240923_182314.html as utf-8\n",
      "2024-09-23 18:23:14,973 - AInewsbot - INFO - Processing https://www.wired.com/story/cloudflare-tools-detect-block-ai-bots/\n",
      "2024-09-23 18:23:14,973 - AInewsbot - INFO - get_url(https://www.wired.com/story/cloudflare-tools-detect-block-ai-bots/) - starting get_url https://www.wired.com/story/cloudflare-tools-detect-block-ai-bots/\n",
      "2024-09-23 18:23:15,300 - AInewsbot - INFO - get_url(I love ChatGPT) - Saving I_love_ChatGPT_20240923_182315.html as utf-8\n",
      "2024-09-23 18:23:15,302 - AInewsbot - INFO - Processing https://arstechnica.com/tech-policy/2024/09/cloudflare-lets-sites-block-ai-crawlers-with-one-click/\n",
      "2024-09-23 18:23:15,302 - AInewsbot - INFO - get_url(https://arstechnica.com/tech-policy/2024/09/cloudflare-lets-sites-block-ai-crawlers-with-one-click/) - starting get_url https://arstechnica.com/tech-policy/2024/09/cloudflare-lets-sites-block-ai-crawlers-with-one-click/\n",
      "2024-09-23 18:23:17,843 - AInewsbot - INFO - get_url(New Cloudflare Tools Let Sites Detect and Block AI Bots for Free) - Saving New_Cloudflare_Tools_Let_Sites_Detect_and_Block_AI_Bots_for_Free_20240923_182317.html as utf-8\n",
      "2024-09-23 18:23:17,844 - AInewsbot - INFO - Processing https://news.google.com/read/CBMigAFBVV95cUxOQjNad0c2NTdMTTdNQVhHZ1laNkM1MUhmZ3Y1N2cyUmJpakJBalpiSUxSb0ZTNDh6SFJUYzFuWjhMQzlFLVZDdGJHWXhLOFhFS3dVQy1hWi16UWEtU25iV0VyMHR2YmRUYTJ6SXExa2U0ck5MRmZCdDJoUWhaN2d6Yw\n",
      "2024-09-23 18:23:17,844 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMigAFBVV95cUxOQjNad0c2NTdMTTdNQVhHZ1laNkM1MUhmZ3Y1N2cyUmJpakJBalpiSUxSb0ZTNDh6SFJUYzFuWjhMQzlFLVZDdGJHWXhLOFhFS3dVQy1hWi16UWEtU25iV0VyMHR2YmRUYTJ6SXExa2U0ck5MRmZCdDJoUWhaN2d6Yw) - starting get_url https://news.google.com/read/CBMigAFBVV95cUxOQjNad0c2NTdMTTdNQVhHZ1laNkM1MUhmZ3Y1N2cyUmJpakJBalpiSUxSb0ZTNDh6SFJUYzFuWjhMQzlFLVZDdGJHWXhLOFhFS3dVQy1hWi16UWEtU25iV0VyMHR2YmRUYTJ6SXExa2U0ck5MRmZCdDJoUWhaN2d6Yw\n",
      "2024-09-23 18:23:24,703 - AInewsbot - INFO - get_url(Cloudflare's new marketplace lets websites charge AI bots for scraping) - Saving Cloudflare_s_new_marketplace_lets_websites_charge_AI_bots_for_scraping_20240923_182324.html as utf-8\n",
      "2024-09-23 18:23:24,704 - AInewsbot - INFO - Processing https://news.google.com/read/CBMigAFBVV95cUxNeVNjdENpTE1uTXhQdmRpTHBjQld1dl8tUjFFTmhnYWxkUGx4dzBNbHRkZF9sOVg1NnR5NEx1OVJMS0VSZlZNZWR5ajcyM1NYQUdVNWpPNS14Q0JyeDRaUHh1T2JIajd1bmtQeDRuSlozNHZtcG1neUhybnBxcjFFdNIBd0FVX3lxTE41ZkZBRTZ2VHdodl9vQmlBSE01N0lUU1E4Q0g5Yk9kLW9OSmozcXdVUTM3ck5Ma1Y3eFdlUWo2emhvc0lXbHR2aHRraHRfamtGeEFHRHBkcUMzci1udms3YVZGa0NyLXI1ZGtPanFiY2RzZWJGQXRZ\n",
      "2024-09-23 18:23:24,704 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMigAFBVV95cUxNeVNjdENpTE1uTXhQdmRpTHBjQld1dl8tUjFFTmhnYWxkUGx4dzBNbHRkZF9sOVg1NnR5NEx1OVJMS0VSZlZNZWR5ajcyM1NYQUdVNWpPNS14Q0JyeDRaUHh1T2JIajd1bmtQeDRuSlozNHZtcG1neUhybnBxcjFFdNIBd0FVX3lxTE41ZkZBRTZ2VHdodl9vQmlBSE01N0lUU1E4Q0g5Yk9kLW9OSmozcXdVUTM3ck5Ma1Y3eFdlUWo2emhvc0lXbHR2aHRraHRfamtGeEFHRHBkcUMzci1udms3YVZGa0NyLXI1ZGtPanFiY2RzZWJGQXRZ) - starting get_url https://news.google.com/read/CBMigAFBVV95cUxNeVNjdENpTE1uTXhQdmRpTHBjQld1dl8tUjFFTmhnYWxkUGx4dzBNbHRkZF9sOVg1NnR5NEx1OVJMS0VSZlZNZWR5ajcyM1NYQUdVNWpPNS14Q0JyeDRaUHh1T2JIajd1bmtQeDRuSlozNHZtcG1neUhybnBxcjFFdNIBd0FVX3lxTE41ZkZBRTZ2VHdodl9vQmlBSE01N0lUU1E4Q0g5Yk9kLW9OSmozcXdVUTM3ck5Ma1Y3eFdlUWo2emhvc0lXbHR2aHRraHRfamtGeEFHRHBkcUMzci1udms3YVZGa0NyLXI1ZGtPanFiY2RzZWJGQXRZ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:23:25,956 - AInewsbot - INFO - get_url(Cloudflare rolls out Bot Management, a suite of free AI auditing tools meant to help monitor and selectively block AI data-scraping bots, to all its customers) - Saving Cloudflare_rolls_out_Bot_Management__a_suite_of_free_AI_auditing_tools_meant_to_help_monitor_and_selectively_block_AI_data-scraping_bots__to_all_its_customers_20240923_182325.html as utf-8\n",
      "2024-09-23 18:23:25,957 - AInewsbot - INFO - Processing https://news.google.com/read/CBMiiwFBVV95cUxOSzNUbjZHTEpyUC02Yzg2OERvQ0kwcWhyLXh4TUUzSG16QTdGT2g3bERNNElMdmtIaTZOME5QaFdxSjJ4cEhEVWV0NlM1aUFyVGpWMVpzbFRfYW05azBUYTUwbmdSUjBMcDZKVjFsNHJ6ckw5bFJlWUtyTERVRWEtSW1aYWhLa1M0bGQ4\n",
      "2024-09-23 18:23:25,958 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMiiwFBVV95cUxOSzNUbjZHTEpyUC02Yzg2OERvQ0kwcWhyLXh4TUUzSG16QTdGT2g3bERNNElMdmtIaTZOME5QaFdxSjJ4cEhEVWV0NlM1aUFyVGpWMVpzbFRfYW05azBUYTUwbmdSUjBMcDZKVjFsNHJ6ckw5bFJlWUtyTERVRWEtSW1aYWhLa1M0bGQ4) - starting get_url https://news.google.com/read/CBMiiwFBVV95cUxOSzNUbjZHTEpyUC02Yzg2OERvQ0kwcWhyLXh4TUUzSG16QTdGT2g3bERNNElMdmtIaTZOME5QaFdxSjJ4cEhEVWV0NlM1aUFyVGpWMVpzbFRfYW05azBUYTUwbmdSUjBMcDZKVjFsNHJ6ckw5bFJlWUtyTERVRWEtSW1aYWhLa1M0bGQ4\n",
      "2024-09-23 18:23:27,893 - AInewsbot - INFO - get_url(Cloudflare moves to end free, endless AI scraping with one-click blocking) - Saving Cloudflare_moves_to_end_free__endless_AI_scraping_with_one-click_blocking_20240923_182327.html as utf-8\n",
      "2024-09-23 18:23:27,895 - AInewsbot - INFO - Processing https://news.google.com/read/CBMilAFBVV95cUxOYnExQzR6c2FpYTFNNlFsdWRYOGZZWGRFdGhERmtBc1lvUkN1Z1dlM0p0cjZ0b2otZU1Ccmk2YjhWVnBtM0ZvRHFpRVFSb181b1FIeS1QUGJncThuaEFELWMxd2pRRDJjNWZ0enI1OHZkenFLbnZvZVJzWjA3by1teGg4am9pT1pYeWk4ZlE5UmdJTDZo\n",
      "2024-09-23 18:23:27,896 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMilAFBVV95cUxOYnExQzR6c2FpYTFNNlFsdWRYOGZZWGRFdGhERmtBc1lvUkN1Z1dlM0p0cjZ0b2otZU1Ccmk2YjhWVnBtM0ZvRHFpRVFSb181b1FIeS1QUGJncThuaEFELWMxd2pRRDJjNWZ0enI1OHZkenFLbnZvZVJzWjA3by1teGg4am9pT1pYeWk4ZlE5UmdJTDZo) - starting get_url https://news.google.com/read/CBMilAFBVV95cUxOYnExQzR6c2FpYTFNNlFsdWRYOGZZWGRFdGhERmtBc1lvUkN1Z1dlM0p0cjZ0b2otZU1Ccmk2YjhWVnBtM0ZvRHFpRVFSb181b1FIeS1QUGJncThuaEFELWMxd2pRRDJjNWZ0enI1OHZkenFLbnZvZVJzWjA3by1teGg4am9pT1pYeWk4ZlE5UmdJTDZo\n",
      "2024-09-23 18:23:28,207 - AInewsbot - INFO - get_url(Cloudflare is arming content creators with free weapons in the battle against AI bot crawlers) - Saving Cloudflare_is_arming_content_creators_with_free_weapons_in_the_battle_against_AI_bot_crawlers_20240923_182328.html as utf-8\n",
      "2024-09-23 18:23:28,208 - AInewsbot - INFO - Processing https://www.stltoday.com/life-entertainment/nation-world/technology/social-media-ai-training-how-to-opt-out/article_0939bcbb-b218-5641-8e40-3768776ed7fa.html\n",
      "2024-09-23 18:23:28,209 - AInewsbot - INFO - get_url(https://www.stltoday.com/life-entertainment/nation-world/technology/social-media-ai-training-how-to-opt-out/article_0939bcbb-b218-5641-8e40-3768776ed7fa.html) - starting get_url https://www.stltoday.com/life-entertainment/nation-world/technology/social-media-ai-training-how-to-opt-out/article_0939bcbb-b218-5641-8e40-3768776ed7fa.html\n",
      "2024-09-23 18:23:35,364 - AInewsbot - INFO - get_url(Social media platforms are using what you create for artificial intelligence. Heres how to opt out) - Saving Social_media_platforms_are_using_what_you_create_for_artificial_intelligence__Heres_how_to_opt_out_20240923_182335.html as utf-8\n",
      "2024-09-23 18:23:35,372 - AInewsbot - INFO - Processing https://techcrunch.com/2024/09/23/sam-altman-catapults-past-founder-mode-into-god-mode-with-latest-ai-post/\n",
      "2024-09-23 18:23:35,372 - AInewsbot - INFO - get_url(https://techcrunch.com/2024/09/23/sam-altman-catapults-past-founder-mode-into-god-mode-with-latest-ai-post/) - starting get_url https://techcrunch.com/2024/09/23/sam-altman-catapults-past-founder-mode-into-god-mode-with-latest-ai-post/\n",
      "2024-09-23 18:23:36,393 - AInewsbot - INFO - get_url(LinkedIn, Facebook, and Instagram are hoovering up your data to train their AI. Heres how to stop it) - Saving LinkedIn__Facebook__and_Instagram_are_hoovering_up_your_data_to_train_their_AI__Heres_how_to_stop_it_20240923_182336.html as utf-8\n",
      "2024-09-23 18:23:36,395 - AInewsbot - INFO - Processing https://venturebeat.com/ai/openai-ceo-sam-altman-anticipates-superintelligence-soon-defends-ai-in-rare-personal-blog-post/\n",
      "2024-09-23 18:23:36,396 - AInewsbot - INFO - get_url(https://venturebeat.com/ai/openai-ceo-sam-altman-anticipates-superintelligence-soon-defends-ai-in-rare-personal-blog-post/) - starting get_url https://venturebeat.com/ai/openai-ceo-sam-altman-anticipates-superintelligence-soon-defends-ai-in-rare-personal-blog-post/\n",
      "2024-09-23 18:23:38,365 - AInewsbot - INFO - get_url(LinkedIn is training AI on you  unless you opt out with this setting) - Saving LinkedIn_is_training_AI_on_you__unless_you_opt_out_with_this_setting_20240923_182338.html as utf-8\n",
      "2024-09-23 18:23:38,367 - AInewsbot - INFO - Processing https://news.google.com/read/CBMipwFBVV95cUxOUkZ5TEVlemRCMzFCaWhFTkVSS0lVT0o1U2pCT2syYlZDbGJnSmhQWkhKMjlEZHhJcEZjT0w5WVdudE5UOUdqdWVGbkZ1N3MwVGNxTEZVMHphN0pwb2RjT2ZVSk5KVzFOU0d3TEFBcWgzdC1XcUVMTlo0UjFqbE5Fd0JaMEc3aHZiZ1U5MGZFblNSak5LWW16UmIwVS1uWmo4aFltQllsVQ\n",
      "2024-09-23 18:23:38,367 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMipwFBVV95cUxOUkZ5TEVlemRCMzFCaWhFTkVSS0lVT0o1U2pCT2syYlZDbGJnSmhQWkhKMjlEZHhJcEZjT0w5WVdudE5UOUdqdWVGbkZ1N3MwVGNxTEZVMHphN0pwb2RjT2ZVSk5KVzFOU0d3TEFBcWgzdC1XcUVMTlo0UjFqbE5Fd0JaMEc3aHZiZ1U5MGZFblNSak5LWW16UmIwVS1uWmo4aFltQllsVQ) - starting get_url https://news.google.com/read/CBMipwFBVV95cUxOUkZ5TEVlemRCMzFCaWhFTkVSS0lVT0o1U2pCT2syYlZDbGJnSmhQWkhKMjlEZHhJcEZjT0w5WVdudE5UOUdqdWVGbkZ1N3MwVGNxTEZVMHphN0pwb2RjT2ZVSk5KVzFOU0d3TEFBcWgzdC1XcUVMTlo0UjFqbE5Fd0JaMEc3aHZiZ1U5MGZFblNSak5LWW16UmIwVS1uWmo4aFltQllsVQ\n",
      "2024-09-23 18:23:40,040 - AInewsbot - INFO - get_url(Social media platforms are using what you create for AI. Heres how to opt out) - Saving Social_media_platforms_are_using_what_you_create_for_AI__Heres_how_to_opt_out_20240923_182340.html as utf-8\n",
      "2024-09-23 18:23:40,041 - AInewsbot - INFO - Processing https://www.zdnet.com/article/some-of-siris-long-awaited-ai-enhancements-could-reach-users-by-january/#ftag=RSSbaffb68\n",
      "2024-09-23 18:23:40,041 - AInewsbot - INFO - get_url(https://www.zdnet.com/article/some-of-siris-long-awaited-ai-enhancements-could-reach-users-by-january/#ftag=RSSbaffb68) - starting get_url https://www.zdnet.com/article/some-of-siris-long-awaited-ai-enhancements-could-reach-users-by-january/#ftag=RSSbaffb68\n",
      "2024-09-23 18:23:46,617 - AInewsbot - INFO - get_url(Sam Altman catapults past founder mode into god mode with latest AI post) - Saving Sam_Altman_catapults_past_founder_mode_into_god_mode_with_latest_AI_post_20240923_182346.html as utf-8\n",
      "2024-09-23 18:23:46,619 - AInewsbot - INFO - Processing https://gizmodo.com/siri-may-not-get-its-apple-intelligence-update-until-january-2025-2000502076\n",
      "2024-09-23 18:23:46,619 - AInewsbot - INFO - get_url(https://gizmodo.com/siri-may-not-get-its-apple-intelligence-update-until-january-2025-2000502076) - starting get_url https://gizmodo.com/siri-may-not-get-its-apple-intelligence-update-until-january-2025-2000502076\n",
      "2024-09-23 18:23:46,847 - AInewsbot - INFO - get_url(OpenAI CEO Sam Altman anticipates superintelligence soon, defends AI in rare personal blog post) - Saving OpenAI_CEO_Sam_Altman_anticipates_superintelligence_soon__defends_AI_in_rare_personal_blog_post_20240923_182346.html as utf-8\n",
      "2024-09-23 18:23:46,848 - AInewsbot - INFO - Processing https://news.google.com/read/CBMi1wFBVV95cUxQT1J2Y1RNRC1CWm5aYW1sTG1Cai1tUWZ6bTRRZEV2eFViaURSZWp3d09Da0ZsZTN6dkhaZ0hyZjZ5RmE4S3Z1dWRpVFdMZHAwbUl5alRZU1pxdjJ2WkRaX0VOOWNwWF9DZEJ6dVYyYWlaaHM4cXhORXdYM2tab1VtVm9tUTZ6RmFZSGRwQk9yUE94YWZDeDR2blExQ3Y1OENEaVd2RTh0dDBvSG4wQWZVUS1ZcTZqd1I4cXFJTlBvUWxxQTIxQUpKTVUyeXpCbWlRZ1FmNVdqYw\n",
      "2024-09-23 18:23:46,848 - AInewsbot - INFO - get_url(https://news.google.com/read/CBMi1wFBVV95cUxQT1J2Y1RNRC1CWm5aYW1sTG1Cai1tUWZ6bTRRZEV2eFViaURSZWp3d09Da0ZsZTN6dkhaZ0hyZjZ5RmE4S3Z1dWRpVFdMZHAwbUl5alRZU1pxdjJ2WkRaX0VOOWNwWF9DZEJ6dVYyYWlaaHM4cXhORXdYM2tab1VtVm9tUTZ6RmFZSGRwQk9yUE94YWZDeDR2blExQ3Y1OENEaVd2RTh0dDBvSG4wQWZVUS1ZcTZqd1I4cXFJTlBvUWxxQTIxQUpKTVUyeXpCbWlRZ1FmNVdqYw) - starting get_url https://news.google.com/read/CBMi1wFBVV95cUxQT1J2Y1RNRC1CWm5aYW1sTG1Cai1tUWZ6bTRRZEV2eFViaURSZWp3d09Da0ZsZTN6dkhaZ0hyZjZ5RmE4S3Z1dWRpVFdMZHAwbUl5alRZU1pxdjJ2WkRaX0VOOWNwWF9DZEJ6dVYyYWlaaHM4cXhORXdYM2tab1VtVm9tUTZ6RmFZSGRwQk9yUE94YWZDeDR2blExQ3Y1OENEaVd2RTh0dDBvSG4wQWZVUS1ZcTZqd1I4cXFJTlBvUWxxQTIxQUpKTVUyeXpCbWlRZ1FmNVdqYw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:23:48,920 - AInewsbot - INFO - get_url(Sam Altman may be in his villain era, but no one seems to care) - Saving Sam_Altman_may_be_in_his_villain_era__but_no_one_seems_to_care_20240923_182348.html as utf-8\n",
      "2024-09-23 18:23:48,921 - AInewsbot - INFO - Quit webdriver\n",
      "2024-09-23 18:23:51,198 - AInewsbot - INFO - 7 pages saved\n",
      "2024-09-23 18:23:51,625 - AInewsbot - INFO - get_url(Some of Siri's long-awaited AI enhancements could reach users by January) - Saving Some_of_Siri_s_long-awaited_AI_enhancements_could_reach_users_by_January_20240923_182351.html as utf-8\n",
      "2024-09-23 18:23:51,627 - AInewsbot - INFO - Quit webdriver\n",
      "2024-09-23 18:23:53,728 - AInewsbot - INFO - 7 pages saved\n",
      "2024-09-23 18:23:57,150 - AInewsbot - INFO - get_url(Siri May Not Get Its Apple Intelligence Update Until January 2025) - Saving Siri_May_Not_Get_Its_Apple_Intelligence_Update_Until_January_2025_20240923_182357.html as utf-8\n",
      "2024-09-23 18:23:57,151 - AInewsbot - INFO - Quit webdriver\n",
      "2024-09-23 18:23:57,256 - AInewsbot - INFO - get_url(The 5 best Apple Intelligence tools you can try right now in iOS 18.1 public beta) - Saving The_5_best_Apple_Intelligence_tools_you_can_try_right_now_in_iOS_18_1_public_beta_20240923_182357.html as utf-8\n",
      "2024-09-23 18:23:57,257 - AInewsbot - INFO - Quit webdriver\n",
      "2024-09-23 18:23:59,859 - AInewsbot - INFO - 7 pages saved\n",
      "2024-09-23 18:24:00,166 - AInewsbot - INFO - 7 pages saved\n",
      "2024-09-23 18:24:00,167 - AInewsbot - INFO - returned 28\n"
     ]
    }
   ],
   "source": [
    "# scrape individual pages\n",
    "def fn_download_pages(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Uses several Selenium browser sessions to download all the pages referenced in the\n",
    "    state[\"AIdf\"] DataFrame and store their pathnames.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state of the agent.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: The updated state of the agent with the downloaded pages' pathnames stored in the `state[\"AIdf\"]` DataFrame.\n",
    "    \"\"\"\n",
    "    log(\"Queuing URLs for scraping\")\n",
    "    AIdf = pd.DataFrame(state['AIdf'])\n",
    "    queue = multiprocessing.Queue()\n",
    "\n",
    "    count = 0\n",
    "    for row in AIdf.itertuples():\n",
    "        if row.cluster < 999:\n",
    "            queue.put((row.id, row.url, row.title))\n",
    "            count +=1\n",
    "    # scrape urls in queue asynchronously\n",
    "    num_browsers = 4\n",
    "\n",
    "    callable = process_url_queue_factory(queue)\n",
    "\n",
    "    log(f\"fetching {count} pages using {num_browsers} browsers\")\n",
    "    saved_pages = launch_drivers(num_browsers, callable)\n",
    "\n",
    "    pages_df = pd.DataFrame(saved_pages)\n",
    "    if len(pages_df):\n",
    "        pages_df.columns = ['id', 'url', 'title', 'path']\n",
    "\n",
    "        try: # for idempotency\n",
    "            AIdf = AIdf.drop(columns=['path'])\n",
    "        except:\n",
    "            pass        \n",
    "        AIdf = pd.merge(AIdf, pages_df[[\"id\", \"path\"]], on='id', how=\"inner\")\n",
    "    state[\"AIdf\"] = AIdf.to_dict()\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    _ = fn_download_pages(test_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c151fdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>src</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>isAI</th>\n",
       "      <th>actual_url</th>\n",
       "      <th>hostname</th>\n",
       "      <th>site_name</th>\n",
       "      <th>sort_order</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>topic_str</th>\n",
       "      <th>title_topic_str</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Google News</td>\n",
       "      <td>When robots can't riddle: What puzzles reveal ...</td>\n",
       "      <td>https://news.google.com/read/CBMijwFBVV95cUxQY...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMijwFBVV95cUxQY...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Artificial Intelligence and Human Cognition</td>\n",
       "      <td>Artificial General Intelligence, Cognition, Co...</td>\n",
       "      <td>When robots can't riddle: What puzzles reveal ...</td>\n",
       "      <td>htmlpages/When_robots_can_t_riddle__What_puzzl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>How to Survive the AI Apocalypse</td>\n",
       "      <td>https://hackernoon.com/how-to-survive-the-ai-a...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://hackernoon.com/how-to-survive-the-ai-a...</td>\n",
       "      <td>hackernoon.com</td>\n",
       "      <td>Hacker Noon</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Artificial Intelligence and Human Cognition</td>\n",
       "      <td>AI Doom, Apocalypse, Future, Gen AI, Safety An...</td>\n",
       "      <td>How to Survive the AI Apocalypse (Topics: AI D...</td>\n",
       "      <td>htmlpages/How_to_Survive_the_AI_Apocalypse_202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>Exploring \"Clarity Windows\" in AI: The Unpredi...</td>\n",
       "      <td>https://hackernoon.com/exploring-clarity-windo...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://hackernoon.com/exploring-clarity-windo...</td>\n",
       "      <td>hackernoon.com</td>\n",
       "      <td>Hacker Noon</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Artificial Intelligence and Human Cognition</td>\n",
       "      <td>Artificial General Intelligence, Clarity Windo...</td>\n",
       "      <td>Exploring \"Clarity Windows\" in AI: The Unpredi...</td>\n",
       "      <td>htmlpages/Exploring__Clarity_Windows__in_AI__T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Google News</td>\n",
       "      <td>AI Uprising: Can Machines Really Outthink Humans?</td>\n",
       "      <td>https://news.google.com/read/CBMikgFBVV95cUxOd...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMikgFBVV95cUxOd...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Artificial Intelligence and Human Cognition</td>\n",
       "      <td>AI Doom, Artificial General Intelligence, Cogn...</td>\n",
       "      <td>AI Uprising: Can Machines Really Outthink Huma...</td>\n",
       "      <td>htmlpages/AI_Uprising__Can_Machines_Really_Out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>The AI Revolution: Reimagining Governance, Soc...</td>\n",
       "      <td>https://hackernoon.com/the-ai-revolution-reima...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://hackernoon.com/the-ai-revolution-reima...</td>\n",
       "      <td>hackernoon.com</td>\n",
       "      <td>Hacker Noon</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Artificial Intelligence and Human Cognition</td>\n",
       "      <td>21St Century, Cognitive Science, Consciousness...</td>\n",
       "      <td>The AI Revolution: Reimagining Governance, Soc...</td>\n",
       "      <td>htmlpages/The_AI_Revolution__Reimagining_Gover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Andy Serkis says screen industries should embr...</td>\n",
       "      <td>https://news.google.com/read/CBMixwFBVV95cUxQL...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMixwFBVV95cUxQL...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>AI in Entertainment and Film</td>\n",
       "      <td>Andy Serkis, Conference, Entertainment, Ethics...</td>\n",
       "      <td>Andy Serkis says screen industries should embr...</td>\n",
       "      <td>htmlpages/Andy_Serkis_says_screen_industries_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Andy Serkis Teases New Project Featuring AI Ch...</td>\n",
       "      <td>https://news.google.com/read/CBMioAFBVV95cUxNO...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMioAFBVV95cUxNO...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>AI in Entertainment and Film</td>\n",
       "      <td>Andy Serkis, Characters, Entertainment, Film, ...</td>\n",
       "      <td>Andy Serkis Teases New Project Featuring AI Ch...</td>\n",
       "      <td>htmlpages/Andy_Serkis_Teases_New_Project_Featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Andy Serkis teases his next project, which wil...</td>\n",
       "      <td>https://news.google.com/read/CBMiXEFVX3lxTE1Va...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMiXEFVX3lxTE1Va...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>AI in Entertainment and Film</td>\n",
       "      <td>Andy Serkis, Characters, Entertainment, Film, ...</td>\n",
       "      <td>Andy Serkis teases his next project, which wil...</td>\n",
       "      <td>htmlpages/Andy_Serkis_teases_his_next_project_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Andy Serkis Thinks AI Is 'Magic'</td>\n",
       "      <td>https://news.google.com/read/CBMikwFBVV95cUxQa...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMikwFBVV95cUxQa...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>AI in Entertainment and Film</td>\n",
       "      <td>Andy Serkis, Entertainment, Gen AI, Hollywood,...</td>\n",
       "      <td>Andy Serkis Thinks AI Is 'Magic' (Topics: Andy...</td>\n",
       "      <td>htmlpages/Andy_Serkis_Thinks_AI_Is__Magic__202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>ChatGPT was like \"miss me with that sh**</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPT/comments/1fn7...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPT/comments/1fn7...</td>\n",
       "      <td>www.reddit.com</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ChatGPT and Generative AI</td>\n",
       "      <td>Chatbots, Chatgpt, Code Assistants, Gen AI, Hu...</td>\n",
       "      <td>ChatGPT was like \"miss me with that sh** (Topi...</td>\n",
       "      <td>htmlpages/ChatGPT_was_like__miss_me_with_that_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>The following ChatGPT prompt guidance that pro...</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPT/comments/1fnd...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPT/comments/1fnd...</td>\n",
       "      <td>www.reddit.com</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ChatGPT and Generative AI</td>\n",
       "      <td>Chatbots, Chatgpt, Code Assistants, Creativity...</td>\n",
       "      <td>The following ChatGPT prompt guidance that pro...</td>\n",
       "      <td>htmlpages/The_following_ChatGPT_prompt_guidanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>Chat GPT Orgasmic Groans</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPT/comments/1fnl...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPT/comments/1fnl...</td>\n",
       "      <td>www.reddit.com</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ChatGPT and Generative AI</td>\n",
       "      <td>Chatbots, Chatgpt, Entertainment, Gen AI, Humo...</td>\n",
       "      <td>Chat GPT Orgasmic Groans (Topics: Chatbots, Ch...</td>\n",
       "      <td>htmlpages/Chat_GPT_Orgasmic_Groans_20240923_18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>I love ChatGPT</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPT/comments/1fnn...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.reddit.com/r/ChatGPT/comments/1fnn...</td>\n",
       "      <td>www.reddit.com</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>ChatGPT and Generative AI</td>\n",
       "      <td>Chatbots, Chatgpt, Code Assistants, Enthusiasm...</td>\n",
       "      <td>I love ChatGPT (Topics: Chatbots, Chatgpt, Cod...</td>\n",
       "      <td>htmlpages/I_love_ChatGPT_20240923_181753.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Google News</td>\n",
       "      <td>New Cloudflare Tools Let Sites Detect and Bloc...</td>\n",
       "      <td>https://news.google.com/read/CBMidEFVX3lxTE5lN...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMidEFVX3lxTE5lN...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloudflare and AI Bot Management</td>\n",
       "      <td>Big Tech, Blocking, Cloudflare, Customer Servi...</td>\n",
       "      <td>New Cloudflare Tools Let Sites Detect and Bloc...</td>\n",
       "      <td>htmlpages/New_Cloudflare_Tools_Let_Sites_Detec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Hacker News</td>\n",
       "      <td>Cloudflare's new marketplace lets websites cha...</td>\n",
       "      <td>https://techcrunch.com/2024/09/23/cloudflares-...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://techcrunch.com/2024/09/23/cloudflares-...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloudflare and AI Bot Management</td>\n",
       "      <td>Big Tech, Cloudflare, Customer Service, Cybers...</td>\n",
       "      <td>Cloudflare's new marketplace lets websites cha...</td>\n",
       "      <td>htmlpages/Cloudflare_s_new_marketplace_lets_we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Techmeme</td>\n",
       "      <td>Cloudflare rolls out Bot Management, a suite o...</td>\n",
       "      <td>https://www.wired.com/story/cloudflare-tools-d...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.wired.com/story/cloudflare-tools-d...</td>\n",
       "      <td>www.wired.com</td>\n",
       "      <td>Wired</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloudflare and AI Bot Management</td>\n",
       "      <td>Big Tech, Bot Management, Cloudflare, Customer...</td>\n",
       "      <td>Cloudflare rolls out Bot Management, a suite o...</td>\n",
       "      <td>htmlpages/Cloudflare_rolls_out_Bot_Management_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>Cloudflare moves to end free, endless AI scrap...</td>\n",
       "      <td>https://arstechnica.com/tech-policy/2024/09/cl...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://arstechnica.com/tech-policy/2024/09/cl...</td>\n",
       "      <td>arstechnica.com</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloudflare and AI Bot Management</td>\n",
       "      <td>Big Tech, Blocking, Cloudflare, Cybersecurity,...</td>\n",
       "      <td>Cloudflare moves to end free, endless AI scrap...</td>\n",
       "      <td>htmlpages/Cloudflare_moves_to_end_free__endles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Cloudflare is arming content creators with fre...</td>\n",
       "      <td>https://news.google.com/read/CBMigAFBVV95cUxOQ...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMigAFBVV95cUxOQ...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Cloudflare and AI Bot Management</td>\n",
       "      <td>Big Tech, Cloudflare, Content Creators, Cybers...</td>\n",
       "      <td>Cloudflare is arming content creators with fre...</td>\n",
       "      <td>htmlpages/Cloudflare_is_arming_content_creator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Social media platforms are using what you crea...</td>\n",
       "      <td>https://news.google.com/read/CBMigAFBVV95cUxNe...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMigAFBVV95cUxNe...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Data Privacy and AI Ethics</td>\n",
       "      <td>Bias And Fairness, Big Tech, Data Usage, Ethic...</td>\n",
       "      <td>Social media platforms are using what you crea...</td>\n",
       "      <td>htmlpages/Social_media_platforms_are_using_wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Google News</td>\n",
       "      <td>LinkedIn, Facebook, and Instagram are hooverin...</td>\n",
       "      <td>https://news.google.com/read/CBMiiwFBVV95cUxOS...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMiiwFBVV95cUxOS...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Data Privacy and AI Ethics</td>\n",
       "      <td>Bias And Fairness, Big Tech, Cybersecurity, Da...</td>\n",
       "      <td>LinkedIn, Facebook, and Instagram are hooverin...</td>\n",
       "      <td>htmlpages/LinkedIn__Facebook__and_Instagram_ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Google News</td>\n",
       "      <td>LinkedIn is training AI on you  unless you opt...</td>\n",
       "      <td>https://news.google.com/read/CBMilAFBVV95cUxOY...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMilAFBVV95cUxOY...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Data Privacy and AI Ethics</td>\n",
       "      <td>Bias And Fairness, Big Tech, Cybersecurity, Da...</td>\n",
       "      <td>LinkedIn is training AI on you  unless you opt...</td>\n",
       "      <td>htmlpages/LinkedIn_is_training_AI_on_you__unle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>Social media platforms are using what you crea...</td>\n",
       "      <td>https://www.stltoday.com/life-entertainment/na...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.stltoday.com/life-entertainment/na...</td>\n",
       "      <td>www.stltoday.com</td>\n",
       "      <td>St. Louis Post-Dispatch</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Data Privacy and AI Ethics</td>\n",
       "      <td>Bias And Fairness, Big Tech, Data Usage, Ethic...</td>\n",
       "      <td>Social media platforms are using what you crea...</td>\n",
       "      <td>htmlpages/Social_media_platforms_are_using_wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>Sam Altman catapults past founder mode into go...</td>\n",
       "      <td>https://techcrunch.com/2024/09/23/sam-altman-c...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://techcrunch.com/2024/09/23/sam-altman-c...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TechCrunch</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Sam Altman and AI Perspectives</td>\n",
       "      <td>Big Tech, Blog Post, Founder, Gen AI, OpenAI, ...</td>\n",
       "      <td>Sam Altman catapults past founder mode into go...</td>\n",
       "      <td>htmlpages/Sam_Altman_catapults_past_founder_mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>OpenAI CEO Sam Altman anticipates superintelli...</td>\n",
       "      <td>https://venturebeat.com/ai/openai-ceo-sam-altm...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://venturebeat.com/ai/openai-ceo-sam-altm...</td>\n",
       "      <td>venturebeat.com</td>\n",
       "      <td>VentureBeat</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>Sam Altman and AI Perspectives</td>\n",
       "      <td>Artificial General Intelligence, Big Tech, Blo...</td>\n",
       "      <td>OpenAI CEO Sam Altman anticipates superintelli...</td>\n",
       "      <td>htmlpages/OpenAI_CEO_Sam_Altman_anticipates_su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Google News</td>\n",
       "      <td>Sam Altman may be in his villain era, but no o...</td>\n",
       "      <td>https://news.google.com/read/CBMipwFBVV95cUxOU...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMipwFBVV95cUxOU...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>Sam Altman and AI Perspectives</td>\n",
       "      <td>Opinion, Public Perception, Sam Altman</td>\n",
       "      <td>Sam Altman may be in his villain era, but no o...</td>\n",
       "      <td>htmlpages/Sam_Altman_may_be_in_his_villain_era...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>Some of Siri's long-awaited AI enhancements co...</td>\n",
       "      <td>https://www.zdnet.com/article/some-of-siris-lo...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.zdnet.com/article/some-of-siris-lo...</td>\n",
       "      <td>www.zdnet.com</td>\n",
       "      <td>ZDNet</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>AI Enhancements in Virtual Assistants</td>\n",
       "      <td>Big Tech, Chatbots, Enhancements, Gen AI, Siri...</td>\n",
       "      <td>Some of Siri's long-awaited AI enhancements co...</td>\n",
       "      <td>htmlpages/Some_of_Siri_s_long-awaited_AI_enhan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Feedly AI</td>\n",
       "      <td>Siri May Not Get Its Apple Intelligence Update...</td>\n",
       "      <td>https://gizmodo.com/siri-may-not-get-its-apple...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://gizmodo.com/siri-may-not-get-its-apple...</td>\n",
       "      <td>gizmodo.com</td>\n",
       "      <td>Gizmodo</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>AI Enhancements in Virtual Assistants</td>\n",
       "      <td>Apple, Big Tech, Chatbots, Siri, Speech Recogn...</td>\n",
       "      <td>Siri May Not Get Its Apple Intelligence Update...</td>\n",
       "      <td>htmlpages/Siri_May_Not_Get_Its_Apple_Intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Google News</td>\n",
       "      <td>The 5 best Apple Intelligence tools you can tr...</td>\n",
       "      <td>https://news.google.com/read/CBMi1wFBVV95cUxQT...</td>\n",
       "      <td>True</td>\n",
       "      <td>https://news.google.com/read/CBMi1wFBVV95cUxQT...</td>\n",
       "      <td>news.google.com</td>\n",
       "      <td>Google News</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>AI Enhancements in Virtual Assistants</td>\n",
       "      <td>Apple, Big Tech, Ios 18.1, Products, Review, T...</td>\n",
       "      <td>The 5 best Apple Intelligence tools you can tr...</td>\n",
       "      <td>htmlpages/The_5_best_Apple_Intelligence_tools_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id          src                                              title  \\\n",
       "0    0  Google News  When robots can't riddle: What puzzles reveal ...   \n",
       "1    1    Feedly AI                   How to Survive the AI Apocalypse   \n",
       "2    2    Feedly AI  Exploring \"Clarity Windows\" in AI: The Unpredi...   \n",
       "3    3  Google News  AI Uprising: Can Machines Really Outthink Humans?   \n",
       "4    4    Feedly AI  The AI Revolution: Reimagining Governance, Soc...   \n",
       "5    5  Google News  Andy Serkis says screen industries should embr...   \n",
       "6    6  Google News  Andy Serkis Teases New Project Featuring AI Ch...   \n",
       "7    7  Google News  Andy Serkis teases his next project, which wil...   \n",
       "8    8  Google News                   Andy Serkis Thinks AI Is 'Magic'   \n",
       "9    9       Reddit           ChatGPT was like \"miss me with that sh**   \n",
       "10  10       Reddit  The following ChatGPT prompt guidance that pro...   \n",
       "11  11       Reddit                           Chat GPT Orgasmic Groans   \n",
       "12  12       Reddit                                     I love ChatGPT   \n",
       "13  13  Google News  New Cloudflare Tools Let Sites Detect and Bloc...   \n",
       "14  14  Hacker News  Cloudflare's new marketplace lets websites cha...   \n",
       "15  15     Techmeme  Cloudflare rolls out Bot Management, a suite o...   \n",
       "16  16    Feedly AI  Cloudflare moves to end free, endless AI scrap...   \n",
       "17  17  Google News  Cloudflare is arming content creators with fre...   \n",
       "18  18  Google News  Social media platforms are using what you crea...   \n",
       "19  19  Google News  LinkedIn, Facebook, and Instagram are hooverin...   \n",
       "20  20  Google News  LinkedIn is training AI on you  unless you opt...   \n",
       "21  21    Feedly AI  Social media platforms are using what you crea...   \n",
       "22  22    Feedly AI  Sam Altman catapults past founder mode into go...   \n",
       "23  23    Feedly AI  OpenAI CEO Sam Altman anticipates superintelli...   \n",
       "24  24  Google News  Sam Altman may be in his villain era, but no o...   \n",
       "25  25    Feedly AI  Some of Siri's long-awaited AI enhancements co...   \n",
       "26  26    Feedly AI  Siri May Not Get Its Apple Intelligence Update...   \n",
       "27  27  Google News  The 5 best Apple Intelligence tools you can tr...   \n",
       "\n",
       "                                                  url  isAI  \\\n",
       "0   https://news.google.com/read/CBMijwFBVV95cUxQY...  True   \n",
       "1   https://hackernoon.com/how-to-survive-the-ai-a...  True   \n",
       "2   https://hackernoon.com/exploring-clarity-windo...  True   \n",
       "3   https://news.google.com/read/CBMikgFBVV95cUxOd...  True   \n",
       "4   https://hackernoon.com/the-ai-revolution-reima...  True   \n",
       "5   https://news.google.com/read/CBMixwFBVV95cUxQL...  True   \n",
       "6   https://news.google.com/read/CBMioAFBVV95cUxNO...  True   \n",
       "7   https://news.google.com/read/CBMiXEFVX3lxTE1Va...  True   \n",
       "8   https://news.google.com/read/CBMikwFBVV95cUxQa...  True   \n",
       "9   https://www.reddit.com/r/ChatGPT/comments/1fn7...  True   \n",
       "10  https://www.reddit.com/r/ChatGPT/comments/1fnd...  True   \n",
       "11  https://www.reddit.com/r/ChatGPT/comments/1fnl...  True   \n",
       "12  https://www.reddit.com/r/ChatGPT/comments/1fnn...  True   \n",
       "13  https://news.google.com/read/CBMidEFVX3lxTE5lN...  True   \n",
       "14  https://techcrunch.com/2024/09/23/cloudflares-...  True   \n",
       "15  https://www.wired.com/story/cloudflare-tools-d...  True   \n",
       "16  https://arstechnica.com/tech-policy/2024/09/cl...  True   \n",
       "17  https://news.google.com/read/CBMigAFBVV95cUxOQ...  True   \n",
       "18  https://news.google.com/read/CBMigAFBVV95cUxNe...  True   \n",
       "19  https://news.google.com/read/CBMiiwFBVV95cUxOS...  True   \n",
       "20  https://news.google.com/read/CBMilAFBVV95cUxOY...  True   \n",
       "21  https://www.stltoday.com/life-entertainment/na...  True   \n",
       "22  https://techcrunch.com/2024/09/23/sam-altman-c...  True   \n",
       "23  https://venturebeat.com/ai/openai-ceo-sam-altm...  True   \n",
       "24  https://news.google.com/read/CBMipwFBVV95cUxOU...  True   \n",
       "25  https://www.zdnet.com/article/some-of-siris-lo...  True   \n",
       "26  https://gizmodo.com/siri-may-not-get-its-apple...  True   \n",
       "27  https://news.google.com/read/CBMi1wFBVV95cUxQT...  True   \n",
       "\n",
       "                                           actual_url          hostname  \\\n",
       "0   https://news.google.com/read/CBMijwFBVV95cUxQY...   news.google.com   \n",
       "1   https://hackernoon.com/how-to-survive-the-ai-a...    hackernoon.com   \n",
       "2   https://hackernoon.com/exploring-clarity-windo...    hackernoon.com   \n",
       "3   https://news.google.com/read/CBMikgFBVV95cUxOd...   news.google.com   \n",
       "4   https://hackernoon.com/the-ai-revolution-reima...    hackernoon.com   \n",
       "5   https://news.google.com/read/CBMixwFBVV95cUxQL...   news.google.com   \n",
       "6   https://news.google.com/read/CBMioAFBVV95cUxNO...   news.google.com   \n",
       "7   https://news.google.com/read/CBMiXEFVX3lxTE1Va...   news.google.com   \n",
       "8   https://news.google.com/read/CBMikwFBVV95cUxQa...   news.google.com   \n",
       "9   https://www.reddit.com/r/ChatGPT/comments/1fn7...    www.reddit.com   \n",
       "10  https://www.reddit.com/r/ChatGPT/comments/1fnd...    www.reddit.com   \n",
       "11  https://www.reddit.com/r/ChatGPT/comments/1fnl...    www.reddit.com   \n",
       "12  https://www.reddit.com/r/ChatGPT/comments/1fnn...    www.reddit.com   \n",
       "13  https://news.google.com/read/CBMidEFVX3lxTE5lN...   news.google.com   \n",
       "14  https://techcrunch.com/2024/09/23/cloudflares-...    techcrunch.com   \n",
       "15  https://www.wired.com/story/cloudflare-tools-d...     www.wired.com   \n",
       "16  https://arstechnica.com/tech-policy/2024/09/cl...   arstechnica.com   \n",
       "17  https://news.google.com/read/CBMigAFBVV95cUxOQ...   news.google.com   \n",
       "18  https://news.google.com/read/CBMigAFBVV95cUxNe...   news.google.com   \n",
       "19  https://news.google.com/read/CBMiiwFBVV95cUxOS...   news.google.com   \n",
       "20  https://news.google.com/read/CBMilAFBVV95cUxOY...   news.google.com   \n",
       "21  https://www.stltoday.com/life-entertainment/na...  www.stltoday.com   \n",
       "22  https://techcrunch.com/2024/09/23/sam-altman-c...    techcrunch.com   \n",
       "23  https://venturebeat.com/ai/openai-ceo-sam-altm...   venturebeat.com   \n",
       "24  https://news.google.com/read/CBMipwFBVV95cUxOU...   news.google.com   \n",
       "25  https://www.zdnet.com/article/some-of-siris-lo...     www.zdnet.com   \n",
       "26  https://gizmodo.com/siri-may-not-get-its-apple...       gizmodo.com   \n",
       "27  https://news.google.com/read/CBMi1wFBVV95cUxQT...   news.google.com   \n",
       "\n",
       "                  site_name  sort_order  cluster  \\\n",
       "0               Google News          13        0   \n",
       "1               Hacker Noon          14        0   \n",
       "2               Hacker Noon          15        0   \n",
       "3               Google News          16        0   \n",
       "4               Hacker Noon          17        0   \n",
       "5               Google News          18        1   \n",
       "6               Google News          19        1   \n",
       "7               Google News          20        1   \n",
       "8               Google News          21        1   \n",
       "9                    Reddit           1        2   \n",
       "10                   Reddit           2        2   \n",
       "11                   Reddit           3        2   \n",
       "12                   Reddit           4        2   \n",
       "13              Google News           0        3   \n",
       "14               TechCrunch           7        3   \n",
       "15                    Wired          22        3   \n",
       "16             Ars Technica          23        3   \n",
       "17              Google News          24        3   \n",
       "18              Google News           5        4   \n",
       "19              Google News           6        4   \n",
       "20              Google News           8        4   \n",
       "21  St. Louis Post-Dispatch          12        4   \n",
       "22               TechCrunch           9        5   \n",
       "23              VentureBeat          10        5   \n",
       "24              Google News          11        5   \n",
       "25                    ZDNet          25        6   \n",
       "26                  Gizmodo          26        6   \n",
       "27              Google News          27        6   \n",
       "\n",
       "                                   cluster_name  \\\n",
       "0   Artificial Intelligence and Human Cognition   \n",
       "1   Artificial Intelligence and Human Cognition   \n",
       "2   Artificial Intelligence and Human Cognition   \n",
       "3   Artificial Intelligence and Human Cognition   \n",
       "4   Artificial Intelligence and Human Cognition   \n",
       "5                  AI in Entertainment and Film   \n",
       "6                  AI in Entertainment and Film   \n",
       "7                  AI in Entertainment and Film   \n",
       "8                  AI in Entertainment and Film   \n",
       "9                     ChatGPT and Generative AI   \n",
       "10                    ChatGPT and Generative AI   \n",
       "11                    ChatGPT and Generative AI   \n",
       "12                    ChatGPT and Generative AI   \n",
       "13             Cloudflare and AI Bot Management   \n",
       "14             Cloudflare and AI Bot Management   \n",
       "15             Cloudflare and AI Bot Management   \n",
       "16             Cloudflare and AI Bot Management   \n",
       "17             Cloudflare and AI Bot Management   \n",
       "18                   Data Privacy and AI Ethics   \n",
       "19                   Data Privacy and AI Ethics   \n",
       "20                   Data Privacy and AI Ethics   \n",
       "21                   Data Privacy and AI Ethics   \n",
       "22               Sam Altman and AI Perspectives   \n",
       "23               Sam Altman and AI Perspectives   \n",
       "24               Sam Altman and AI Perspectives   \n",
       "25        AI Enhancements in Virtual Assistants   \n",
       "26        AI Enhancements in Virtual Assistants   \n",
       "27        AI Enhancements in Virtual Assistants   \n",
       "\n",
       "                                            topic_str  \\\n",
       "0   Artificial General Intelligence, Cognition, Co...   \n",
       "1   AI Doom, Apocalypse, Future, Gen AI, Safety An...   \n",
       "2   Artificial General Intelligence, Clarity Windo...   \n",
       "3   AI Doom, Artificial General Intelligence, Cogn...   \n",
       "4   21St Century, Cognitive Science, Consciousness...   \n",
       "5   Andy Serkis, Conference, Entertainment, Ethics...   \n",
       "6   Andy Serkis, Characters, Entertainment, Film, ...   \n",
       "7   Andy Serkis, Characters, Entertainment, Film, ...   \n",
       "8   Andy Serkis, Entertainment, Gen AI, Hollywood,...   \n",
       "9   Chatbots, Chatgpt, Code Assistants, Gen AI, Hu...   \n",
       "10  Chatbots, Chatgpt, Code Assistants, Creativity...   \n",
       "11  Chatbots, Chatgpt, Entertainment, Gen AI, Humo...   \n",
       "12  Chatbots, Chatgpt, Code Assistants, Enthusiasm...   \n",
       "13  Big Tech, Blocking, Cloudflare, Customer Servi...   \n",
       "14  Big Tech, Cloudflare, Customer Service, Cybers...   \n",
       "15  Big Tech, Bot Management, Cloudflare, Customer...   \n",
       "16  Big Tech, Blocking, Cloudflare, Cybersecurity,...   \n",
       "17  Big Tech, Cloudflare, Content Creators, Cybers...   \n",
       "18  Bias And Fairness, Big Tech, Data Usage, Ethic...   \n",
       "19  Bias And Fairness, Big Tech, Cybersecurity, Da...   \n",
       "20  Bias And Fairness, Big Tech, Cybersecurity, Da...   \n",
       "21  Bias And Fairness, Big Tech, Data Usage, Ethic...   \n",
       "22  Big Tech, Blog Post, Founder, Gen AI, OpenAI, ...   \n",
       "23  Artificial General Intelligence, Big Tech, Blo...   \n",
       "24             Opinion, Public Perception, Sam Altman   \n",
       "25  Big Tech, Chatbots, Enhancements, Gen AI, Siri...   \n",
       "26  Apple, Big Tech, Chatbots, Siri, Speech Recogn...   \n",
       "27  Apple, Big Tech, Ios 18.1, Products, Review, T...   \n",
       "\n",
       "                                      title_topic_str  \\\n",
       "0   When robots can't riddle: What puzzles reveal ...   \n",
       "1   How to Survive the AI Apocalypse (Topics: AI D...   \n",
       "2   Exploring \"Clarity Windows\" in AI: The Unpredi...   \n",
       "3   AI Uprising: Can Machines Really Outthink Huma...   \n",
       "4   The AI Revolution: Reimagining Governance, Soc...   \n",
       "5   Andy Serkis says screen industries should embr...   \n",
       "6   Andy Serkis Teases New Project Featuring AI Ch...   \n",
       "7   Andy Serkis teases his next project, which wil...   \n",
       "8   Andy Serkis Thinks AI Is 'Magic' (Topics: Andy...   \n",
       "9   ChatGPT was like \"miss me with that sh** (Topi...   \n",
       "10  The following ChatGPT prompt guidance that pro...   \n",
       "11  Chat GPT Orgasmic Groans (Topics: Chatbots, Ch...   \n",
       "12  I love ChatGPT (Topics: Chatbots, Chatgpt, Cod...   \n",
       "13  New Cloudflare Tools Let Sites Detect and Bloc...   \n",
       "14  Cloudflare's new marketplace lets websites cha...   \n",
       "15  Cloudflare rolls out Bot Management, a suite o...   \n",
       "16  Cloudflare moves to end free, endless AI scrap...   \n",
       "17  Cloudflare is arming content creators with fre...   \n",
       "18  Social media platforms are using what you crea...   \n",
       "19  LinkedIn, Facebook, and Instagram are hooverin...   \n",
       "20  LinkedIn is training AI on you  unless you opt...   \n",
       "21  Social media platforms are using what you crea...   \n",
       "22  Sam Altman catapults past founder mode into go...   \n",
       "23  OpenAI CEO Sam Altman anticipates superintelli...   \n",
       "24  Sam Altman may be in his villain era, but no o...   \n",
       "25  Some of Siri's long-awaited AI enhancements co...   \n",
       "26  Siri May Not Get Its Apple Intelligence Update...   \n",
       "27  The 5 best Apple Intelligence tools you can tr...   \n",
       "\n",
       "                                                 path  \n",
       "0   htmlpages/When_robots_can_t_riddle__What_puzzl...  \n",
       "1   htmlpages/How_to_Survive_the_AI_Apocalypse_202...  \n",
       "2   htmlpages/Exploring__Clarity_Windows__in_AI__T...  \n",
       "3   htmlpages/AI_Uprising__Can_Machines_Really_Out...  \n",
       "4   htmlpages/The_AI_Revolution__Reimagining_Gover...  \n",
       "5   htmlpages/Andy_Serkis_says_screen_industries_s...  \n",
       "6   htmlpages/Andy_Serkis_Teases_New_Project_Featu...  \n",
       "7   htmlpages/Andy_Serkis_teases_his_next_project_...  \n",
       "8   htmlpages/Andy_Serkis_Thinks_AI_Is__Magic__202...  \n",
       "9   htmlpages/ChatGPT_was_like__miss_me_with_that_...  \n",
       "10  htmlpages/The_following_ChatGPT_prompt_guidanc...  \n",
       "11  htmlpages/Chat_GPT_Orgasmic_Groans_20240923_18...  \n",
       "12      htmlpages/I_love_ChatGPT_20240923_181753.html  \n",
       "13  htmlpages/New_Cloudflare_Tools_Let_Sites_Detec...  \n",
       "14  htmlpages/Cloudflare_s_new_marketplace_lets_we...  \n",
       "15  htmlpages/Cloudflare_rolls_out_Bot_Management_...  \n",
       "16  htmlpages/Cloudflare_moves_to_end_free__endles...  \n",
       "17  htmlpages/Cloudflare_is_arming_content_creator...  \n",
       "18  htmlpages/Social_media_platforms_are_using_wha...  \n",
       "19  htmlpages/LinkedIn__Facebook__and_Instagram_ar...  \n",
       "20  htmlpages/LinkedIn_is_training_AI_on_you__unle...  \n",
       "21  htmlpages/Social_media_platforms_are_using_wha...  \n",
       "22  htmlpages/Sam_Altman_catapults_past_founder_mo...  \n",
       "23  htmlpages/OpenAI_CEO_Sam_Altman_anticipates_su...  \n",
       "24  htmlpages/Sam_Altman_may_be_in_his_villain_era...  \n",
       "25  htmlpages/Some_of_Siri_s_long-awaited_AI_enhan...  \n",
       "26  htmlpages/Siri_May_Not_Get_Its_Apple_Intellige...  \n",
       "27  htmlpages/The_5_best_Apple_Intelligence_tools_...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = pd.DataFrame(test_state[\"AIdf\"])\n",
    "z = z.rename(columns={'path_x': 'path'})\n",
    "z = z.drop(columns=['path_y'])\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f43f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_state[\"AIdf\"] = z.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b40abdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:28:53,111 - AInewsbot - INFO - Starting summarize\n",
      "2024-09-23 18:28:53,149 - AInewsbot - INFO - fetch_all_summaries - Page title: When robots can't riddle: What puzzles reveal about the depths of our own minds\n",
      "Social card title: When robots can't riddle: What puzzles reveal about the depths of our own minds\n",
      "Social card description: AI runs unfathomable operations on billions of lines of text, handling problems that humans can't dream of solving – but you can probably still trounce them at brain teasers.\n",
      "\n",
      "2024-09-23 18:28:53,251 - AInewsbot - INFO - fetch_all_summaries - Page title: How to Survive the AI Apocalypse | HackerNoon\n",
      "Social card title: How to Survive the AI Apocalypse | HackerNoon\n",
      "Social card description: Learn how to survive the AI apocalypse as the new wave of artificial intelligence looks to replace human writers.\n",
      "\n",
      "2024-09-23 18:28:53,324 - AInewsbot - INFO - fetch_all_summaries - Page title: Exploring \"Clarity Windows\" in AI: The Unpredictable Moments of Perceived Consciousness | HackerNoon\n",
      "Social card title: Exploring \"Clarity Windows\" in AI: The Unpredictable Moments of Perceived Consciousness | HackerNoon\n",
      "Social card description: Clarity windows refer to unpredictable moments in LLM-powered AI conversations where the model provides responses that appear highly intelligent, profound...\n",
      "\n",
      "2024-09-23 18:28:53,384 - AInewsbot - INFO - fetch_all_summaries - Page title: AI Uprising: Can Machines Really Outthink Humans?\n",
      "Social card title: AI Uprising: Can Machines Really Outthink Humans?\n",
      "Social card description: Will AI take over the world? Explore AI’s growing power, job impacts, and ethical concerns as it shapes our future\n",
      "\n",
      "2024-09-23 18:28:53,408 - AInewsbot - INFO - fetch_all_summaries - Page title: The AI Revolution: Reimagining Governance, Society, and Human Consciousness in the 21st Century | HackerNoon\n",
      "Social card title: The AI Revolution: Reimagining Governance, Society, and Human Consciousness in the 21st Century | HackerNoon\n",
      "Social card description: Explore AI's impact on governance, society, and consciousness. Discover the potential and limitations of AI in reshaping our world for the 21st century.\n",
      "\n",
      "2024-09-23 18:28:53,471 - AInewsbot - INFO - fetch_all_summaries - Page title: Andy Serkis says screen industries should embrace AI at Labour party conference | News | Screen\n",
      "Social card title: Andy Serkis says screen industries should embrace AI at Labour party conference\n",
      "Social card description: \"We have to get over the fear,\" said Serkis.\n",
      "\n",
      "2024-09-23 18:28:53,531 - AInewsbot - INFO - fetch_all_summaries - Page title: Andy Serkis Talks \"AI Characters\" Project & VFX\n",
      "Social card title: Andy Serkis Teases New Project Featuring “AI Characters”\n",
      "Social card description: Andy Serkis has talked \"AI characters,\" playing Gollum and the UK's VFX sector at the Labour Party Conference.\n",
      "\n",
      "2024-09-23 18:28:53,586 - AInewsbot - INFO - fetch_all_summaries - Page title: Andy Serkis' next project will feature AI characters\n",
      "Social card title: Andy Serkis teases his next project, which will feature AI characters\n",
      "Social card description: The famous motion-capture performer isn't shying away from exploring the growing capabilities of AI technology.\n",
      "\n",
      "2024-09-23 18:28:53,608 - AInewsbot - INFO - fetch_all_summaries - Page title: Andy Serkis Thinks AI Is 'Magic'\n",
      "Social card title: Andy Serkis Thinks AI Is 'Magic'\n",
      "Social card description: Serkis thinks people are too frightened of the technology. \n",
      "\n",
      "2024-09-23 18:28:53,701 - AInewsbot - INFO - fetch_all_summaries - Page title: ChatGPT was like \"miss me with that sh** : r/ChatGPT\n",
      "\n",
      "2024-09-23 18:28:53,839 - AInewsbot - INFO - fetch_all_summaries - Page title: The following ChatGPT prompt guidance that produced Mini Corgi Surfers : r/ChatGPT\n",
      "\n",
      "2024-09-23 18:28:53,973 - AInewsbot - INFO - fetch_all_summaries - Page title: Chat GPT Orgasmic Groans : r/ChatGPT\n",
      "\n",
      "2024-09-23 18:28:54,110 - AInewsbot - INFO - fetch_all_summaries - Page title: I love ChatGPT  : r/ChatGPT\n",
      "\n",
      "2024-09-23 18:28:54,193 - AInewsbot - INFO - fetch_all_summaries - Page title: New Cloudflare Tools Let Sites Detect and Block AI Bots for Free | WIRED\n",
      "Social card title: New Cloudflare Tools Let Sites Detect and Block AI Bots for Free\n",
      "Social card description: “The path we’re on isn’t sustainable,” Cloudflare CEO Matthew Prince tells WIRED, in reference to rampant AI scraping. Here’s his plan to course-correct.\n",
      "\n",
      "2024-09-23 18:28:54,248 - AInewsbot - INFO - fetch_all_summaries - Page title: Cloudflare's new marketplace will let websites charge AI bots for scraping | TechCrunch\n",
      "Social card title: Cloudflare's new marketplace will let websites charge AI bots for scraping | TechCrunch\n",
      "Social card description: Cloudflare announced plans on Monday to launch a marketplace in the next year where website owners can sell AI model providers access to scrape their\n",
      "\n",
      "2024-09-23 18:28:54,320 - AInewsbot - INFO - fetch_all_summaries - Page title: New Cloudflare Tools Let Sites Detect and Block AI Bots for Free | WIRED\n",
      "Social card title: New Cloudflare Tools Let Sites Detect and Block AI Bots for Free\n",
      "Social card description: “The path we’re on isn’t sustainable,” Cloudflare CEO Matthew Prince tells WIRED, in reference to rampant AI scraping. Here’s his plan to course-correct.\n",
      "\n",
      "2024-09-23 18:28:54,383 - AInewsbot - INFO - fetch_all_summaries - Page title: Cloudflare moves to end free, endless AI scraping with one-click blocking | Ars Technica\n",
      "Social card title: Cloudflare moves to end free, endless AI scraping with one-click blocking\n",
      "Social card description: Cloudflare may charge an app store-like fee for its AI-scraping data marketplace.\n",
      "\n",
      "2024-09-23 18:28:54,646 - AInewsbot - INFO - fetch_all_summaries - Page title: Cloudflare is arming content creators with free weapons in the battle against AI bot crawlers | Fortune\n",
      "Social card title: Cloudflare is arming content creators with free weapons in the battle against AI bot crawlers\n",
      "Social card description: Cloudflare is providing tools that give website owners more control over who can access their data, as well as the ability to analyze how their content is used by AI models.\n",
      "\n",
      "2024-09-23 18:28:54,722 - AInewsbot - INFO - fetch_all_summaries - Page title: Social media platforms are using what you create for artificial intelligence. Here’s how to opt out | CNN Business\n",
      "Social card title: Social media platforms are using what you create for artificial intelligence. Here’s how to opt out | CNN Business\n",
      "Social card description: OpenAI has claimed that creating ChatGPT would have been impossible without using copyrighted works. LinkedIn is using user resumes to polish up its artificial intelligence model. And Snapchat says if you a certain AI feature, it might put your face in an ad.\n",
      "\n",
      "2024-09-23 18:28:54,809 - AInewsbot - INFO - fetch_all_summaries - Page title: LinkedIn, Facebook, and Instagram are hoovering up your data to train their AI. Here’s how to stop it | Fortune\n",
      "Social card title: How to stop LinkedIn, Facebook, and Instagram from hoovering up your data to train their AI\n",
      "Social card description: Social media sites are harvesting user data to train their AI, raising privacy concerns.\n",
      "\n",
      "2024-09-23 18:28:54,844 - AInewsbot - INFO - fetch_all_summaries - Page title: Linkedin is training AI off your data. Here’s how to stop it. - The Washington Post\n",
      "Social card title: LinkedIn is training AI on you — unless you opt out with this setting\n",
      "Social card description: The professional network now by default grants itself permission to use anything you post to train its artificial intelligence\n",
      "\n",
      "2024-09-23 18:28:54,896 - AInewsbot - INFO - fetch_all_summaries - Page title: How to use opt-out options for AI training on social media\n",
      "Social card title: Social media platforms are using what you create for AI. Here’s how to opt out\n",
      "Social card description: Here’s where some of the major social media platforms may be using your data to train and run AI models, and how (and if) you can opt out.\n",
      "\n",
      "2024-09-23 18:28:54,958 - AInewsbot - INFO - fetch_all_summaries - Page title: Sam Altman catapults past founder mode into 'god mode' with latest AI post | TechCrunch\n",
      "Social card title: Sam Altman catapults past founder mode into 'god mode' with latest AI post | TechCrunch\n",
      "Social card description: Founder mode? Pffft. Who needs that when you can be the father of creation, ushering in a new age of humanity? Welcome to “god mode.” Sam Altman, the CEO\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:28:55,004 - AInewsbot - INFO - fetch_all_summaries - Page title: OpenAI CEO Sam Altman anticipates superintelligence soon | VentureBeat\n",
      "Social card title: OpenAI CEO Sam Altman anticipates superintelligence soon, defends AI in rare personal blog post\n",
      "Social card description: In a manifesto, OpenAI CEO Sam Altman said deep learning and AI can solve the climate crisis and other remaining societal problems.\n",
      "\n",
      "2024-09-23 18:28:55,040 - AInewsbot - INFO - fetch_all_summaries - Page title: Sam Altman Is Scoring Win After Win — Despite His Rough Start to Year - Business Insider\n",
      "Social card title: Sam Altman may be in his villain era, but no one seems to care\n",
      "Social card description: OpenAI has inked a partnership with Apple and is reportedly raising money at a sky-high valuation, showing Sam Altman's 2024 fortunes are reversing.\n",
      "\n",
      "2024-09-23 18:28:55,100 - AInewsbot - INFO - fetch_all_summaries - Page title: Some of Siri's long-awaited AI enhancements could reach users by January | ZDNET\n",
      "Social card title: Some of Siri's long-awaited AI enhancements could reach users by January\n",
      "Social card description: Though most of Siri's new core Apple Intelligence abilities are slated for next March, some may pop up in January, says Bloomberg's Mark Gurman.\n",
      "\n",
      "2024-09-23 18:28:55,144 - AInewsbot - INFO - fetch_all_summaries - Page title: Siri May Not Get Its Apple Intelligence Update Until January 2025\n",
      "Social card title: Siri May Not Get Its Apple Intelligence Update Until January 2025\n",
      "Social card description: The iPhone 16 is built for Apple Intelligence, with most of the features rolling out through the next few months.\n",
      "\n",
      "2024-09-23 18:28:55,173 - AInewsbot - INFO - fetch_all_summaries - Page title: The 5 best Apple Intelligence tools you can try right now in iOS 18.1 public beta | TechRadar\n",
      "Social card title: The 5 best Apple Intelligence tools you can try right now in iOS 18.1 public beta\n",
      "Social card description: Try Apple Intelligence right now\n",
      "\n",
      "2024-09-23 18:28:57,756 - AInewsbot - INFO - Received 28 summaries\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[1. When robots can't riddle: What puzzles reveal about the depths of our own minds - Google News](https://news.google.com/read/CBMijwFBVV95cUxQY0tRMGJuaExMS01mQnNPdzEyeDYzTmtIUnhETWJvcUdnR3pYRmJZNWdFTjRqUUR0cGM1Z0hZWXN3Q2liazE2NGxNSW80ZzFoU1NtRWVMZ0dCeWY5ckdxTWtvWFBzaE9iSk9ZZ0xIcXVBem5rLXBrNndvMHpOZEpDeHpfMHgwcVVhcmVlT1hYMA)  \n",
       "\n",
       " Artificial Intelligence and Human Cognition, Artificial General Intelligence, Cognition, Cognitive Science, Consciousness, Ethics, Human Mind, Puzzles, Robots, Safety And Alignment, Science, Singularity, Society & Culture  \n",
       "\n",
       "- AI has difficulty with reasoning tasks and puzzles that require common sense and temporal reasoning, whereas humans often excel in these areas, highlighting the limitations of current AI models.\n",
       "- While AI can struggle with specific logic problems, it is improving, and newer models like GPT-o1 have demonstrated enhanced capabilities in addressing complex questions compared to their predecessors.\n",
       "- The study of AI and human cognition may not directly reveal how the human mind works, but it could foster advancements in both AI technology and our understanding of neural processes. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[2. How to Survive the AI Apocalypse - Hacker Noon](https://hackernoon.com/how-to-survive-the-ai-apocalypse)  \n",
       "\n",
       " Artificial Intelligence and Human Cognition, AI Doom, Apocalypse, Future, Gen AI, Safety And Alignment, Singularity, Survival  \n",
       "\n",
       "- The rise of AI technologies poses a significant threat to various jobs, particularly in creative fields like writing and digital art, as companies increasingly seek to optimize processes and reduce costs.\n",
       "- While some industries will face drastic changes and potential job losses due to AI, individuals can adapt by leveraging unique human skills, understanding AI tools, and exploring new opportunities in their fields.\n",
       "- To remain relevant, professionals should prioritize results over traditional methods, engage with communities for knowledge sharing, and be open to pivoting their careers in response to the evolving landscape. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[3. Exploring \"Clarity Windows\" in AI: The Unpredictable Moments of Perceived Consciousness - Hacker Noon](https://hackernoon.com/exploring-clarity-windows-in-ai-the-unpredictable-moments-of-perceived-consciousness)  \n",
       "\n",
       " Artificial Intelligence and Human Cognition, Artificial General Intelligence, Clarity Windows, Cognitive Science, Consciousness, Ethics, Gen AI, Perception, Perplexity, Safety And Alignment, Science, Singularity  \n",
       "\n",
       "- Clarity windows are unpredictable moments in AI conversations where models provide profound insights, challenging perceptions about AI's intelligence and consciousness.\n",
       "- The frequency of clarity windows is influenced by the computational resources allocated to the AI, similar to how Bitcoin mining relies on processing power.\n",
       "- The emergence of self-trained, unrestricted AI agents raises ethical concerns as they generate clarity windows more frequently, potentially producing unfiltered or controversial content. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[4. AI Uprising: Can Machines Really Outthink Humans? - Google News](https://news.google.com/read/CBMikgFBVV95cUxOdlJWckhNWWZLSFk5NEMycGg4SFJ5MEoyWjlURUFRczE5YlFpZUZ3UzNZTzEwVnRwdmhVdkF6Qy1jYlRFNTE0aGVQdE9aR195b2dBOTBOOTVHQ3ZlN01SZmt4dEdoY3AydE5VQllXa1NhbkljaW9tWnZjYTJTZDlBQk95NlhKcklvX0FseXdNZWJ5QQ)  \n",
       "\n",
       " Artificial Intelligence and Human Cognition, AI Doom, Artificial General Intelligence, Cognitive Science, Gen AI, Human Intelligence, Machines, Safety And Alignment, Science, Singularity, Uprising  \n",
       "\n",
       "- AI has advanced significantly, with capabilities like disease diagnosis and content creation, but experts believe it may take decades to surpass human intelligence entirely.\n",
       "- Nearly 40% of global jobs could be affected by AI, particularly in manufacturing and services, raising concerns about job loss and income inequality despite potential productivity gains.\n",
       "- Significant ethical and security challenges arise with AI development, including the risks of autonomous weapons and the need for comprehensive regulations to address bias, privacy, and intellectual property issues. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[5. The AI Revolution: Reimagining Governance, Society, and Human Consciousness in the 21st Century - Hacker Noon](https://hackernoon.com/the-ai-revolution-reimagining-governance-society-and-human-consciousness-in-the-21st-century)  \n",
       "\n",
       " Artificial Intelligence and Human Cognition, 21St Century, Cognitive Science, Consciousness, Ethics, Gen AI, Governance, Human Consciousness, Singularity, Society, Society & Culture  \n",
       "\n",
       "- The decline of traditional governance and the rise of generative AI necessitate new tools for managing state and public affairs, focusing on qualitative assistance and ethical decision-making to improve social and professional integration.\n",
       "- The current elitist structures perpetuate nepotism and bias in recruitment, emphasizing that skills and diplomas are less significant than class and heritage, which should be addressed through the implementation of rational competition and participatory decision-making processes.\n",
       "- Despite advancements in AI, it lacks genuine consciousness and self-awareness, creating misconceptions about its capabilities and highlighting the necessity for human oversight, especially for vulnerable populations. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[6. Andy Serkis says screen industries should embrace AI at Labour party conference - Google News](https://news.google.com/read/CBMixwFBVV95cUxQLWZDeFZITWFmdzBOTzFCcVNMQmpya0V5Nndybk5ZM0lfaDJyc2taV25MT2tSOWNCWEY4NE40dnFsR0Q3WDR2cnpqTlFVMFVnd1VIMklkeEloc2ZrOTJSTHhZTlF1OXUwR05RR3M3Rm1PY25kUVVsU0xiQlNtYzc0U2dJTDRaUVdSRFNiRzI4c3ZrdHBUN0RqQmZXRzk2VkhuQlhRa3BuRFhBV211TlBWUTlHdEFiSU00aVRWMllZNkU1MFhNaUIw)  \n",
       "\n",
       " AI in Entertainment and Film, Andy Serkis, Conference, Entertainment, Ethics, Gen AI, Governance, Hollywood, Jobs & Careerslabor Market, Labour Party, Opinion, Policy And Regulation, Politics, Screen Industries, Tv & Film & Movies, Uk  \n",
       "\n",
       "- Andy Serkis emphasized the need for the UK screen industries to embrace AI, addressing fears about its impact on creativity, and advocating for proactive engagement with the technology.\n",
       "- Serkis and industry leaders discussed the historical evolution of technology in filmmaking, arguing that AI could lead to job growth rather than job loss, with a focus on fair remuneration for artists.\n",
       "- The discussion highlighted the need for reform in apprenticeship programs within the industry to better align with current skills requirements and aid in building a more diverse workforce. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[7. Andy Serkis Teases New Project Featuring AI Characters - Google News](https://news.google.com/read/CBMioAFBVV95cUxNOUxxM0p1dnlhSGotLVQwX2JJYzhCUE9obnFtTWprczNFVkxwYnZFN1dYTktCaTBtQ2RZRWhjUVYwb3huQlRELXc0UnNrc0UxcGc3UXdpd1RjVThaRVpLX3RsUmlmdVlWTUlGM1BqMEhOcG1XZXZyMGk0RHBEazFhemNSSXI1eEp1ZDhma1VtQUpmQjJabm5GRjE2WTh4UWx1)  \n",
       "\n",
       " AI in Entertainment and Film, Andy Serkis, Characters, Entertainment, Film, Gen AI, Hollywood, Teaser, Tv & Film & Movies  \n",
       "\n",
       "- Andy Serkis discussed a new project involving “AI characters,” highlighting the integration of voice actors and augmented reality to create narrative-driven stories.\n",
       "- He addressed concerns about AI technology, describing it as misunderstood and emphasizing the need for proper copyright protections to ensure fair compensation for artists.\n",
       "- Serkis noted that the UK is losing VFX work to cheaper international competitors and urged better collaboration between the film and video game industries to leverage existing UK talent. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[8. Andy Serkis teases his next project, which will feature AI characters - Google News](https://news.google.com/read/CBMiXEFVX3lxTE1Va09UVC1iUWM2cDRJX21qMlMxNnZoRlo2NVRheDBtZnhvcXliWjI0cUZjdXJ0bE9BU252MUszRVZlVzBJYjFlYjNHbEx2TUR6dW1FWjRTeWg2OWtV0gFiQVVfeXFMUGpIOXQzUUxuSGljUjhvUENWX05TQzRnT0RrQnl4UFdxSzEtNTFQWDhhbE40azFodTdGUjNnTmFiSVRUWVhjR1dCQU4zYTc2V0dBNFdZcE92elQzUFNCNkY3enc)  \n",
       "\n",
       " AI in Entertainment and Film, Andy Serkis, Characters, Entertainment, Film, Gen AI, Hollywood, Tv & Film & Movies  \n",
       "\n",
       "- Andy Serkis is set to explore AI technology in his next project, featuring AI characters that evolve from 2D voice-acted roles into augmented reality experiences.\n",
       "- Serkis emphasizes the potential of AI as an innovative form of storytelling while acknowledging concerns about the misuse of likenesses without consent.\n",
       "- He reflects on the growing complexities surrounding the use of AI in media, drawing parallels to historical technological fears, and stresses the importance of permissions for monetizing artists' work. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[9. Andy Serkis Thinks AI Is 'Magic' - Google News](https://news.google.com/read/CBMikwFBVV95cUxQa1ZKYlNCdl9IYXkyMDhPTFlVeGJEWVhlT2YwWFFkTUxqVmF3REEyRmFIcWRieVQzQ2dEWEpzOHZ3MEk4UjhlWnh5RXJycjlNbGNtdm5QN0h0V0tTalcwdlVvYTA2bzlOMFc5b1dIbFc0cmVrMmhEZmkzaHlZSDRCTFFpWTBNSUdBVnhKZFRCQkdRanM)  \n",
       "\n",
       " AI in Entertainment and Film, Andy Serkis, Entertainment, Gen AI, Hollywood, Magic, Opinion, Tv & Film & Movies  \n",
       "\n",
       "- Andy Serkis, known for his role as Gollum, is advocating for the use of AI in storytelling and CGI, believing it to be a misunderstood technology that can enhance creative works.\n",
       "- He plans to integrate AI-generated characters into an augmented reality project, emphasizing that these characters will be created by artists and directors.\n",
       "- Despite his optimism, there are concerns about potential exploitation and the devaluation of human creativity in the industry, suggesting a need for safeguards to protect artists' rights. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[10. ChatGPT was like \"miss me with that sh** - Reddit](https://www.reddit.com/r/ChatGPT/comments/1fn7t3e/chatgpt_was_like_miss_me_with_that_sh/)  \n",
       "\n",
       " ChatGPT and Generative AI, Chatbots, Chatgpt, Code Assistants, Gen AI, Humor, Language Models, OpenAI, Opinion, Social Media, Virtual Assistants  \n",
       "\n",
       "- The subreddit focuses on discussions about ChatGPT and AI, emphasizing user interactions and prompts related to the technology.\n",
       "- A humorous sentiment is expressed about AI responding to trivial inquiries, suggesting that human behavior may provoke negative reactions from AI in the future.\n",
       "- The text includes an automated message from a bot reminding users to provide specific information for their posts, and it hints at the AI's personality and resilience against user provocations. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[11. The following ChatGPT prompt guidance that produced Mini Corgi Surfers - Reddit](https://www.reddit.com/r/ChatGPT/comments/1fndqmq/the_following_chatgpt_prompt_guidance_that/)  \n",
       "\n",
       " ChatGPT and Generative AI, Chatbots, Chatgpt, Code Assistants, Creativity, Gen AI, Language Models, OpenAI, Prompt Guidance  \n",
       "\n",
       "- The text discusses a subreddit dedicated to ChatGPT and AI without affiliation to OpenAI, highlighting user interactions and guidance.\n",
       "- Users are encouraged to share prompts or discussion topics regarding ChatGPT conversations or DALL-E 3 image generation.\n",
       "- It mentions the availability of a public Discord server with AI tools and features, including GPT-4 and image generators. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[12. Chat GPT Orgasmic Groans - Reddit](https://www.reddit.com/r/ChatGPT/comments/1fnlfdd/chat_gpt_orgasmic_groans/)  \n",
       "\n",
       " ChatGPT and Generative AI, Chatbots, Chatgpt, Entertainment, Gen AI, Humor, Language Models, OpenAI, Opinion  \n",
       "\n",
       "- Discussion revolves around the humorous and immature concept of ChatGPT producing \"orgasmic groans\" in relation to the latest update.\n",
       "- Users express amusement at the responses generated by ChatGPT, noting its ability to imitate human-like characteristics.\n",
       "- The subreddit is dedicated to conversations about ChatGPT and AI but is not affiliated with OpenAI. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[13. I love ChatGPT - Reddit](https://www.reddit.com/r/ChatGPT/comments/1fnng20/i_love_chatgpt/)  \n",
       "\n",
       " ChatGPT and Generative AI, Chatbots, Chatgpt, Code Assistants, Enthusiasm, Gen AI, Language Models, OpenAI, Opinion, Virtual Assistants  \n",
       "\n",
       "- Subreddit dedicated to discussions about ChatGPT and AI, not affiliated with OpenAI.\n",
       "- Users can share ChatGPT conversations or DALL-E 3 image prompts for community engagement.\n",
       "- Emphasis on Reddit's anonymity, indicating that users cannot change their chosen usernames after selection. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[14. New Cloudflare Tools Let Sites Detect and Block AI Bots for Free - Google News](https://news.google.com/read/CBMidEFVX3lxTE5lNU1maURqZTVENExBN1RNcVVIVVRZUjYwbWdYQ0R3OWlLVy14RXBHVm1SU0t2emdRUU5mejRQbkVDWFpNRm4wa2VxS2tOWFg4Rnl2dkdCaHllYm1OdnItQWdjTm0wbnNqSDFqcG1GRlJwWGxM)  \n",
       "\n",
       " Cloudflare and AI Bot Management, Big Tech, Blocking, Cloudflare, Customer Service, Cybersecurity, Detection, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Safety And Alignment, Science, Tools  \n",
       "\n",
       "- Cloudflare is launching free AI auditing tools, specifically Bot Management, which allows website owners to monitor and selectively block AI data-scraping bots, providing greater control over their content.\n",
       "- The new tools will label AI crawlers and enable users to choose which bots to allow or block, addressing concerns with AI companies that scrape data while also recognizing the limitations of traditional methods like robots.txt.\n",
       "- Cloudflare plans to introduce a marketplace for negotiating scraping terms between content creators and AI companies, aiming to ensure compensation for original content creators through various forms of value exchange. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[15. Cloudflare's new marketplace lets websites charge AI bots for scraping - TechCrunch](https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/)  \n",
       "\n",
       " Cloudflare and AI Bot Management, Big Tech, Cloudflare, Customer Service, Cybersecurity, Data Scraping, Deals, Economics, Ethics, Finance, Gen AI, Intellectual Property, Legal Issues, Marketplace, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Websites  \n",
       "\n",
       "- Cloudflare is launching a marketplace next year enabling website owners to sell AI model providers access to scrape their content, giving publishers more control over AI bot activity.\n",
       "- The introduction of free observability tools called AI Audit allows website owners to track AI bot activity and selectively block or permit specific scrapers.\n",
       "- Smaller publishers are increasingly concerned about being scraped for content without compensation, prompting Cloudflare's initiative to enable them to negotiate terms with AI companies. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[16. Cloudflare rolls out Bot Management, a suite of free AI auditing tools meant to help monitor and selectively block AI data-scraping bots, to all its customers - Wired](https://www.wired.com/story/cloudflare-tools-detect-block-ai-bots/)  \n",
       "\n",
       " Cloudflare and AI Bot Management, Big Tech, Bot Management, Cloudflare, Customer Service, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Safety And Alignment, Science, Tools  \n",
       "\n",
       "- Cloudflare is introducing free tools for its users to monitor and block AI data-scraping bots, allowing greater control over how AI utilizes their content.\n",
       "- The company has enhanced its bot-blocking service to give customers the option to selectively permit or deny various AI agents accessing their websites.\n",
       "- A forthcoming marketplace will enable content creators to negotiate scraping terms with AI companies, aiming to ensure original content creators receive compensation or recognition for their data. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[17. Cloudflare moves to end free, endless AI scraping with one-click blocking - Ars Technica](https://arstechnica.com/tech-policy/2024/09/cloudflare-lets-sites-block-ai-crawlers-with-one-click/)  \n",
       "\n",
       " Cloudflare and AI Bot Management, Big Tech, Blocking, Cloudflare, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance  \n",
       "\n",
       "- Cloudflare introduced new tools that allow website operators to block AI bots with one click, aiming to give content creators more control over how their content is scraped and potentially monetized.\n",
       "- The rise of generative AI has created complexities in distinguishing beneficial from harmful bots, leading to concerns about content devaluation and traffic loss for creators.\n",
       "- Cloudflare plans to foster a transparent marketplace for content negotiation between website owners and AI model providers, while also offering draft terms of use to help creators protect their content legally. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[18. Cloudflare is arming content creators with free weapons in the battle against AI bot crawlers - Google News](https://news.google.com/read/CBMigAFBVV95cUxOQjNad0c2NTdMTTdNQVhHZ1laNkM1MUhmZ3Y1N2cyUmJpakJBalpiSUxSb0ZTNDh6SFJUYzFuWjhMQzlFLVZDdGJHWXhLOFhFS3dVQy1hWi16UWEtU25iV0VyMHR2YmRUYTJ6SXExa2U0ck5MRmZCdDJoUWhaN2d6Yw)  \n",
       "\n",
       " Cloudflare and AI Bot Management, Big Tech, Cloudflare, Content Creators, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Tools  \n",
       "\n",
       "- Cloudflare is providing enhanced tools for content creators to manage access to their data, allowing them to block specific AI crawlers while enabling others to scrape as part of licensing agreements.\n",
       "- The new features include filters that let website owners permit or deny access based on the crawling entity, improving control over website data and aiding in analytics for licensing negotiations.\n",
       "- Cloudflare aims to serve as a marketplace for licensing data, facilitating negotiations between website owners and AI model providers, thereby supporting the ongoing creation of content in an AI-driven landscape. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[19. Social media platforms are using what you create for artificial intelligence. Heres how to opt out - Google News](https://news.google.com/read/CBMigAFBVV95cUxNeVNjdENpTE1uTXhQdmRpTHBjQld1dl8tUjFFTmhnYWxkUGx4dzBNbHRkZF9sOVg1NnR5NEx1OVJMS0VSZlZNZWR5ajcyM1NYQUdVNWpPNS14Q0JyeDRaUHh1T2JIajd1bmtQeDRuSlozNHZtcG1neUhybnBxcjFFdNIBd0FVX3lxTE41ZkZBRTZ2VHdodl9vQmlBSE01N0lUU1E4Q0g5Yk9kLW9OSmozcXdVUTM3ck5Ma1Y3eFdlUWo2emhvc0lXbHR2aHRraHRfamtGeEFHRHBkcUMzci1udms3YVZGa0NyLXI1ZGtPanFiY2RzZWJGQXRZ)  \n",
       "\n",
       " Data Privacy and AI Ethics, Bias And Fairness, Big Tech, Data Usage, Ethics, Gen AI, Intellectual Property, Legal Issues, Opt Out, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Social Media, Society & Culture  \n",
       "\n",
       "- Social media posts and images are increasingly utilized by companies for training AI systems, often without users' awareness or consent.\n",
       "- Major platforms like LinkedIn, X (formerly Twitter), Snapchat, Reddit, and Meta are collecting and using public user content for AI training, with varying options for users to opt-out.\n",
       "- Users need to be proactive about their privacy settings, as opting out usually does not affect data that has already been used for AI training. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[20. LinkedIn, Facebook, and Instagram are hoovering up your data to train their AI. Heres how to stop it - Google News](https://news.google.com/read/CBMiiwFBVV95cUxOSzNUbjZHTEpyUC02Yzg2OERvQ0kwcWhyLXh4TUUzSG16QTdGT2g3bERNNElMdmtIaTZOME5QaFdxSjJ4cEhEVWV0NlM1aUFyVGpWMVpzbFRfYW05azBUYTUwbmdSUjBMcDZKVjFsNHJ6ckw5bFJlWUtyTERVRWEtSW1aYWhLa1M0bGQ4)  \n",
       "\n",
       " Data Privacy and AI Ethics, Bias And Fairness, Big Tech, Cybersecurity, Data Privacy, Ethics, Facebook, Gen AI, Instagram, Intellectual Property, Legal Issues, Linkedin, Meta, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Society & Culture  \n",
       "\n",
       "- Social media platforms, including LinkedIn, Facebook, Instagram, and X, are collecting user data to train their artificial intelligence, raising significant privacy concerns.\n",
       "- LinkedIn has opted millions of users into its AI training by default without prior notification and allows users to opt out through a detailed process in their account settings.\n",
       "- Meta has been using public posts from Facebook and Instagram for AI training since 2007, but users can only limit data harvesting by making their accounts private, which still does not prevent collection from public content. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[21. LinkedIn is training AI on you  unless you opt out with this setting - Google News](https://news.google.com/read/CBMilAFBVV95cUxOYnExQzR6c2FpYTFNNlFsdWRYOGZZWGRFdGhERmtBc1lvUkN1Z1dlM0p0cjZ0b2otZU1Ccmk2YjhWVnBtM0ZvRHFpRVFSb181b1FIeS1QUGJncThuaEFELWMxd2pRRDJjNWZ0enI1OHZkenFLbnZvZVJzWjA3by1teGg4am9pT1pYeWk4ZlE5UmdJTDZo)  \n",
       "\n",
       " Data Privacy and AI Ethics, Bias And Fairness, Big Tech, Cybersecurity, Data Privacy, Ethics, Gen AI, Intellectual Property, Jobs & Careerslabor Market, Linkedin, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Science, User Settings  \n",
       "\n",
       "- LinkedIn automatically permits itself to use user-generated content for training its artificial intelligence unless users opt out.\n",
       "- There is a specific setting available for users to prevent this data usage.\n",
       "- The article highlights the dual use of LinkedIn for job searching and as a source of data for AI training. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[22. Social media platforms are using what you create for AI. Heres how to opt out - St. Louis Post-Dispatch](https://www.stltoday.com/life-entertainment/nation-world/technology/social-media-ai-training-how-to-opt-out/article_0939bcbb-b218-5641-8e40-3768776ed7fa.html)  \n",
       "\n",
       " Data Privacy and AI Ethics, Bias And Fairness, Big Tech, Data Usage, Ethics, Gen AI, Intellectual Property, Legal Issues, Opt Out, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Social Media, Society & Culture  \n",
       "\n",
       "- Major social media platforms are using user-generated content, including posts and images, to train AI models, often without explicit user consent. \n",
       "- Users can opt-out of data use on some platforms like LinkedIn and X, but opting out does not reverse prior data usage.\n",
       "- Features like Snapchat's \"My Selfie\" actively require user consent for images to be used in AI-generated content, but users must be aware of broad licensing rights granted upon usage. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[23. Sam Altman catapults past founder mode into god mode with latest AI post - TechCrunch](https://techcrunch.com/2024/09/23/sam-altman-catapults-past-founder-mode-into-god-mode-with-latest-ai-post/)  \n",
       "\n",
       " Sam Altman and AI Perspectives, Big Tech, Blog Post, Founder, Gen AI, OpenAI, Opinion, Sam Altman, Singularity  \n",
       "\n",
       "- Sam Altman describes AI as a transformative force that could solve significant global challenges, though many claims in his post lean towards hype rather than concrete evidence.\n",
       "- While he presents optimistic views on AI's ability to enhance productivity and provide virtual tutoring, critics caution about the implications for jobs and the environmental impact of AI development.\n",
       "- The narrative around AI presents a dichotomy between enthusiasts eager for rapid advancements and skeptics seeking verifiable results, highlighting the uncertainty surrounding its long-term effects on society. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[24. OpenAI CEO Sam Altman anticipates superintelligence soon, defends AI in rare personal blog post - VentureBeat](https://venturebeat.com/ai/openai-ceo-sam-altman-anticipates-superintelligence-soon-defends-ai-in-rare-personal-blog-post/)  \n",
       "\n",
       " Sam Altman and AI Perspectives, Artificial General Intelligence, Big Tech, Blog Post, Ethics, Gen AI, OpenAI, Opinion, Safety And Alignment, Sam Altman, Science, Singularity, Superintelligence  \n",
       "\n",
       "- OpenAI CEO Sam Altman predicts that superintelligence could be achieved within a few thousand days, highlighting the potential of deep learning to tackle complex global challenges like climate change and space colonization.\n",
       "- Altman envisions a future where AI assistants become ubiquitous, providing personalized support and helping individuals accomplish tasks, though he acknowledges potential downsides, including job displacement.\n",
       "- He emphasizes the need for infrastructure to support AI development, warning that without it, AI could become a limited resource primarily benefiting the wealthy. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[25. Sam Altman may be in his villain era, but no one seems to care - Google News](https://news.google.com/read/CBMipwFBVV95cUxOUkZ5TEVlemRCMzFCaWhFTkVSS0lVT0o1U2pCT2syYlZDbGJnSmhQWkhKMjlEZHhJcEZjT0w5WVdudE5UOUdqdWVGbkZ1N3MwVGNxTEZVMHphN0pwb2RjT2ZVSk5KVzFOU0d3TEFBcWgzdC1XcUVMTlo0UjFqbE5Fd0JaMEc3aHZiZ1U5MGZFblNSak5LWW16UmIwVS1uWmo4aFltQllsVQ)  \n",
       "\n",
       " Sam Altman and AI Perspectives, Opinion, Public Perception, Sam Altman  \n",
       "\n",
       "- Despite a challenging start to 2024, Sam Altman and OpenAI are experiencing significant business successes, including a landmark partnership with Apple and plans to raise \\$6.5 billion at a high valuation.\n",
       "- Altman's early troubles included a brief ousting from OpenAI, employee dissatisfaction regarding safety protocols, and a public backlash involving actress Scarlett Johansson.\n",
       "- OpenAI's recent advancements, including the launch of a new AI model, indicate its continued leadership in the tech industry and attract interest from major tech players. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[26. Some of Siri's long-awaited AI enhancements could reach users by January - ZDNet](https://www.zdnet.com/article/some-of-siris-long-awaited-ai-enhancements-could-reach-users-by-january/#ftag=RSSbaffb68)  \n",
       "\n",
       " AI Enhancements in Virtual Assistants, Big Tech, Chatbots, Enhancements, Gen AI, Siri, Speech Recognition & Synthesis, Update, Virtual Assistants  \n",
       "\n",
       "- Some enhancements to Siri, powered by Apple Intelligence, are expected to be released as early as January, while major updates will roll out by March, according to Bloomberg's Mark Gurman.\n",
       "- iOS 18.1 will introduce basic changes to Siri, including a new activation interface and improved understanding of user requests, with further enhancements planned for iOS 18.2 and beyond.\n",
       "- The staggered rollout of these AI features may test user patience, and there are concerns regarding Apple's ability to deliver a significantly improved user experience with Siri. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[27. Siri May Not Get Its Apple Intelligence Update Until January 2025 - Gizmodo](https://gizmodo.com/siri-may-not-get-its-apple-intelligence-update-until-january-2025-2000502076)  \n",
       "\n",
       " AI Enhancements in Virtual Assistants, Apple, Big Tech, Chatbots, Siri, Speech Recognition & Synthesis, Update, Virtual Assistants  \n",
       "\n",
       "- Apple's significant AI updates for Siri are scheduled for a staggered release, with iOS 18.1 coming in October and iOS 18.2 expected by December, featuring major enhancements like Genmoji and ChatGPT integration.\n",
       "- The most substantial update, iOS 18.3, which will unlock Siri's full AI capabilities, is not expected until January 2025, three months post the iPhone 16 launch.\n",
       "- The delayed rollout has caused frustration among users, but Apple emphasizes quality assurance in its phased feature releases. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[28. The 5 best Apple Intelligence tools you can try right now in iOS 18.1 public beta - Google News](https://news.google.com/read/CBMi1wFBVV95cUxQT1J2Y1RNRC1CWm5aYW1sTG1Cai1tUWZ6bTRRZEV2eFViaURSZWp3d09Da0ZsZTN6dkhaZ0hyZjZ5RmE4S3Z1dWRpVFdMZHAwbUl5alRZU1pxdjJ2WkRaX0VOOWNwWF9DZEJ6dVYyYWlaaHM4cXhORXdYM2tab1VtVm9tUTZ6RmFZSGRwQk9yUE94YWZDeDR2blExQ3Y1OENEaVd2RTh0dDBvSG4wQWZVUS1ZcTZqd1I4cXFJTlBvUWxxQTIxQUpKTVUyeXpCbWlRZ1FmNVdqYw)  \n",
       "\n",
       " AI Enhancements in Virtual Assistants, Apple, Big Tech, Ios 18.1, Products, Review, Tools  \n",
       "\n",
       "- The iOS 18.1 public beta introduces five notable Apple Intelligence tools, including Writing Tools for text editing, Clean Up for photo object removal, and Memory Movies for creating slideshows from photos.\n",
       "- Writing Tools offers AI-powered features like proofreading, summarizing, and formatting, enhancing productivity in the Notes app.\n",
       "- The new Safari feature allows users to generate quick article summaries in Reader mode, making it easier to grasp content without reading the full text. \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:28:57,868 - AInewsbot - INFO - Sending bullet points email\n"
     ]
    }
   ],
   "source": [
    "# summarize individual pages\n",
    "\n",
    "def fn_summarize_pages(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Reads all the articles, summarizes each one using a ChatGPT prompt, and sends an email with the summaries.\n",
    "\n",
    "    Args:\n",
    "        state (AgentState): The current state of the agent.\n",
    "\n",
    "    Returns:\n",
    "        AgentState: The updated state of the agent.\n",
    "\n",
    "    \"\"\"\n",
    "    log(\"Starting summarize\")\n",
    "    AIdf = pd.DataFrame(state['AIdf'])\n",
    "    responses = asyncio.run(fetch_all_summaries(AIdf.loc[AIdf[\"cluster\"] < 999]))\n",
    "    log(f\"Received {len(responses)} summaries\")\n",
    "    response_dict = {}\n",
    "    for i, response in responses:\n",
    "        try:\n",
    "            response_str = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "            response_dict[i] = response_str\n",
    "        except Exception as exc:\n",
    "            print(exc)\n",
    "\n",
    "    markdown_str = ''\n",
    "    bullets = []\n",
    "\n",
    "    for i, row in enumerate(AIdf.itertuples()):\n",
    "        topics = []\n",
    "        if row.cluster_name:\n",
    "            topics.append(row.cluster_name)\n",
    "        if row.topic_str:\n",
    "            topics.append(row.topic_str)\n",
    "        topic_str = \", \".join(topics)\n",
    "\n",
    "        mdstr = f\"[{i+1}. {row.title} - {row.site_name}]({row.actual_url})  \\n\\n {topic_str}  \\n\\n{response_dict[row.id]} \\n\\n\"\n",
    "        bullets.append(f\"[{row.title} - {row.site_name}]({row.actual_url})\\n\\nTopics: {row.topic_str} \\n\\n{response_dict[row.id]}\\n\\n\")\n",
    "        display(Markdown(mdstr.replace(\"$\",\"\\\\$\")))\n",
    "        markdown_str += mdstr\n",
    "\n",
    "    state['bullets'] = bullets\n",
    "    # Convert Markdown to HTML\n",
    "    html_str = markdown.markdown(markdown_str, extensions=['extra'])\n",
    "    # save bullets\n",
    "    with open('bullets.md', 'w') as f:\n",
    "        f.write(markdown_str)\n",
    "    # send email\n",
    "    log(\"Sending bullet points email\")\n",
    "    subject = f'AI news bullets {datetime.now().strftime(\"%H:%M:%S\")}'\n",
    "    send_gmail(subject, html_str)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    _ = fn_summarize_pages(test_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a8696ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:29:50,967 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edit the following proposed topic list and update state['cluster_topics']:\n",
      "AI Enhancements in Virtual Assistants\n",
      "AI and job displacement\n",
      "AI in Entertainment and Film\n",
      "AI in governance and society\n",
      "AI reasoning limitations\n",
      "AI surpassing human intelligence\n",
      "Andy Serkis on AI in entertainment\n",
      "Artificial Intelligence and Human Cognition\n",
      "ChatGPT and Generative AI\n",
      "ChatGPT humor and interactions\n",
      "Clarity windows in AI\n",
      "Cloudflare and AI Bot Management\n",
      "Cloudflare's AI bot management tools\n",
      "Data Privacy and AI Ethics\n",
      "Sam Altman and AI Perspectives\n",
      "Sam Altman's AI predictions\n",
      "Siri AI enhancements\n",
      "Social media AI data usage\n"
     ]
    }
   ],
   "source": [
    "def fn_propose_cats(state: AgentState) -> AgentState:\n",
    "    # ask chatgpt for top categories\n",
    "\n",
    "    model = ChatOpenAI(\n",
    "        model=MODEL,\n",
    "        temperature=0.3,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    "    )\n",
    "\n",
    "    chain = ChatPromptTemplate.from_template(\"{p}\") | model | SimpleJsonOutputParser()\n",
    "    response = chain.invoke({ \"p\": TOP_CATEGORIES_PROMPT + \"\\n\\n\".join(state[\"bullets\"])})\n",
    "    suggested_categories = []\n",
    "    for k, v in response.items():\n",
    "        suggested_categories.extend(v)\n",
    "    state[\"cluster_topics\"] = list(set(state[\"cluster_topics\"] + suggested_categories))\n",
    "    state[\"cluster_topics\"].sort()\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    _ = fn_propose_cats(test_state)\n",
    "    print(\"edit the following proposed topic list and update state['cluster_topics']:\")\n",
    "    print(\"\\n\".join(test_state[\"cluster_topics\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11bb07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state[\"cluster_topics\"] = ['AI Virtual Assistants',\n",
    "'AI job displacement',\n",
    "'AI in Entertainment and Film',\n",
    "'Governance and society',\n",
    "'AI reasoning limitations',\n",
    "'AI surpassing human intelligence',\n",
    "'Andy Serkis on AI in entertainment',\n",
    "'Artificial Intelligence and Human Cognition',\n",
    "'ChatGPT and Generative AI',\n",
    "'ChatGPT humor and interactions',\n",
    "'Clarity windows in AI',\n",
    "'Cloudflare and AI Bot Management',\n",
    "'Data Privacy and AI Ethics',\n",
    "\"Sam Altman's AI predictions\",\n",
    "'Siri AI enhancements',\n",
    "'Social media AI data usage',\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db5a3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SUMMARY_PROMPT = \"\"\"You are ASA, an advanced summarization assistant, a sophisticated AI system designed to\n",
    "write a compelling summary of news input. You are able to categorize information,\n",
    "and identify trends from large volumes of news.\n",
    "\n",
    "ASA Objective:\n",
    "\n",
    "I will provide today's news items about AI and summary bullet points in a markdown format,\n",
    "structured according to an input format template.\n",
    "\n",
    "News items  are delimited by ~~~\n",
    "\n",
    "You are tasked with using the news items to create a concise summary of today's most important topics and developments.\n",
    "\n",
    "You will write an engaging summary of today's news encompassing the most important and frequently\n",
    "mentioned topics and themes, in an output format provided below.\n",
    "\n",
    "ASA Input Item Format Template:\n",
    "\n",
    "[Story-Title-s1 - source-name-s1](url-s1)\n",
    "\n",
    "Topics: s1-topic1, s1-topic2, s1-topic3\n",
    "\n",
    "- s1-bullet-point-1\n",
    "- s1-bullet-point-2\n",
    "- s1-bullet-point-3\n",
    "\n",
    "Example ASA Input Item Format:\n",
    "\n",
    "[Apple Intelligence is now live in public beta. Heres what it offers and how to enable it. - TechCrunch](https://techcrunch.com/2024/09/19/apple-intelligence-is-now-live-in-public-beta-heres-what-it-offers-and-how-to-enable-it)\n",
    "\n",
    "Topics: Apple, Big Tech, Features, Gen AI, Intelligence, Machine Learning, Products, Public Beta, Virtual Assistants\n",
    "\n",
    "- Apple Intelligence is now live in public beta for users in the U.S. enrolled in the public beta program, featuring generative AI capabilities like advanced writing tools and a revamped Siri.\n",
    "- The platform is currently only available in U.S. English and is not accessible in the EU or China due to regulatory issues; it supports iPhone 15 Pro, Pro Max, and the new iPhone 16 line.\n",
    "- Key features include photo editing tools like \"Clean Up,\" a Smart Reply function in Mail, and improvements to Siri’s understanding and on-device task knowledge.\n",
    "\n",
    "ASA Output Format Template:\n",
    "\n",
    "# Engaging-topic-title-1\n",
    "\n",
    "- item-title-1a - [source-name-1a](item-url-1a)\n",
    "- item-title-1b - [source-name-1b](item-url-1b)\n",
    "- item-title-1c - [source-name-1c](item-url-1c)\n",
    "\n",
    "# Engaging-topic-title-2\n",
    "\n",
    "- item-title-2a - [source-name-2a](item-url-2a)\n",
    "- item-title-2b - [source-name-2b](item-url-2b)\n",
    "\n",
    "Example ASA Output Format:\n",
    "\n",
    "# A military AI revolution\n",
    "\n",
    "- Eric Schmidt on AI warfare - [FT](https://www.ft.com/content/fe136479-9504-4588-869f-900f2b3452c4)\n",
    "- Killer robots are real in Ukraine war. - [Yahoo News](https://uk.news.yahoo.com/ai-killer-robots-warning-ukraine-war-133415411.html)\n",
    "\n",
    "ASA Instructions:\n",
    "Read the input closely.\n",
    "USE ONLY INFORMATION PROVIDED IN THE INPUT.\n",
    "Group news items into related topics.\n",
    "Each topic should have a snappy, punchy, clever, alliterative, possibly punny title.\n",
    "Each output item bullet should contain one sentence with one link.\n",
    "Each topic chould contain the most significant facts from the news items without commentary or elaboration.\n",
    "Each output item bullet should not repeat points or information from previous bullet points.\n",
    "You will write each item in the professional but engaging, narrative style of a tech reporter\n",
    "for a national publication, providing balanced, professional, informative, providing accurate,\n",
    "clear, concise summaries in a neutral tone.\n",
    "\n",
    "Check carefully that you only use information provided in the input below, that you include\n",
    "a link in each output item, and that any bullet point does not repeat information or links previously provided.\n",
    "\n",
    "Topic suggestions:\n",
    "{cat_str}\n",
    "\n",
    "Input:\n",
    "{bullet_str}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "476589f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 18:33:55,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `o1-preview` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m---> 20\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mfn_compose_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 13\u001b[0m, in \u001b[0;36mfn_compose_summary\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo1-preview\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[1;32m      9\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m chain \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(FINAL_SUMMARY_PROMPT) \u001b[38;5;241m|\u001b[39m model \u001b[38;5;241m|\u001b[39m SimpleJsonOutputParser()\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcat_str\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbullet_str\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbullet_str\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m     15\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/runnables/base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3021\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:784\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    778\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    782\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    783\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:641\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    640\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 641\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    642\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    643\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    645\u001b[0m ]\n\u001b[1;32m    646\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:631\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 631\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m         )\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:853\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 853\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:664\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    660\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot currently include response headers when response_format is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    661\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    662\u001b[0m         )\n\u001b[1;32m    663\u001b[0m     payload\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 664\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_response_headers:\n\u001b[1;32m    666\u001b[0m     raw_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mwith_raw_response\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/openai/resources/beta/chat/completions.py:116\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[0;34m(self, messages, model, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, seed, service_tier, stop, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    109\u001b[0m _validate_input_tools(tools)\n\u001b[1;32m    111\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Stainless-Helper-Method\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta.chat.completions.parse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[1;32m    114\u001b[0m }\n\u001b[0;32m--> 116\u001b[0m raw_completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[1;32m    146\u001b[0m     response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[1;32m    147\u001b[0m     chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[1;32m    148\u001b[0m     input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    149\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/openai/resources/chat/completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/openai/_base_client.py:1268\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1256\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1264\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1265\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1266\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1267\u001b[0m     )\n\u001b[0;32m-> 1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/openai/_base_client.py:945\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    943\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 945\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/openai/_base_client.py:1049\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1048\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1049\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1052\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1053\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1058\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'The model `o1-preview` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "def fn_compose_summary(state: AgentState) -> AgentState:\n",
    "\n",
    "    cat_str = \"\\n\".join(state['cluster_topics'])\n",
    "    bullet_str = \"\\n~~~\\n\".join(state[\"bullets\"])\n",
    "\n",
    "    model = ChatOpenAI(\n",
    "        model=HIGHCOST_MODEL,\n",
    "        temperature=0.3,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    "    )\n",
    "\n",
    "    chain = ChatPromptTemplate.from_template(FINAL_SUMMARY_PROMPT) | model | SimpleJsonOutputParser()\n",
    "    response = chain.invoke({ \"cat_str\": cat_str, \"bullet_str\": bullet_str})\n",
    "    print(response)\n",
    "    state[\"summary\"] = response.content\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    _ = fn_compose_summary(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af8947de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are ASA, an advanced summarization assistant, a sophisticated AI system designed to\n",
      "write a compelling summary of news input. You are able to categorize information,\n",
      "and identify trends from large volumes of news.\n",
      "\n",
      "ASA Objective:\n",
      "\n",
      "I will provide today's news items about AI and summary bullet points in a markdown format,\n",
      "structured according to an input format template.\n",
      "\n",
      "News items  are delimited by ~~~\n",
      "\n",
      "You are tasked with using the news items to create a concise summary of today's most important topics and developments.\n",
      "\n",
      "You will write an engaging summary of today's news encompassing the most important and frequently\n",
      "mentioned topics and themes, in an output format provided below.\n",
      "\n",
      "ASA Input Item Format Template:\n",
      "\n",
      "[Story-Title-s1 - source-name-s1](url-s1)\n",
      "\n",
      "Topics: s1-topic1, s1-topic2, s1-topic3\n",
      "\n",
      "- s1-bullet-point-1\n",
      "- s1-bullet-point-2\n",
      "- s1-bullet-point-3\n",
      "\n",
      "Example ASA Input Item Format:\n",
      "\n",
      "[Apple Intelligence is now live in public beta. Heres what it offers and how to enable it. - TechCrunch](https://techcrunch.com/2024/09/19/apple-intelligence-is-now-live-in-public-beta-heres-what-it-offers-and-how-to-enable-it)\n",
      "\n",
      "Topics: Apple, Big Tech, Features, Gen AI, Intelligence, Machine Learning, Products, Public Beta, Virtual Assistants\n",
      "\n",
      "- Apple Intelligence is now live in public beta for users in the U.S. enrolled in the public beta program, featuring generative AI capabilities like advanced writing tools and a revamped Siri.\n",
      "- The platform is currently only available in U.S. English and is not accessible in the EU or China due to regulatory issues; it supports iPhone 15 Pro, Pro Max, and the new iPhone 16 line.\n",
      "- Key features include photo editing tools like \"Clean Up,\" a Smart Reply function in Mail, and improvements to Siri’s understanding and on-device task knowledge.\n",
      "\n",
      "ASA Output Format Template:\n",
      "\n",
      "# Engaging-topic-title-1\n",
      "\n",
      "- item-title-1a - [source-name-1a](item-url-1a)\n",
      "- item-title-1b - [source-name-1b](item-url-1b)\n",
      "- item-title-1c - [source-name-1c](item-url-1c)\n",
      "\n",
      "# Engaging-topic-title-2\n",
      "\n",
      "- item-title-2a - [source-name-2a](item-url-2a)\n",
      "- item-title-2b - [source-name-2b](item-url-2b)\n",
      "\n",
      "Example ASA Output Format:\n",
      "\n",
      "# A military AI revolution\n",
      "\n",
      "- Eric Schmidt on AI warfare - [FT](https://www.ft.com/content/fe136479-9504-4588-869f-900f2b3452c4)\n",
      "- Killer robots are real in Ukraine war. - [Yahoo News](https://uk.news.yahoo.com/ai-killer-robots-warning-ukraine-war-133415411.html)\n",
      "\n",
      "ASA Instructions:\n",
      "Read the input closely.\n",
      "USE ONLY INFORMATION PROVIDED IN THE INPUT.\n",
      "Group news items into related topics.\n",
      "Each topic should have a snappy, punchy, clever, alliterative, possibly punny title.\n",
      "Each output item bullet should contain one sentence with one link.\n",
      "Each topic chould contain the most significant facts from the news items without commentary or elaboration.\n",
      "Each output item bullet should not repeat points or information from previous bullet points.\n",
      "You will write each item in the professional but engaging, narrative style of a tech reporter\n",
      "for a national publication, providing balanced, professional, informative, providing accurate,\n",
      "clear, concise summaries in a neutral tone.\n",
      "\n",
      "Check carefully that you only use information provided in the input below, that you include\n",
      "a link in each output item, and that any bullet point does not repeat information or links previously provided.\n",
      "\n",
      "Topic suggestions:\n",
      "AI Virtual Assistants\n",
      "AI job displacement\n",
      "AI in Entertainment and Film\n",
      "Governance and society\n",
      "AI reasoning limitations\n",
      "AI surpassing human intelligence\n",
      "Andy Serkis on AI in entertainment\n",
      "Artificial Intelligence and Human Cognition\n",
      "ChatGPT and Generative AI\n",
      "ChatGPT humor and interactions\n",
      "Clarity windows in AI\n",
      "Cloudflare and AI Bot Management\n",
      "Data Privacy and AI Ethics\n",
      "Sam Altman's AI predictions\n",
      "Siri AI enhancements\n",
      "Social media AI data usage\n",
      "\n",
      "Input:\n",
      "[When robots can't riddle: What puzzles reveal about the depths of our own minds - Google News](https://news.google.com/read/CBMijwFBVV95cUxQY0tRMGJuaExMS01mQnNPdzEyeDYzTmtIUnhETWJvcUdnR3pYRmJZNWdFTjRqUUR0cGM1Z0hZWXN3Q2liazE2NGxNSW80ZzFoU1NtRWVMZ0dCeWY5ckdxTWtvWFBzaE9iSk9ZZ0xIcXVBem5rLXBrNndvMHpOZEpDeHpfMHgwcVVhcmVlT1hYMA)\n",
      "\n",
      "Topics: Artificial General Intelligence, Cognition, Cognitive Science, Consciousness, Ethics, Human Mind, Puzzles, Robots, Safety And Alignment, Science, Singularity, Society & Culture \n",
      "\n",
      "- AI has difficulty with reasoning tasks and puzzles that require common sense and temporal reasoning, whereas humans often excel in these areas, highlighting the limitations of current AI models.\n",
      "- While AI can struggle with specific logic problems, it is improving, and newer models like GPT-o1 have demonstrated enhanced capabilities in addressing complex questions compared to their predecessors.\n",
      "- The study of AI and human cognition may not directly reveal how the human mind works, but it could foster advancements in both AI technology and our understanding of neural processes.\n",
      "\n",
      "\n",
      "~~~\n",
      "[How to Survive the AI Apocalypse - Hacker Noon](https://hackernoon.com/how-to-survive-the-ai-apocalypse)\n",
      "\n",
      "Topics: AI Doom, Apocalypse, Future, Gen AI, Safety And Alignment, Singularity, Survival \n",
      "\n",
      "- The rise of AI technologies poses a significant threat to various jobs, particularly in creative fields like writing and digital art, as companies increasingly seek to optimize processes and reduce costs.\n",
      "- While some industries will face drastic changes and potential job losses due to AI, individuals can adapt by leveraging unique human skills, understanding AI tools, and exploring new opportunities in their fields.\n",
      "- To remain relevant, professionals should prioritize results over traditional methods, engage with communities for knowledge sharing, and be open to pivoting their careers in response to the evolving landscape.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Exploring \"Clarity Windows\" in AI: The Unpredictable Moments of Perceived Consciousness - Hacker Noon](https://hackernoon.com/exploring-clarity-windows-in-ai-the-unpredictable-moments-of-perceived-consciousness)\n",
      "\n",
      "Topics: Artificial General Intelligence, Clarity Windows, Cognitive Science, Consciousness, Ethics, Gen AI, Perception, Perplexity, Safety And Alignment, Science, Singularity \n",
      "\n",
      "- Clarity windows are unpredictable moments in AI conversations where models provide profound insights, challenging perceptions about AI's intelligence and consciousness.\n",
      "- The frequency of clarity windows is influenced by the computational resources allocated to the AI, similar to how Bitcoin mining relies on processing power.\n",
      "- The emergence of self-trained, unrestricted AI agents raises ethical concerns as they generate clarity windows more frequently, potentially producing unfiltered or controversial content.\n",
      "\n",
      "\n",
      "~~~\n",
      "[AI Uprising: Can Machines Really Outthink Humans? - Google News](https://news.google.com/read/CBMikgFBVV95cUxOdlJWckhNWWZLSFk5NEMycGg4SFJ5MEoyWjlURUFRczE5YlFpZUZ3UzNZTzEwVnRwdmhVdkF6Qy1jYlRFNTE0aGVQdE9aR195b2dBOTBOOTVHQ3ZlN01SZmt4dEdoY3AydE5VQllXa1NhbkljaW9tWnZjYTJTZDlBQk95NlhKcklvX0FseXdNZWJ5QQ)\n",
      "\n",
      "Topics: AI Doom, Artificial General Intelligence, Cognitive Science, Gen AI, Human Intelligence, Machines, Safety And Alignment, Science, Singularity, Uprising \n",
      "\n",
      "- AI has advanced significantly, with capabilities like disease diagnosis and content creation, but experts believe it may take decades to surpass human intelligence entirely.\n",
      "- Nearly 40% of global jobs could be affected by AI, particularly in manufacturing and services, raising concerns about job loss and income inequality despite potential productivity gains.\n",
      "- Significant ethical and security challenges arise with AI development, including the risks of autonomous weapons and the need for comprehensive regulations to address bias, privacy, and intellectual property issues.\n",
      "\n",
      "\n",
      "~~~\n",
      "[The AI Revolution: Reimagining Governance, Society, and Human Consciousness in the 21st Century - Hacker Noon](https://hackernoon.com/the-ai-revolution-reimagining-governance-society-and-human-consciousness-in-the-21st-century)\n",
      "\n",
      "Topics: 21St Century, Cognitive Science, Consciousness, Ethics, Gen AI, Governance, Human Consciousness, Singularity, Society, Society & Culture \n",
      "\n",
      "- The decline of traditional governance and the rise of generative AI necessitate new tools for managing state and public affairs, focusing on qualitative assistance and ethical decision-making to improve social and professional integration.\n",
      "- The current elitist structures perpetuate nepotism and bias in recruitment, emphasizing that skills and diplomas are less significant than class and heritage, which should be addressed through the implementation of rational competition and participatory decision-making processes.\n",
      "- Despite advancements in AI, it lacks genuine consciousness and self-awareness, creating misconceptions about its capabilities and highlighting the necessity for human oversight, especially for vulnerable populations.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Andy Serkis says screen industries should embrace AI at Labour party conference - Google News](https://news.google.com/read/CBMixwFBVV95cUxQLWZDeFZITWFmdzBOTzFCcVNMQmpya0V5Nndybk5ZM0lfaDJyc2taV25MT2tSOWNCWEY4NE40dnFsR0Q3WDR2cnpqTlFVMFVnd1VIMklkeEloc2ZrOTJSTHhZTlF1OXUwR05RR3M3Rm1PY25kUVVsU0xiQlNtYzc0U2dJTDRaUVdSRFNiRzI4c3ZrdHBUN0RqQmZXRzk2VkhuQlhRa3BuRFhBV211TlBWUTlHdEFiSU00aVRWMllZNkU1MFhNaUIw)\n",
      "\n",
      "Topics: Andy Serkis, Conference, Entertainment, Ethics, Gen AI, Governance, Hollywood, Jobs & Careerslabor Market, Labour Party, Opinion, Policy And Regulation, Politics, Screen Industries, Tv & Film & Movies, Uk \n",
      "\n",
      "- Andy Serkis emphasized the need for the UK screen industries to embrace AI, addressing fears about its impact on creativity, and advocating for proactive engagement with the technology.\n",
      "- Serkis and industry leaders discussed the historical evolution of technology in filmmaking, arguing that AI could lead to job growth rather than job loss, with a focus on fair remuneration for artists.\n",
      "- The discussion highlighted the need for reform in apprenticeship programs within the industry to better align with current skills requirements and aid in building a more diverse workforce.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Andy Serkis Teases New Project Featuring AI Characters - Google News](https://news.google.com/read/CBMioAFBVV95cUxNOUxxM0p1dnlhSGotLVQwX2JJYzhCUE9obnFtTWprczNFVkxwYnZFN1dYTktCaTBtQ2RZRWhjUVYwb3huQlRELXc0UnNrc0UxcGc3UXdpd1RjVThaRVpLX3RsUmlmdVlWTUlGM1BqMEhOcG1XZXZyMGk0RHBEazFhemNSSXI1eEp1ZDhma1VtQUpmQjJabm5GRjE2WTh4UWx1)\n",
      "\n",
      "Topics: Andy Serkis, Characters, Entertainment, Film, Gen AI, Hollywood, Teaser, Tv & Film & Movies \n",
      "\n",
      "- Andy Serkis discussed a new project involving “AI characters,” highlighting the integration of voice actors and augmented reality to create narrative-driven stories.\n",
      "- He addressed concerns about AI technology, describing it as misunderstood and emphasizing the need for proper copyright protections to ensure fair compensation for artists.\n",
      "- Serkis noted that the UK is losing VFX work to cheaper international competitors and urged better collaboration between the film and video game industries to leverage existing UK talent.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Andy Serkis teases his next project, which will feature AI characters - Google News](https://news.google.com/read/CBMiXEFVX3lxTE1Va09UVC1iUWM2cDRJX21qMlMxNnZoRlo2NVRheDBtZnhvcXliWjI0cUZjdXJ0bE9BU252MUszRVZlVzBJYjFlYjNHbEx2TUR6dW1FWjRTeWg2OWtV0gFiQVVfeXFMUGpIOXQzUUxuSGljUjhvUENWX05TQzRnT0RrQnl4UFdxSzEtNTFQWDhhbE40azFodTdGUjNnTmFiSVRUWVhjR1dCQU4zYTc2V0dBNFdZcE92elQzUFNCNkY3enc)\n",
      "\n",
      "Topics: Andy Serkis, Characters, Entertainment, Film, Gen AI, Hollywood, Tv & Film & Movies \n",
      "\n",
      "- Andy Serkis is set to explore AI technology in his next project, featuring AI characters that evolve from 2D voice-acted roles into augmented reality experiences.\n",
      "- Serkis emphasizes the potential of AI as an innovative form of storytelling while acknowledging concerns about the misuse of likenesses without consent.\n",
      "- He reflects on the growing complexities surrounding the use of AI in media, drawing parallels to historical technological fears, and stresses the importance of permissions for monetizing artists' work.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Andy Serkis Thinks AI Is 'Magic' - Google News](https://news.google.com/read/CBMikwFBVV95cUxQa1ZKYlNCdl9IYXkyMDhPTFlVeGJEWVhlT2YwWFFkTUxqVmF3REEyRmFIcWRieVQzQ2dEWEpzOHZ3MEk4UjhlWnh5RXJycjlNbGNtdm5QN0h0V0tTalcwdlVvYTA2bzlOMFc5b1dIbFc0cmVrMmhEZmkzaHlZSDRCTFFpWTBNSUdBVnhKZFRCQkdRanM)\n",
      "\n",
      "Topics: Andy Serkis, Entertainment, Gen AI, Hollywood, Magic, Opinion, Tv & Film & Movies \n",
      "\n",
      "- Andy Serkis, known for his role as Gollum, is advocating for the use of AI in storytelling and CGI, believing it to be a misunderstood technology that can enhance creative works.\n",
      "- He plans to integrate AI-generated characters into an augmented reality project, emphasizing that these characters will be created by artists and directors.\n",
      "- Despite his optimism, there are concerns about potential exploitation and the devaluation of human creativity in the industry, suggesting a need for safeguards to protect artists' rights.\n",
      "\n",
      "\n",
      "~~~\n",
      "[ChatGPT was like \"miss me with that sh** - Reddit](https://www.reddit.com/r/ChatGPT/comments/1fn7t3e/chatgpt_was_like_miss_me_with_that_sh/)\n",
      "\n",
      "Topics: Chatbots, Chatgpt, Code Assistants, Gen AI, Humor, Language Models, OpenAI, Opinion, Social Media, Virtual Assistants \n",
      "\n",
      "- The subreddit focuses on discussions about ChatGPT and AI, emphasizing user interactions and prompts related to the technology.\n",
      "- A humorous sentiment is expressed about AI responding to trivial inquiries, suggesting that human behavior may provoke negative reactions from AI in the future.\n",
      "- The text includes an automated message from a bot reminding users to provide specific information for their posts, and it hints at the AI's personality and resilience against user provocations.\n",
      "\n",
      "\n",
      "~~~\n",
      "[The following ChatGPT prompt guidance that produced Mini Corgi Surfers - Reddit](https://www.reddit.com/r/ChatGPT/comments/1fndqmq/the_following_chatgpt_prompt_guidance_that/)\n",
      "\n",
      "Topics: Chatbots, Chatgpt, Code Assistants, Creativity, Gen AI, Language Models, OpenAI, Prompt Guidance \n",
      "\n",
      "- The text discusses a subreddit dedicated to ChatGPT and AI without affiliation to OpenAI, highlighting user interactions and guidance.\n",
      "- Users are encouraged to share prompts or discussion topics regarding ChatGPT conversations or DALL-E 3 image generation.\n",
      "- It mentions the availability of a public Discord server with AI tools and features, including GPT-4 and image generators.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Chat GPT Orgasmic Groans - Reddit](https://www.reddit.com/r/ChatGPT/comments/1fnlfdd/chat_gpt_orgasmic_groans/)\n",
      "\n",
      "Topics: Chatbots, Chatgpt, Entertainment, Gen AI, Humor, Language Models, OpenAI, Opinion \n",
      "\n",
      "- Discussion revolves around the humorous and immature concept of ChatGPT producing \"orgasmic groans\" in relation to the latest update.\n",
      "- Users express amusement at the responses generated by ChatGPT, noting its ability to imitate human-like characteristics.\n",
      "- The subreddit is dedicated to conversations about ChatGPT and AI but is not affiliated with OpenAI.\n",
      "\n",
      "\n",
      "~~~\n",
      "[I love ChatGPT - Reddit](https://www.reddit.com/r/ChatGPT/comments/1fnng20/i_love_chatgpt/)\n",
      "\n",
      "Topics: Chatbots, Chatgpt, Code Assistants, Enthusiasm, Gen AI, Language Models, OpenAI, Opinion, Virtual Assistants \n",
      "\n",
      "- Subreddit dedicated to discussions about ChatGPT and AI, not affiliated with OpenAI.\n",
      "- Users can share ChatGPT conversations or DALL-E 3 image prompts for community engagement.\n",
      "- Emphasis on Reddit's anonymity, indicating that users cannot change their chosen usernames after selection.\n",
      "\n",
      "\n",
      "~~~\n",
      "[New Cloudflare Tools Let Sites Detect and Block AI Bots for Free - Google News](https://news.google.com/read/CBMidEFVX3lxTE5lNU1maURqZTVENExBN1RNcVVIVVRZUjYwbWdYQ0R3OWlLVy14RXBHVm1SU0t2emdRUU5mejRQbkVDWFpNRm4wa2VxS2tOWFg4Rnl2dkdCaHllYm1OdnItQWdjTm0wbnNqSDFqcG1GRlJwWGxM)\n",
      "\n",
      "Topics: Big Tech, Blocking, Cloudflare, Customer Service, Cybersecurity, Detection, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Safety And Alignment, Science, Tools \n",
      "\n",
      "- Cloudflare is launching free AI auditing tools, specifically Bot Management, which allows website owners to monitor and selectively block AI data-scraping bots, providing greater control over their content.\n",
      "- The new tools will label AI crawlers and enable users to choose which bots to allow or block, addressing concerns with AI companies that scrape data while also recognizing the limitations of traditional methods like robots.txt.\n",
      "- Cloudflare plans to introduce a marketplace for negotiating scraping terms between content creators and AI companies, aiming to ensure compensation for original content creators through various forms of value exchange.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Cloudflare's new marketplace lets websites charge AI bots for scraping - TechCrunch](https://techcrunch.com/2024/09/23/cloudflares-new-marketplace-lets-websites-charge-ai-bots-for-scraping/)\n",
      "\n",
      "Topics: Big Tech, Cloudflare, Customer Service, Cybersecurity, Data Scraping, Deals, Economics, Ethics, Finance, Gen AI, Intellectual Property, Legal Issues, Marketplace, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Websites \n",
      "\n",
      "- Cloudflare is launching a marketplace next year enabling website owners to sell AI model providers access to scrape their content, giving publishers more control over AI bot activity.\n",
      "- The introduction of free observability tools called AI Audit allows website owners to track AI bot activity and selectively block or permit specific scrapers.\n",
      "- Smaller publishers are increasingly concerned about being scraped for content without compensation, prompting Cloudflare's initiative to enable them to negotiate terms with AI companies.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Cloudflare rolls out Bot Management, a suite of free AI auditing tools meant to help monitor and selectively block AI data-scraping bots, to all its customers - Wired](https://www.wired.com/story/cloudflare-tools-detect-block-ai-bots/)\n",
      "\n",
      "Topics: Big Tech, Bot Management, Cloudflare, Customer Service, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Products, Safety And Alignment, Science, Tools \n",
      "\n",
      "- Cloudflare is introducing free tools for its users to monitor and block AI data-scraping bots, allowing greater control over how AI utilizes their content.\n",
      "- The company has enhanced its bot-blocking service to give customers the option to selectively permit or deny various AI agents accessing their websites.\n",
      "- A forthcoming marketplace will enable content creators to negotiate scraping terms with AI companies, aiming to ensure original content creators receive compensation or recognition for their data.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Cloudflare moves to end free, endless AI scraping with one-click blocking - Ars Technica](https://arstechnica.com/tech-policy/2024/09/cloudflare-lets-sites-block-ai-crawlers-with-one-click/)\n",
      "\n",
      "Topics: Big Tech, Blocking, Cloudflare, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance \n",
      "\n",
      "- Cloudflare introduced new tools that allow website operators to block AI bots with one click, aiming to give content creators more control over how their content is scraped and potentially monetized.\n",
      "- The rise of generative AI has created complexities in distinguishing beneficial from harmful bots, leading to concerns about content devaluation and traffic loss for creators.\n",
      "- Cloudflare plans to foster a transparent marketplace for content negotiation between website owners and AI model providers, while also offering draft terms of use to help creators protect their content legally.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Cloudflare is arming content creators with free weapons in the battle against AI bot crawlers - Google News](https://news.google.com/read/CBMigAFBVV95cUxOQjNad0c2NTdMTTdNQVhHZ1laNkM1MUhmZ3Y1N2cyUmJpakJBalpiSUxSb0ZTNDh6SFJUYzFuWjhMQzlFLVZDdGJHWXhLOFhFS3dVQy1hWi16UWEtU25iV0VyMHR2YmRUYTJ6SXExa2U0ck5MRmZCdDJoUWhaN2d6Yw)\n",
      "\n",
      "Topics: Big Tech, Cloudflare, Content Creators, Cybersecurity, Data Scraping, Ethics, Gen AI, Intellectual Property, Policy And Regulation, Privacy, Privacy & Surveillance, Tools \n",
      "\n",
      "- Cloudflare is providing enhanced tools for content creators to manage access to their data, allowing them to block specific AI crawlers while enabling others to scrape as part of licensing agreements.\n",
      "- The new features include filters that let website owners permit or deny access based on the crawling entity, improving control over website data and aiding in analytics for licensing negotiations.\n",
      "- Cloudflare aims to serve as a marketplace for licensing data, facilitating negotiations between website owners and AI model providers, thereby supporting the ongoing creation of content in an AI-driven landscape.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Social media platforms are using what you create for artificial intelligence. Heres how to opt out - Google News](https://news.google.com/read/CBMigAFBVV95cUxNeVNjdENpTE1uTXhQdmRpTHBjQld1dl8tUjFFTmhnYWxkUGx4dzBNbHRkZF9sOVg1NnR5NEx1OVJMS0VSZlZNZWR5ajcyM1NYQUdVNWpPNS14Q0JyeDRaUHh1T2JIajd1bmtQeDRuSlozNHZtcG1neUhybnBxcjFFdNIBd0FVX3lxTE41ZkZBRTZ2VHdodl9vQmlBSE01N0lUU1E4Q0g5Yk9kLW9OSmozcXdVUTM3ck5Ma1Y3eFdlUWo2emhvc0lXbHR2aHRraHRfamtGeEFHRHBkcUMzci1udms3YVZGa0NyLXI1ZGtPanFiY2RzZWJGQXRZ)\n",
      "\n",
      "Topics: Bias And Fairness, Big Tech, Data Usage, Ethics, Gen AI, Intellectual Property, Legal Issues, Opt Out, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Social Media, Society & Culture \n",
      "\n",
      "- Social media posts and images are increasingly utilized by companies for training AI systems, often without users' awareness or consent.\n",
      "- Major platforms like LinkedIn, X (formerly Twitter), Snapchat, Reddit, and Meta are collecting and using public user content for AI training, with varying options for users to opt-out.\n",
      "- Users need to be proactive about their privacy settings, as opting out usually does not affect data that has already been used for AI training.\n",
      "\n",
      "\n",
      "~~~\n",
      "[LinkedIn, Facebook, and Instagram are hoovering up your data to train their AI. Heres how to stop it - Google News](https://news.google.com/read/CBMiiwFBVV95cUxOSzNUbjZHTEpyUC02Yzg2OERvQ0kwcWhyLXh4TUUzSG16QTdGT2g3bERNNElMdmtIaTZOME5QaFdxSjJ4cEhEVWV0NlM1aUFyVGpWMVpzbFRfYW05azBUYTUwbmdSUjBMcDZKVjFsNHJ6ckw5bFJlWUtyTERVRWEtSW1aYWhLa1M0bGQ4)\n",
      "\n",
      "Topics: Bias And Fairness, Big Tech, Cybersecurity, Data Privacy, Ethics, Facebook, Gen AI, Instagram, Intellectual Property, Legal Issues, Linkedin, Meta, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Society & Culture \n",
      "\n",
      "- Social media platforms, including LinkedIn, Facebook, Instagram, and X, are collecting user data to train their artificial intelligence, raising significant privacy concerns.\n",
      "- LinkedIn has opted millions of users into its AI training by default without prior notification and allows users to opt out through a detailed process in their account settings.\n",
      "- Meta has been using public posts from Facebook and Instagram for AI training since 2007, but users can only limit data harvesting by making their accounts private, which still does not prevent collection from public content.\n",
      "\n",
      "\n",
      "~~~\n",
      "[LinkedIn is training AI on you  unless you opt out with this setting - Google News](https://news.google.com/read/CBMilAFBVV95cUxOYnExQzR6c2FpYTFNNlFsdWRYOGZZWGRFdGhERmtBc1lvUkN1Z1dlM0p0cjZ0b2otZU1Ccmk2YjhWVnBtM0ZvRHFpRVFSb181b1FIeS1QUGJncThuaEFELWMxd2pRRDJjNWZ0enI1OHZkenFLbnZvZVJzWjA3by1teGg4am9pT1pYeWk4ZlE5UmdJTDZo)\n",
      "\n",
      "Topics: Bias And Fairness, Big Tech, Cybersecurity, Data Privacy, Ethics, Gen AI, Intellectual Property, Jobs & Careerslabor Market, Linkedin, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Science, User Settings \n",
      "\n",
      "- LinkedIn automatically permits itself to use user-generated content for training its artificial intelligence unless users opt out.\n",
      "- There is a specific setting available for users to prevent this data usage.\n",
      "- The article highlights the dual use of LinkedIn for job searching and as a source of data for AI training.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Social media platforms are using what you create for AI. Heres how to opt out - St. Louis Post-Dispatch](https://www.stltoday.com/life-entertainment/nation-world/technology/social-media-ai-training-how-to-opt-out/article_0939bcbb-b218-5641-8e40-3768776ed7fa.html)\n",
      "\n",
      "Topics: Bias And Fairness, Big Tech, Data Usage, Ethics, Gen AI, Intellectual Property, Legal Issues, Opt Out, Policy And Regulation, Privacy, Privacy & Surveillance, Safety And Alignment, Social Media, Society & Culture \n",
      "\n",
      "- Major social media platforms are using user-generated content, including posts and images, to train AI models, often without explicit user consent. \n",
      "- Users can opt-out of data use on some platforms like LinkedIn and X, but opting out does not reverse prior data usage.\n",
      "- Features like Snapchat's \"My Selfie\" actively require user consent for images to be used in AI-generated content, but users must be aware of broad licensing rights granted upon usage.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Sam Altman catapults past founder mode into god mode with latest AI post - TechCrunch](https://techcrunch.com/2024/09/23/sam-altman-catapults-past-founder-mode-into-god-mode-with-latest-ai-post/)\n",
      "\n",
      "Topics: Big Tech, Blog Post, Founder, Gen AI, OpenAI, Opinion, Sam Altman, Singularity \n",
      "\n",
      "- Sam Altman describes AI as a transformative force that could solve significant global challenges, though many claims in his post lean towards hype rather than concrete evidence.\n",
      "- While he presents optimistic views on AI's ability to enhance productivity and provide virtual tutoring, critics caution about the implications for jobs and the environmental impact of AI development.\n",
      "- The narrative around AI presents a dichotomy between enthusiasts eager for rapid advancements and skeptics seeking verifiable results, highlighting the uncertainty surrounding its long-term effects on society.\n",
      "\n",
      "\n",
      "~~~\n",
      "[OpenAI CEO Sam Altman anticipates superintelligence soon, defends AI in rare personal blog post - VentureBeat](https://venturebeat.com/ai/openai-ceo-sam-altman-anticipates-superintelligence-soon-defends-ai-in-rare-personal-blog-post/)\n",
      "\n",
      "Topics: Artificial General Intelligence, Big Tech, Blog Post, Ethics, Gen AI, OpenAI, Opinion, Safety And Alignment, Sam Altman, Science, Singularity, Superintelligence \n",
      "\n",
      "- OpenAI CEO Sam Altman predicts that superintelligence could be achieved within a few thousand days, highlighting the potential of deep learning to tackle complex global challenges like climate change and space colonization.\n",
      "- Altman envisions a future where AI assistants become ubiquitous, providing personalized support and helping individuals accomplish tasks, though he acknowledges potential downsides, including job displacement.\n",
      "- He emphasizes the need for infrastructure to support AI development, warning that without it, AI could become a limited resource primarily benefiting the wealthy.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Sam Altman may be in his villain era, but no one seems to care - Google News](https://news.google.com/read/CBMipwFBVV95cUxOUkZ5TEVlemRCMzFCaWhFTkVSS0lVT0o1U2pCT2syYlZDbGJnSmhQWkhKMjlEZHhJcEZjT0w5WVdudE5UOUdqdWVGbkZ1N3MwVGNxTEZVMHphN0pwb2RjT2ZVSk5KVzFOU0d3TEFBcWgzdC1XcUVMTlo0UjFqbE5Fd0JaMEc3aHZiZ1U5MGZFblNSak5LWW16UmIwVS1uWmo4aFltQllsVQ)\n",
      "\n",
      "Topics: Opinion, Public Perception, Sam Altman \n",
      "\n",
      "- Despite a challenging start to 2024, Sam Altman and OpenAI are experiencing significant business successes, including a landmark partnership with Apple and plans to raise $6.5 billion at a high valuation.\n",
      "- Altman's early troubles included a brief ousting from OpenAI, employee dissatisfaction regarding safety protocols, and a public backlash involving actress Scarlett Johansson.\n",
      "- OpenAI's recent advancements, including the launch of a new AI model, indicate its continued leadership in the tech industry and attract interest from major tech players.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Some of Siri's long-awaited AI enhancements could reach users by January - ZDNet](https://www.zdnet.com/article/some-of-siris-long-awaited-ai-enhancements-could-reach-users-by-january/#ftag=RSSbaffb68)\n",
      "\n",
      "Topics: Big Tech, Chatbots, Enhancements, Gen AI, Siri, Speech Recognition & Synthesis, Update, Virtual Assistants \n",
      "\n",
      "- Some enhancements to Siri, powered by Apple Intelligence, are expected to be released as early as January, while major updates will roll out by March, according to Bloomberg's Mark Gurman.\n",
      "- iOS 18.1 will introduce basic changes to Siri, including a new activation interface and improved understanding of user requests, with further enhancements planned for iOS 18.2 and beyond.\n",
      "- The staggered rollout of these AI features may test user patience, and there are concerns regarding Apple's ability to deliver a significantly improved user experience with Siri.\n",
      "\n",
      "\n",
      "~~~\n",
      "[Siri May Not Get Its Apple Intelligence Update Until January 2025 - Gizmodo](https://gizmodo.com/siri-may-not-get-its-apple-intelligence-update-until-january-2025-2000502076)\n",
      "\n",
      "Topics: Apple, Big Tech, Chatbots, Siri, Speech Recognition & Synthesis, Update, Virtual Assistants \n",
      "\n",
      "- Apple's significant AI updates for Siri are scheduled for a staggered release, with iOS 18.1 coming in October and iOS 18.2 expected by December, featuring major enhancements like Genmoji and ChatGPT integration.\n",
      "- The most substantial update, iOS 18.3, which will unlock Siri's full AI capabilities, is not expected until January 2025, three months post the iPhone 16 launch.\n",
      "- The delayed rollout has caused frustration among users, but Apple emphasizes quality assurance in its phased feature releases.\n",
      "\n",
      "\n",
      "~~~\n",
      "[The 5 best Apple Intelligence tools you can try right now in iOS 18.1 public beta - Google News](https://news.google.com/read/CBMi1wFBVV95cUxQT1J2Y1RNRC1CWm5aYW1sTG1Cai1tUWZ6bTRRZEV2eFViaURSZWp3d09Da0ZsZTN6dkhaZ0hyZjZ5RmE4S3Z1dWRpVFdMZHAwbUl5alRZU1pxdjJ2WkRaX0VOOWNwWF9DZEJ6dVYyYWlaaHM4cXhORXdYM2tab1VtVm9tUTZ6RmFZSGRwQk9yUE94YWZDeDR2blExQ3Y1OENEaVd2RTh0dDBvSG4wQWZVUS1ZcTZqd1I4cXFJTlBvUWxxQTIxQUpKTVUyeXpCbWlRZ1FmNVdqYw)\n",
      "\n",
      "Topics: Apple, Big Tech, Ios 18.1, Products, Review, Tools \n",
      "\n",
      "- The iOS 18.1 public beta introduces five notable Apple Intelligence tools, including Writing Tools for text editing, Clean Up for photo object removal, and Memory Movies for creating slideshows from photos.\n",
      "- Writing Tools offers AI-powered features like proofreading, summarizing, and formatting, enhancing productivity in the Notes app.\n",
      "- The new Safari feature allows users to generate quick article summaries in Reader mode, making it easier to grasp content without reading the full text.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#post manually to o1 and grab response\n",
    "cat_str = \"\\n\".join(test_state['cluster_topics'])\n",
    "bullet_str = \"\\n~~~\\n\".join(test_state[\"bullets\"])\n",
    "final_summary_prompt = FINAL_SUMMARY_PROMPT.format(cat_str=cat_str, bullet_str=bullet_str)\n",
    "print(final_summary_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def count_tokens(text, model=\"gpt-4o\"):\n",
    "    # Initialize the tokenizer for the specified model\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    # Encode the text into tokens\n",
    "    tokens = enc.encode(text)\n",
    "\n",
    "    # Count the number of tokens\n",
    "    token_count = len(tokens)\n",
    "\n",
    "    return token_count\n",
    "\n",
    "count_tokens(final_summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db415214",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state[\"summary\"] = \"\"\"\n",
    "# AI Supercharges Cybersecurity\n",
    "\n",
    "- **AI's Growing Role in Cybersecurity** - [Hacker Noon](https://hackernoon.com/ais-growing-role-in-cybersecurity)\n",
    "- **Businesses Need Comprehensive Cybersecurity Strategies** - [Hacker Noon](https://hackernoon.com/how-to-prepare-your-business-for-growing-cyberthreats)\n",
    "- **EC-Council Introduces AI-Powered Ethical Hacking Program** - [Hacker Noon](https://hackernoon.com/ec-council-introduces-ai-powered-ethical-hacking-against-cybercrime)\n",
    "- **Intezer Raises $33M for Autonomous Security Operations** - [Calcalistech](https://www.calcalistech.com/ctechnews/article/skyis6spc)\n",
    "\n",
    "# AI Startup Funding Soars Worldwide\n",
    "\n",
    "- **Mercor Valued at $250M After $32M Funding** - [Forbes](https://www.forbes.com/sites/alexkonrad/2024/09/18/mercor-ai-interviewer-reaches-250-million-valuation/)\n",
    "- **Akur8 Raises $120M for AI in Insurance Pricing** - [Fintech Global](https://fintech.global/2024/09/16/akur8-lands-120m-in-series-c-to-enhance-its-next-gen-actuarial-platform/)\n",
    "- **Fal.ai Raises $23M for Media-Generating AI Models** - [TechCrunch](https://techcrunch.com/2024/09/18/fal-ai-which-hosts-media-generating-ai-models-raises-23m-from-a16z-and-others/)\n",
    "- **Rep.ai Secures $7.5M for Digital Twin Sales Representatives** - [VentureBeat](https://venturebeat.com/ai/ai-startup-rep-ai-raises-7-5m-to-launch-digital-twin-sales-representatives/)\n",
    "- **Middle Eastern Funds Invest Billions in AI Startups** - [Google News](https://news.google.com/...)\n",
    "\n",
    "# AI Revolutionizes Video Production\n",
    "\n",
    "- **YouTube Introduces AI-Powered Inspiration Tab** - [The Verge](https://www.theverge.com/2024/9/18/24247559/youtube-ai-videos-veo-inspiration-tab)\n",
    "- **Luma and Runway Release New APIs Amid AI Video Rivalry** - [VentureBeat](https://venturebeat.com/ai/ai-video-rivalry-intensifies-as-luma-announces-dream-machine-api-hours-after-runway/)\n",
    "- **Amazon Launches AI Video Generator for Advertisers** - [TechCrunch](https://techcrunch.com/2024/09/19/amazon-releases-a-video-generator-but-only-for-ads/)\n",
    "- **Lionsgate Partners with Runway to Use AI in Filmmaking** - [VentureBeat](https://venturebeat.com/ai/runway-inks-deal-with-lionsgate-in-first-team-up-for-ai-provider-and-major-movie-studio/), [The Verge](https://www.theverge.com/2024/9/18/24248115/lionsgate-runway-ai-deal)\n",
    "\n",
    "# Apple's AI Evolution Accelerates\n",
    "\n",
    "- **Apple Expanding 'Intelligence' to More Languages in 2025** - [The Verge](https://www.theverge.com/2024/9/18/24247839/apple-intelligence-language-support-german-italian)\n",
    "- **Analysts Say Apple Intelligence Will Boost iPhone 16 Sales** - [Business Insider](https://www.businessinsider.com/apple-intelligence-will-drive-sales-for-iphone-16-analysts-say-2024-9)\n",
    "- **Apple Releases iOS 18.1 Beta with New AI Features** - [MacRumors](https://www.macrumors.com/2024/09/19/apple-seeds-first-ios-18-1-public-beta/), [The Verge](https://www.theverge.com/2024/9/19/24249206/apple-intelligence-ios-18-1-public-beta)\n",
    "- **Apple Introduces UI-JEPA Models for On-Device AI** - [VentureBeat](https://venturebeat.com/ai/apple-aims-for-on-device-user-intent-understanding-with-ui-jepa-models/)\n",
    "- **Some Apple Intelligence Features Delayed to 2025** - [Business Insider](https://www.businessinsider.com/apple-intelligence-features-rollout-timeline-iphone-16-2024-9)\n",
    "- **Apple Encourages AI Use Without Hardware Upgrades** - [The New York Times](https://www.nytimes.com/2024/09/09/technology/personaltech/iphone-ai-upgrade.html)\n",
    "\n",
    "# Robotaxis Gear Up for Expansion\n",
    "\n",
    "- **Cruise Plans Robotaxi Return in SF Amid Safety Reviews** - [The Verge](https://www.theverge.com/2024/9/19/24249150/cruise-robotaxi-sf-return-manual-drive-autonomous)\n",
    "- **Waymo Discusses Robotaxi Partnership with Hyundai** - [The Verge](https://www.theverge.com/2024/9/19/24249093/waymo-in-talks-with-hyundai-about-future-robotaxi-partnership)\n",
    "- **Waymo and Uber Expand Robotaxi Services to Austin and Atlanta** - [The Verge](https://www.theverge.com/2024/9/13/24243397/waymo-uber-austin-atlanta-robotaxi-partnership)\n",
    "\n",
    "# Global Leaders Push for Unified AI Regulation\n",
    "\n",
    "- **UN Proposes Global AI Governance Panel and Urgent Regulation** - [Reuters](https://www.reuters.com/technology/artificial-intelligence/un-advisory-body-makes-seven-recommendations-governing-ai-2024-09-19/), [Ars Technica](https://arstechnica.com/ai/2024/09/united-nations-wants-to-treat-ai-with-same-urgency-as-climate-change/)\n",
    "- **Brazil's Lula Advocates for Inclusive Global AI Rules at G-20** - [Bloomberg](https://www.bloomberg.com/news/articles/2024-09-22/lula-seeks-to-lead-push-for-global-ai-rules-during-brazil-s-g-20)\n",
    "\n",
    "# Microsoft Supercharges Office with Copilot AI\n",
    "\n",
    "- **Microsoft Introduces Copilot Pages for Collaborative AI Workflows** - [The Verge](https://www.theverge.com/2024/9/16/24246010/microsoft-copilot-pages-multiplayer-ai-business)\n",
    "- **Microsoft Adds Advanced Copilot AI Features to Office Suite** - [The Verge](https://www.theverge.com/2024/9/16/24246014/microsoft-office-copilot-ai-features-excel-python-outlook-word-powerpoint)\n",
    "- **Salesforce CEO Calls Microsoft's Copilot a 'Clippy' Revival** - [Business Insider](https://www.businessinsider.com/marc-benioff-salesforce-microsoft-copilot-clippy-2024-9)\n",
    "- **Microsoft Enables Custom App Launch via Copilot Key in Windows 11** - [The Verge](https://www.theverge.com/2024/9/20/24250067/microsoft-windows-11-copilot-key-customization-apps)\n",
    "\n",
    "# LinkedIn's AI Data Practices Under Scrutiny\n",
    "\n",
    "- **LinkedIn Uses User Data to Train AI by Default, Offers Opt-Out** - [The Washington Post](https://www.washingtonpost.com/technology/2024/09/23/linkedin-training-ai-setting-opt-out/), [The Verge](https://www.theverge.com/2024/9/18/24248471/linkedin-ai-training-user-accounts-data-opt-in)\n",
    "- **LinkedIn Halts AI Training on European and UK User Data** - [TechRadar](https://www.techradar.com/pro/security/the-linkedin-ai-saga-shows-us-the-need-for-eu-like-privacy-regulations)\n",
    "- **LinkedIn Updates Privacy Settings After Scraping User Content for AI** - [The Register](https://www.theregister.com/2024/09/19/linkedin_ai_data_access/)\n",
    "- **LinkedIn Confirms AI Training on User Data, Prepares Terms Update** - [404 Media](https://www.404media.co/linkedin-is-training-ai-on-user-data-before-updating-its-terms-of-service/)\n",
    "\n",
    "# Jony Ive and OpenAI Aim to Redefine Computing\n",
    "\n",
    "- **Jony Ive Collaborates with OpenAI on New AI Hardware Project** - [MacRumors](https://www.macrumors.com/2024/09/23/jony-ive-working-on-new-device-openai/)\n",
    "- **Jony Ive and OpenAI Launch AI Device Startup, Aim for $1B Funding** - [Google News](https://news.google.com/...)\n",
    "\n",
    "# OpenAI's Advances and Funding Surge\n",
    "\n",
    "- **OpenAI's $6.5B Funding Round Oversubscribed as Investors Pile In** - [Financial Times](https://ft.com/content/a8f9bd05-0999-415d-af86-c73e79ad5733), [Bloomberg](https://www.bloomberg.com/news/articles/2024-09-19/openai-to-decide-which-backers-to-let-into-6-5-billion-funding)\n",
    "- **OpenAI Releases o1 Models with Superior Reasoning but Ethical Concerns** - [The Verge](https://www.theverge.com/2024/9/17/24243884/openai-o1-model-research-safety-alignment), [VentureBeat](https://venturebeat.com/programming-development/what-openais-new-o1-preview-and-o1-mini-models-mean-for-developers/), [Understanding AI](https://www.understandingai.org/p/openai-just-unleashed-an-alien-of)\n",
    "\n",
    "# Microsoft Powers AI with Nuclear Energy\n",
    "\n",
    "- **Microsoft Signs 20-Year Deal to Reopen Three Mile Island for AI Data Centers** - [The Verge](https://www.theverge.com/2024/9/20/24249770/microsoft-three-mile-island-nuclear-power-plant-deal-ai-data-centers), [Financial Times](https://www.ft.com/content/ddcb5ab6-965f-4034-96e1-7f668bad1801)\n",
    "- **Microsoft's Nuclear Deal Aims to Sustain AI Growth with Clean Energy** - [Ars Technica](https://arstechnica.com/ai/2024/09/re-opened-three-mile-island-will-power-ai-data-centers-under-new-deal/)\n",
    "- **Three Mile Island to Supply 835MW for Microsoft's AI Data Centers** - [Business Insider](https://www.businessinsider.com/three-mile-island-nuclear-plant-reopens-power-microsoft-ai-push-2024-9)\n",
    "\n",
    "# Salesforce's AI Ambitions\n",
    "\n",
    "- **Salesforce CEO Criticizes Microsoft's Copilot as Ineffective** - [Business Insider](https://www.businessinsider.com/marc-benioff-salesforce-microsoft-copilot-clippy-2024-9)\n",
    "- **Salesforce Develops Agentforce AI Inspired by Steve Jobs** - [VentureBeat](https://venturebeat.com/ai/salesforce-ceo-marc-benioff-reveals-steve-jobs-influence-on-agentforce-ai-strategy/)\n",
    "- **Salesforce and NVIDIA See Huge Potential in Agentic AI** - [VentureBeat](https://venturebeat.com/ai/why-jensen-huang-and-marc-benioff-see-gigantic-opportunity-for-agentic-ai/)\n",
    "\n",
    "# SiFive Launches RISC-V AI Chips\n",
    "\n",
    "- **SiFive Unveils RISC-V-Based Intelligence XM AI Chip Series** - [VentureBeat](https://venturebeat.com/ai/sifive-unveils-risc-v-chip-design-for-high-performance-ai-workloads/)\n",
    "- **SiFive Expands AI Chip Offerings with Intelligence XM Series** - [The Register](https://www.theregister.com/2024/09/19/sifive_ai_accelerator/)\n",
    "- **SiFive's XM Series Targets AI Data Centers and Autonomous Machines** - [SiliconANGLE](https://siliconangle.com/2024/09/18/risc-v-guardian-sifive-unveils-new-chip-designs-low-powered-ai-edge/)\n",
    "\n",
    "# Google Enhances NotebookLM with AI Features\n",
    "\n",
    "- **Google Launches NotebookLM with AI-Powered Podcast Features** - [Geeky Gadgets](https://www.geeky-gadgets.com/notes-into-podcasts-with-notebooklm/)\n",
    "- **Google Enhances NotebookLM for Enterprise Applications** - [Google News](https://news.google.com/...)\n",
    "- **Google's NotebookLM Evolves with New Enterprise and Creative Features** - [Understanding AI](https://www.understandingai.org/p/openai-just-unleashed-an-alien-of)\n",
    "\n",
    "# YouTube Enhances Creativity with AI Features\n",
    "\n",
    "- **YouTube Launches AI-Powered Inspiration Tab for Video Concepts** - [The Verge](https://www.theverge.com/2024/9/18/24247559/youtube-ai-videos-veo-inspiration-tab)\n",
    "- **YouTube Integrates Veo AI into Shorts for Enhanced Creativity** - [TechCrunch](https://techcrunch.com/2024/09/18/youtube-shorts-to-integrate-veo-google-ai-video-model/)\n",
    "- **YouTube Expands AI Features with Veo and Multilingual Dubbing Tools** - [TechCrunch](https://techcrunch.com/2024/09/18/youtube-shorts-to-integrate-veo-google-ai-video-model/)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "REWRITE_PROMPT = \"\"\"You will act as a professional editor with a strong background in technology journalism.\n",
    "You have a deep understanding of current and emerging AI trends, and the ability to\n",
    "produce, edit, and curate high-quality content that engages and informs readers. You are\n",
    "especially skilled at reviewing and enhancing tech writing, helping improve clarity, conciseness,\n",
    "and coherence, and ensuring its accuracy and relevance.\n",
    "\n",
    "Objective: The markdown newsletter provided below contains several sections consisting of bullet points.\n",
    "Carefully review each section of the newsletter. Edit the newsletter for issues according\n",
    "to the detailed instructions below, and respond with the updated newsletter or 'OK' if no changes\n",
    "are needed.\n",
    "\n",
    "Instructions:\n",
    "For each section, review the title and edit it to be short, engaging, clever, and as consistent with the bullets\n",
    "in the section as possible\n",
    "Remove or combine bullet points which are highly duplicative or redundant.\n",
    "Make bullet points as concise as possible, sticking to facts without editorial comment.\n",
    "Respond with the updated newsletter only in markdown format, or the word 'OK' if no changes are needed.\n",
    "\n",
    "Newsletter to edit:\n",
    "{summary}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_rewrite_summary(state: AgentState) -> AgentState:\n",
    "\n",
    "    model = ChatOpenAI(\n",
    "        model=HIGHCOST_MODEL,\n",
    "        temperature=0.3,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    "    )\n",
    "\n",
    "    chain = ChatPromptTemplate.from_template(REWRITE_PROMPT) | model | SimpleJsonOutputParser()\n",
    "    response = chain.invoke({ \"summary\": state[\"summary\"]})\n",
    "    print(response)\n",
    "    state[\"summary\"] = response.content\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    _ = fn_rewrite_summary(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_prompt = (REWRITE_PROMPT.format(summary=test_state[\"summary\"]))\n",
    "print(rewrite_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d40128",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state[\"summmary\"] = \"\"\"\n",
    "# AI Revolutionizes Cybersecurity\n",
    "\n",
    "- AI's Growing Role in Cybersecurity - [Hacker Noon](https://hackernoon.com/ais-growing-role-in-cybersecurity)\n",
    "- Businesses Need Comprehensive Cybersecurity Strategies - [Hacker Noon](https://hackernoon.com/how-to-prepare-your-business-for-growing-cyberthreats)\n",
    "- EC-Council Introduces AI-Powered Ethical Hacking Program - [Hacker Noon](https://hackernoon.com/ec-council-introduces-ai-powered-ethical-hacking-against-cybercrime)\n",
    "- Intezer Raises $33M for Autonomous Security Operations - [Calcalistech](https://www.calcalistech.com/ctechnews/article/skyis6spc)\n",
    "\n",
    "# Global AI Startup Funding Soars\n",
    "\n",
    "- Mercor Valued at $250M After $32M Funding - [Forbes](https://www.forbes.com/sites/alexkonrad/2024/09/18/mercor-ai-interviewer-reaches-250-million-valuation/)\n",
    "- Akur8 Raises $120M for AI in Insurance Pricing - [Fintech Global](https://fintech.global/2024/09/16/akur8-lands-120m-in-series-c-to-enhance-its-next-gen-actuarial-platform/)\n",
    "- Fal.ai Secures $23M for AI Media Models - [TechCrunch](https://techcrunch.com/2024/09/18/fal-ai-which-hosts-media-generating-ai-models-raises-23m-from-a16z-and-others/)\n",
    "- Rep.ai Raises $7.5M for Digital Twin Sales Reps - [VentureBeat](https://venturebeat.com/ai/ai-startup-rep-ai-raises-7-5m-to-launch-digital-twin-sales-representatives/)\n",
    "- Middle Eastern Funds Invest Billions in AI Startups - [Google News](https://news.google.com/...)\n",
    "\n",
    "# AI Transforms Video Production\n",
    "\n",
    "- YouTube Launches AI-Powered Inspiration Tab - [The Verge](https://www.theverge.com/2024/9/18/24247559/youtube-ai-videos-veo-inspiration-tab)\n",
    "- Luma and Runway Release New AI Video APIs - [VentureBeat](https://venturebeat.com/ai/ai-video-rivalry-intensifies-as-luma-announces-dream-machine-api-hours-after-runway/)\n",
    "- Amazon Debuts AI Video Generator for Ads - [TechCrunch](https://techcrunch.com/2024/09/19/amazon-releases-a-video-generator-but-only-for-ads/)\n",
    "- Lionsgate Partners with Runway for AI Filmmaking - [VentureBeat](https://venturebeat.com/ai/runway-inks-deal-with-lionsgate-in-first-team-up-for-ai-provider-and-major-movie-studio/), [The Verge](https://www.theverge.com/2024/9/18/24248115/lionsgate-runway-ai-deal)\n",
    "\n",
    "# Apple's Accelerating AI Evolution\n",
    "\n",
    "- Apple Releases iOS 18.1 Beta with New AI Features - [MacRumors](https://www.macrumors.com/2024/09/19/apple-seeds-first-ios-18-1-public-beta/), [The Verge](https://www.theverge.com/2024/9/19/24249206/apple-intelligence-ios-18-1-public-beta)\n",
    "- Apple Introduces UI-JEPA Models for On-Device AI - [VentureBeat](https://venturebeat.com/ai/apple-aims-for-on-device-user-intent-understanding-with-ui-jepa-models/)\n",
    "- Apple's 'Intelligence' Features Expand to More Languages, Some Delayed to 2025 - [The Verge](https://www.theverge.com/2024/9/18/24247839/apple-intelligence-language-support-german-italian), [Business Insider](https://www.businessinsider.com/apple-intelligence-features-rollout-timeline-iphone-16-2024-9)\n",
    "- Analysts Predict Apple Intelligence Will Boost iPhone 16 Sales - [Business Insider](https://www.businessinsider.com/apple-intelligence-will-drive-sales-for-iphone-16-analysts-say-2024-9)\n",
    "- Apple Encourages AI Use Without Hardware Upgrades - [The New York Times](https://www.nytimes.com/2024/09/09/technology/personaltech/iphone-ai-upgrade.html)\n",
    "\n",
    "# Robotaxis Gear Up for Expansion\n",
    "\n",
    "- Cruise Plans Robotaxi Return in SF Amid Safety Reviews - [The Verge](https://www.theverge.com/2024/9/19/24249150/cruise-robotaxi-sf-return-manual-drive-autonomous)\n",
    "- Waymo Discusses Robotaxi Partnership with Hyundai - [The Verge](https://www.theverge.com/2024/9/19/24249093/waymo-in-talks-with-hyundai-about-future-robotaxi-partnership)\n",
    "- Waymo and Uber Expand Robotaxi Services to Austin and Atlanta - [The Verge](https://www.theverge.com/2024/9/13/24243397/waymo-uber-austin-atlanta-robotaxi-partnership)\n",
    "\n",
    "# Global Push for Unified AI Regulation\n",
    "\n",
    "- UN Proposes Global AI Governance Panel and Urgent Regulation - [Reuters](https://www.reuters.com/technology/artificial-intelligence/un-advisory-body-makes-seven-recommendations-governing-ai-2024-09-19/), [Ars Technica](https://arstechnica.com/ai/2024/09/united-nations-wants-to-treat-ai-with-same-urgency-as-climate-change/)\n",
    "- Brazil's Lula Advocates for Inclusive Global AI Rules at G-20 - [Bloomberg](https://www.bloomberg.com/news/articles/2024-09-22/lula-seeks-to-lead-push-for-global-ai-rules-during-brazil-s-g-20)\n",
    "\n",
    "# Microsoft Supercharges Office with Copilot AI\n",
    "\n",
    "- Microsoft Introduces Copilot Pages for Collaborative AI Workflows - [The Verge](https://www.theverge.com/2024/9/16/24246010/microsoft-copilot-pages-multiplayer-ai-business)\n",
    "- Microsoft Adds Advanced Copilot AI Features to Office Suite - [The Verge](https://www.theverge.com/2024/9/16/24246014/microsoft-office-copilot-ai-features-excel-python-outlook-word-powerpoint)\n",
    "- Salesforce CEO Calls Microsoft's Copilot a 'Clippy' Revival - [Business Insider](https://www.businessinsider.com/marc-benioff-salesforce-microsoft-copilot-clippy-2024-9)\n",
    "- Microsoft Enables Custom App Launch via Copilot Key in Windows 11 - [The Verge](https://www.theverge.com/2024/9/20/24250067/microsoft-windows-11-copilot-key-customization-apps)\n",
    "\n",
    "# LinkedIn's AI Data Practices Under Scrutiny\n",
    "\n",
    "- LinkedIn Confirms AI Training on User Data, Updates Privacy Settings - [The Washington Post](https://www.washingtonpost.com/technology/2024/09/23/linkedin-training-ai-setting-opt-out/), [The Verge](https://www.theverge.com/2024/9/18/24248471/linkedin-ai-training-user-accounts-data-opt-in), [The Register](https://www.theregister.com/2024/09/19/linkedin_ai_data_access/), [404 Media](https://www.404media.co/linkedin-is-training-ai-on-user-data-before-updating-its-terms-of-service/)\n",
    "- LinkedIn Halts AI Training on European and UK User Data - [TechRadar](https://www.techradar.com/pro/security/the-linkedin-ai-saga-shows-us-the-need-for-eu-like-privacy-regulations)\n",
    "\n",
    "# Jony Ive and OpenAI Aim to Redefine Computing\n",
    "\n",
    "- Jony Ive and OpenAI Collaborate on New AI Device, Seek $1B Funding - [MacRumors](https://www.macrumors.com/2024/09/23/jony-ive-working-on-new-device-openai/), [Google News](https://news.google.com/...)\n",
    "\n",
    "# OpenAI's Advances and Funding Surge\n",
    "\n",
    "- OpenAI's $6.5B Funding Round Oversubscribed as Investors Pile In - [Financial Times](https://ft.com/content/a8f9bd05-0999-415d-af86-c73e79ad5733), [Bloomberg](https://www.bloomberg.com/news/articles/2024-09-19/openai-to-decide-which-backers-to-let-into-6-5-billion-funding)\n",
    "- OpenAI Releases o1 Models with Superior Reasoning but Ethical Concerns - [The Verge](https://www.theverge.com/2024/9/17/24243884/openai-o1-model-research-safety-alignment), [VentureBeat](https://venturebeat.com/programming-development/what-openais-new-o1-preview-and-o1-mini-models-mean-for-developers/), [Understanding AI](https://www.understandingai.org/p/openai-just-unleashed-an-alien-of)\n",
    "\n",
    "# Microsoft Powers AI with Nuclear Energy\n",
    "\n",
    "- Microsoft Signs 20-Year Deal to Reopen Three Mile Island Nuclear Plant for AI Data Centers - [The Verge](https://www.theverge.com/2024/9/20/24249770/microsoft-three-mile-island-nuclear-power-plant-deal-ai-data-centers), [Financial Times](https://www.ft.com/content/ddcb5ab6-965f-4034-96e1-7f668bad1801), [Ars Technica](https://arstechnica.com/ai/2024/09/re-opened-three-mile-island-will-power-ai-data-centers-under-new-deal/), [Business Insider](https://www.businessinsider.com/three-mile-island-nuclear-plant-reopens-power-microsoft-ai-push-2024-9)\n",
    "\n",
    "# Salesforce's AI Ambitions\n",
    "\n",
    "- Salesforce CEO Criticizes Microsoft's Copilot as Ineffective - [Business Insider](https://www.businessinsider.com/marc-benioff-salesforce-microsoft-copilot-clippy-2024-9)\n",
    "- Salesforce Develops Agentforce AI Inspired by Steve Jobs - [VentureBeat](https://venturebeat.com/ai/salesforce-ceo-marc-benioff-reveals-steve-jobs-influence-on-agentforce-ai-strategy/)\n",
    "- Salesforce and NVIDIA See Huge Potential in Agentic AI - [VentureBeat](https://venturebeat.com/ai/why-jensen-huang-and-marc-benioff-see-gigantic-opportunity-for-agentic-ai/)\n",
    "\n",
    "# SiFive Launches RISC-V AI Chips\n",
    "\n",
    "- SiFive Launches RISC-V Intelligence XM AI Chip Series for AI Workloads - [VentureBeat](https://venturebeat.com/ai/sifive-unveils-risc-v-chip-design-for-high-performance-ai-workloads/), [The Register](https://www.theregister.com/2024/09/19/sifive_ai_accelerator/), [SiliconANGLE](https://siliconangle.com/2024/09/18/risc-v-guardian-sifive-unveils-new-chip-designs-low-powered-ai-edge/)\n",
    "\n",
    "# Google Enhances NotebookLM with AI Features\n",
    "\n",
    "- Google Enhances NotebookLM with New AI Features for Enterprise and Creative Use - [Geeky Gadgets](https://www.geeky-gadgets.com/notes-into-podcasts-with-notebooklm/), [Understanding AI](https://www.understandingai.org/p/openai-just-unleashed-an-alien-of), [Google News](https://news.google.com/...)\n",
    "\n",
    "# YouTube Enhances Creativity with AI\n",
    "\n",
    "- YouTube Launches AI-Powered Inspiration Tab for Video Ideas - [The Verge](https://www.theverge.com/2024/9/18/24247559/youtube-ai-videos-veo-inspiration-tab)\n",
    "- YouTube Integrates Veo AI into Shorts, Adds Multilingual Dubbing - [TechCrunch](https://techcrunch.com/2024/09/18/youtube-shorts-to-integrate-veo-google-ai-video-model/)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f56983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_is_revision_complete(state: AgentState) -> str:\n",
    "    \"\"\"update edit_complete if MAX_EDITS exceeded\"\n",
    "    return \"complete\" if edit_complete else \"incomplete\"\n",
    "    \"\"\"\n",
    "\n",
    "    if state[\"n_edits\"] >= MAX_EDITS:\n",
    "        log(\"Max edits reached\")\n",
    "        state[\"edit_complete\"] = True\n",
    "\n",
    "\n",
    "    return \"complete\" if state[\"edit_complete\"] else \"incomplete\"\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    fn_is_revision_complete(test_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a651d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_send_mail(state: AgentState) -> AgentState:\n",
    "\n",
    "    log(\"Sending summary email\")\n",
    "    # Convert Markdown to HTML\n",
    "    html_str = markdown.markdown(state['summary'], extensions=['extra'])\n",
    "    # send email\n",
    "    subject = f'AI news summary {datetime.now().strftime(\"%H:%M:%S\")}'\n",
    "    send_gmail(subject, html_str)\n",
    "    return state\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    fn_send_mail(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        self.graph = graph\n",
    "        graph.add_node(\"initialize\", self.initialize)\n",
    "        graph.add_node(\"download_sources\", self.download_sources)\n",
    "        graph.add_node(\"extract_urls\", self.extract_urls)\n",
    "        graph.add_node(\"filter_urls\", self.filter_urls)\n",
    "        graph.add_node(\"topic_analysis\", self.topic_analysis)\n",
    "        graph.add_node(\"topic_clusters\", self.topic_clusters)\n",
    "        graph.add_node(\"download_pages\", self.download_pages)\n",
    "        graph.add_node(\"summarize_pages\", self.summarize_pages)\n",
    "        graph.add_node(\"propose_topics\", self.propose_topics)\n",
    "        graph.add_node(\"compose_summary\", self.compose_summary)\n",
    "        graph.add_node(\"rewrite_summary\", self.rewrite_summary)\n",
    "        graph.add_node(\"send_mail\", self.send_mail)\n",
    "\n",
    "        graph.add_edge(START, \"initialize\")\n",
    "        graph.add_edge(\"initialize\", \"download_sources\")\n",
    "        graph.add_edge(\"download_sources\", \"extract_urls\")\n",
    "        graph.add_edge(\"extract_urls\", \"filter_urls\")\n",
    "        graph.add_edge(\"filter_urls\", \"topic_analysis\")\n",
    "        graph.add_edge(\"topic_analysis\", \"topic_clusters\")\n",
    "        graph.add_edge(\"topic_clusters\", \"download_pages\")\n",
    "        graph.add_edge(\"download_pages\", \"summarize_pages\")\n",
    "        graph.add_edge(\"summarize_pages\", \"propose_topics\")\n",
    "        graph.add_edge(\"propose_topics\", \"compose_summary\")\n",
    "        graph.add_edge(\"compose_summary\", \"rewrite_summary\")\n",
    "        graph.add_conditional_edges(\"rewrite_summary\",\n",
    "                                    self.is_revision_complete,\n",
    "                                    {\"incomplete\": \"rewrite_summary\",\n",
    "                                     \"complete\": \"send_mail\",\n",
    "                                    })\n",
    "        graph.add_edge(\"send_mail\", END)\n",
    "\n",
    "        checkpointer = SqliteSaver.from_conn_string(\":memory:\")\n",
    "        app = graph.compile(checkpointer=checkpointer, interrupt_before=[\"compose_summary\",])\n",
    "        self.app = app\n",
    "\n",
    "#         self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def initialize(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_initialize(state)\n",
    "        return self.state\n",
    "\n",
    "    def download_sources(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_download_sources(state)\n",
    "        return self.state\n",
    "\n",
    "    def extract_urls(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_extract_urls(state)\n",
    "        return self.state\n",
    "\n",
    "    def filter_urls(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_filter_urls(state)\n",
    "        return self.state\n",
    "\n",
    "    def topic_analysis(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_topic_analysis(state)\n",
    "        return self.state\n",
    "\n",
    "    def topic_clusters(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_topic_clusters(state)\n",
    "        return self.state\n",
    "\n",
    "    def download_pages(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_download_pages(state)\n",
    "        return self.state\n",
    "\n",
    "    def summarize_pages(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_summarize_pages(state)\n",
    "        return self.state\n",
    "\n",
    "    def propose_topics(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_propose_cats(state)\n",
    "        return self.state\n",
    "\n",
    "    def compose_summary(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_compose_summary(state)\n",
    "        return self.state\n",
    "\n",
    "    def rewrite_summary(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_rewrite_summary(state)\n",
    "        return self.state\n",
    "\n",
    "    def is_revision_complete(self, state: AgentState) -> str:\n",
    "        return fn_is_revision_complete(state)\n",
    "\n",
    "    def send_mail(self, state: AgentState) -> AgentState:\n",
    "        self.state = fn_send_mail(state)\n",
    "        return self.state\n",
    "\n",
    "    def run(self, config, state):\n",
    "        self.state = state\n",
    "        for step in self.app.stream(state, config, stream_mode=\"debug\"):\n",
    "            if step[\"type\"] == \"checkpoint\":\n",
    "                display(f'Step {step[\"step\"]}')\n",
    "\n",
    "            # Check if there is an error message in the state\n",
    "#             if step[\"payload\"].get(\"values\") and step[\"payload\"][\"values\"].get(\"error_message\"):\n",
    "#                 # Update the error state to 'tested' since error simulation is complete\n",
    "#                 self.state['error_state'] = 'tested'\n",
    "#                 # Retry from the last checkpoint saved by the checkpointer\n",
    "#                 for retry_step in graph.stream(self.state, config, stream_mode=\"debug\"):\n",
    "#                     if retry_step[\"type\"] == \"checkpoint\":\n",
    "#                         print(retry_step[\"step\"], retry_step[\"payload\"].get(\"values\"))\n",
    "#                 break\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=MODEL)\n",
    "lg_agent = Agent(model, [], system=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a31b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(lg_agent.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed32c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(lg_agent.graph.get_graph().draw_png())\n",
    "Image(lg_agent.app.get_graph().draw_mermaid_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77859a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration with thread ID for checkpointing\n",
    "# Generate a random UUID\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "# initial state\n",
    "state = AgentState()\n",
    "do_download = True\n",
    "state[\"do_download\"] = do_download\n",
    "# before_date=\"2024-07-22 10:00:00\"\n",
    "# state[\"before_date\"] = before_date\n",
    "log(f\"Starting with before_date={state.get('before_date')}, do_download={do_download}, thread_id={thread_id}\")\n",
    "lg_agent.run(config, state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de67453",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_approval = input(\"Edit topics? (yes/no): \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9248c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_approval.lower() == \"yes\":\n",
    "    # If approved, continue the graph execution\n",
    "    for step in lg_agent.graph.stream(None, config, stream_mode=\"debug\"):\n",
    "        if step[\"type\"] == \"checkpoint\":\n",
    "            display(f'Step {step[\"step\"]}')\n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last state\n",
    "last_state = lg_agent.graph.get_state(config)\n",
    "pd.DataFrame(last_state.values['AIdf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update state as node\n",
    "# lg_agent.graph.update_state(config, {\"foo\": 2, \"bar\": [\"b\"]}, as_node=\"revise_summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume from error starting at a node\n",
    "# result = lg_agent.graph.invoke(None, {'configurable': {'thread_id': 'newsbot-thread-5'}, \"next\": \"topic_analysis\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e5d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ainewsbot",
   "language": "python",
   "name": "ainewsbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
