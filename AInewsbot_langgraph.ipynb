{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c703a9",
   "metadata": {},
   "source": [
    "### Newsbot to write a daily AI news summary using langgraph\n",
    "- Save a list of HTML files from sources.yaml (tech news sites)\n",
    "- Extract URLs for the news stories\n",
    "- Filter URLs to remove duplicates, articles seen before, and non-AI articles (using a ChatGPT prompt)\n",
    "- Perform headline topic analysis and sort by topic to help the AI structure the response by topic\n",
    "- Scrape and summarize individual articles\n",
    "- Compose and email the summary\n",
    "- Used to generate a daily newsletter at skynetandchill.com and potentially an autogenerated podcast\n",
    "\n",
    "\n",
    "possible TODOs:\n",
    "\n",
    "- try using google / model swap\n",
    "- rate on various dimensions\n",
    "- when doing summary, store the log length of the text for the summary\n",
    "- store rating by source, bloomberg is high, normal pubs, prob garbage\n",
    "\n",
    "spammy = has a relatively fact free headline with sensaitonal language.\n",
    "only covers a stock movement or prediction without any basis in fact or sensational language\n",
    "2 magnificent stocks\n",
    "200 words is 0\n",
    "divide chars by 1000 and take the log base 10\n",
    "subtract 1 for spammy\n",
    "add 1 for top source\n",
    "delete less than 0 \n",
    "only ai incidentally , ie ai predictions for nfl against the spread\n",
    "\n",
    "\"For each of the 100 summarized news stories, provide a rating on a scale of 1-10 for the following criteria:\n",
    "\n",
    "Length (1 being too short or too long, 10 being optimal length)\n",
    "\n",
    "Reputation of source (1 being unreliable, 10 being highly reputable)\n",
    "\n",
    "Relevance/Importance (1 being trivial, 10 being highly significant)\n",
    "\n",
    "Spamminess (1 being very spammy, 10 being not spammy at all)\n",
    "- use exponential backoff to deal with rate limit issues (using metadata is not really well supported across llm providers, openai only gives time to reset in the http headers and not in the API itelf)\n",
    "- do tests with promptfoo, promptlayer, do prompt optimization with eg dspy or your own thing\n",
    "- scrape, extract, filter headlines, download pages, summarize, filter, categorize and sort, compose, rewrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74032f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to selectively re-import as needed\n",
    "import sys\n",
    "# del sys.modules['ainb_llm']\n",
    "# del sys.modules['ainb_const']\n",
    "# del sys.modules['ainb_utilities']\n",
    "# del sys.modules['ainb_webscrape']\n",
    "del sys.modules['AInewsbot_langgraph']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "562be45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# import dotenv\n",
    "# import subprocess\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "import uuid\n",
    "import re\n",
    "# import operator\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate,\n",
    "                                    SystemMessagePromptTemplate, HumanMessagePromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.errors import NodeInterrupt\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import bs4\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_exponential,\n",
    "    retry_if_exception_type\n",
    ")\n",
    "\n",
    "import asyncio\n",
    "from asyncio import Semaphore\n",
    "\n",
    "from IPython.display import HTML, Image, Markdown, display\n",
    "\n",
    "# import pyperclip\n",
    "# import shlex\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, TypedDict, Annotated, Any\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "import google.generativeai as genai\n",
    "import httpx\n",
    "\n",
    "import trafilatura   # web scrape uses this to get clean news stories w/o a lot of js and boilerplate\n",
    "\n",
    "from ainb_const import (\n",
    "                        FINAL_SUMMARY_PROMPT,\n",
    "                        REWRITE_PROMPT,\n",
    "                        SCREENSHOT_DIR, SUMMARIZE_SYSTEM_PROMPT, SUMMARIZE_USER_PROMPT\n",
    "                       )\n",
    "\n",
    "from ainb_utilities import log\n",
    "\n",
    "from AInewsbot_langgraph import (newscatcher_sources, initialize_agent,\n",
    "                                 fn_initialize, fn_download_sources, fn_extract_urls,\n",
    "                                 fn_verify_download, fn_extract_newscatcher, fn_extract_newsapi,\n",
    "                                 fn_filter_urls, fn_topic_clusters, fn_topic_analysis, fn_download_pages, \n",
    "                                 fn_summarize_pages, fn_propose_cats,\n",
    "                                 fn_compose_summary, fn_rewrite_summary\n",
    "                                )\n",
    "\n",
    "\n",
    "import podcastfy\n",
    "from podcastfy.client import generate_podcast, process_content\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from IPython.display import Audio, display, Markdown\n",
    "\n",
    "import pdb\n",
    "\n",
    "# need this to run async in jupyter since it already has an asyncio event loop running\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Activate global verbose logging\n",
    "set_debug(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59ba13ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python            3.11.11 | packaged by conda-forge | (main, Dec  5 2024, 14:21:42) [Clang 18.1.8 ]\n",
      "LangChain         0.3.18\n",
      "OpenAI            1.63.1\n",
      "trafilatura       2.0.0\n",
      "numpy             1.26.4\n",
      "pandas            2.2.3\n",
      "sklearn           1.6.1\n",
      "umap              0.5.7\n",
      "podcastfy         0.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python            {sys.version}\")\n",
    "print(f\"LangChain         {langchain.__version__}\")\n",
    "print(f\"OpenAI            {openai.__version__}\")\n",
    "# print(f\"smtplib           {smtplib.sys.version}\")\n",
    "print(f\"trafilatura       {trafilatura.__version__}\")\n",
    "# print(f\"bs4               {bs4.__version__}\")\n",
    "print(f\"numpy             {np.__version__}\")\n",
    "print(f\"pandas            {pd.__version__}\")\n",
    "print(f\"sklearn           {sklearn.__version__}\")\n",
    "print(f\"umap              {umap.__version__}\")\n",
    "print(f\"podcastfy         {podcastfy.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83bbf66",
   "metadata": {},
   "source": [
    "# Define LangGraph agent state graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e94b7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to maintain state within graph\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    AIdf: list[dict]                    #  the current working set of headlines (pandas dataframe not supported)\n",
    "    before_date: str                    #  ignore stories before this date for deduplication (force reprocess since)\n",
    "    do_download: bool                   #  if False use existing files, else download from sources\n",
    "    sources: dict                       #  sources to scrap\n",
    "    sources_reverse: dict[str, str]     #  map file names to sources\n",
    "    bullets: list[str]                  #  bullet points for summary email\n",
    "    summary: str                        #  final summary\n",
    "    cluster_topics: list[str]           #  list of cluster topics\n",
    "    topics_str: str                     #  edited topics\n",
    "    n_edits: int                        #  count edit iterations so we don't keep editing forever\n",
    "    edit_complete: bool                 #  edit will update if no more edits to make\n",
    "    # message thread with OpenAI\n",
    "    # messages: Annotated[list[AnyMessage], operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9eb53b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlite schema to store previously processed headlines\n",
    "# CREATE TABLE news_articles (\n",
    "#     id INTEGER PRIMARY KEY,\n",
    "#     src TEXT,\n",
    "#     title TEXT,\n",
    "#     url TEXT UNIQUE,\n",
    "#     isAI BOOLEAN,\n",
    "#     article_date DATE\n",
    "# , timestamp DATETIME, actual_url TEXT, actual_src TEXT);\n",
    "#\n",
    "# CREATE TABLE sites (\n",
    "#     id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#     hostname TEXT UNIQUE NOT NULL,\n",
    "#     site_name TEXT NOT NULL\n",
    "# );\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3143ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some debugging stuff, check a headline is cached properly\n",
    "# zdf = pd.DataFrame(test_state[\"AIdf\"])\n",
    "# zdf.loc[zdf[\"src\"]=='Techmeme']\n",
    "\n",
    "# connection = sqlite3.connect('articles.db')\n",
    "# xdf = pd.read_sql_query(\"SELECT * FROM news_articles\", connection)\n",
    "# connection.close()\n",
    "\n",
    "# zdf.loc[zdf[\"title\"].str.startswith(\"NHTSA\")]\n",
    "# xdf.loc[xdf[\"title\"].str.startswith(\"NHTSA\")]\n",
    "\n",
    "# pd.set_option('display.max_rows', 300)  # Ensure up to 300 rows are shown\n",
    "\n",
    "# xdf.loc[xdf['isAI']> 0].groupby('actual_src') \\\n",
    "#     .count() \\\n",
    "#     .reset_index()[['actual_src', 'id']] \\\n",
    "#     .sort_values('id', ascending=False) \\\n",
    "#     .head(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ae374e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    \"\"\"Langraph Agent class\"\"\"\n",
    "\n",
    "    def __init__(self, state, model_low, model_medium, model_high):\n",
    "        \"\"\"set up state graph and memory\"\"\"\n",
    "        self.state = state\n",
    "\n",
    "        self.BROWSERS = []\n",
    "\n",
    "        self.model_low = ChatOpenAI(model=model_low,\n",
    "                                    request_timeout=REQUEST_TIMEOUT)\n",
    "        self.model_medium = ChatOpenAI(model=model_medium,\n",
    "                                       request_timeout=REQUEST_TIMEOUT)\n",
    "        self.model_high = ChatOpenAI(model=model_high,\n",
    "                                     request_timeout=REQUEST_TIMEOUT)\n",
    "\n",
    "        graph_builder = StateGraph(AgentState)\n",
    "        graph_builder.add_node(\"initialize\", self.initialize)\n",
    "        graph_builder.add_node(\"download_sources\", self.download_sources)\n",
    "        graph_builder.add_node(\"extract_web_urls\", self.extract_web_urls)\n",
    "        graph_builder.add_node(\"verify_download\", self.verify_download)\n",
    "        graph_builder.add_node(\"extract_newsapi_urls\",\n",
    "                               self.extract_newsapi_urls)\n",
    "        # graph_builder.add_node(\"extract_newscatcher_urls\",\n",
    "        #                        self.extract_newscatcher_urls)\n",
    "        graph_builder.add_node(\"filter_urls\", self.filter_urls)\n",
    "        graph_builder.add_node(\"topic_analysis\", self.topic_analysis)\n",
    "        graph_builder.add_node(\"topic_clusters\", self.topic_clusters)\n",
    "        graph_builder.add_node(\"download_pages\", self.download_pages)\n",
    "        graph_builder.add_node(\"summarize_pages\", self.summarize_pages)\n",
    "        graph_builder.add_node(\"propose_topics\", self.propose_topics)\n",
    "        graph_builder.add_node(\"compose_summary\", self.compose_summary)\n",
    "        graph_builder.add_node(\"rewrite_summary\", self.rewrite_summary)\n",
    "        graph_builder.add_node(\"send_mail\", self.send_mail)\n",
    "\n",
    "        graph_builder.add_edge(START, \"initialize\")\n",
    "        graph_builder.add_edge(\"initialize\", \"download_sources\")\n",
    "        graph_builder.add_edge(\"download_sources\", \"extract_web_urls\")\n",
    "        graph_builder.add_edge(\"extract_web_urls\", \"verify_download\")\n",
    "        graph_builder.add_edge(\"verify_download\", \"extract_newsapi_urls\")\n",
    "        graph_builder.add_edge(\"extract_newsapi_urls\", \"filter_urls\")\n",
    "        # graph_builder.add_edge(\"extract_newscatcher_urls\", \"filter_urls\")\n",
    "        graph_builder.add_edge(\"filter_urls\", \"download_pages\")\n",
    "        graph_builder.add_edge(\"download_pages\", \"summarize_pages\")\n",
    "        graph_builder.add_edge(\"summarize_pages\", \"topic_analysis\")\n",
    "        graph_builder.add_edge(\"topic_analysis\", \"topic_clusters\")\n",
    "        graph_builder.add_edge(\"topic_clusters\", \"propose_topics\")\n",
    "        graph_builder.add_edge(\"propose_topics\", \"compose_summary\")\n",
    "        graph_builder.add_edge(\"compose_summary\", \"rewrite_summary\")\n",
    "        graph_builder.add_conditional_edges(\"rewrite_summary\",\n",
    "                                            self.is_revision_complete,\n",
    "                                            {\"incomplete\": \"rewrite_summary\",\n",
    "                                             \"complete\": \"send_mail\",\n",
    "                                             })\n",
    "        graph_builder.add_edge(\"send_mail\", END)\n",
    "\n",
    "        # human in the loop should check web pages downloaded ok, and edit proposed categories\n",
    "        # self.conn = sqlite3.connect('lg_checkpointer.db')\n",
    "        # self.checkpointer = SqliteSaver(conn=self.conn)\n",
    "        self.checkpointer = MemorySaver()\n",
    "        graph = graph_builder.compile(checkpointer=self.checkpointer,)\n",
    "#                                      interrupt_before=[\"filter_urls\", \"compose_summary\",])\n",
    "        self.graph = graph\n",
    "\n",
    "    def initialize(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"initialize agent, loading sources and setting up initial state\"\"\"\n",
    "        self.state = fn_initialize(state)\n",
    "        return self.state\n",
    "\n",
    "    def download_sources(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"download sources or load exisitng sources\"\"\"\n",
    "        self.state = fn_download_sources(state, self.BROWSERS)\n",
    "        return self.state\n",
    "\n",
    "    def extract_web_urls(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"parse all urls from downloaded pages\"\"\"\n",
    "        self.state = fn_extract_urls(state)\n",
    "        return self.state\n",
    "\n",
    "    def verify_download(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"verify we found news stories from all sources\"\"\"\n",
    "        self.state = fn_verify_download(state)\n",
    "        return self.state\n",
    "\n",
    "    def extract_newscatcher_urls(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"extract newscatcher urls\"\"\"\n",
    "        try:\n",
    "            self.state = fn_extract_newscatcher(state)\n",
    "        except KeyError:\n",
    "            log(\"Newscatcher download failed\")\n",
    "        return self.state\n",
    "\n",
    "    def extract_newsapi_urls(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"extract newsapi urls\"\"\"\n",
    "        try:\n",
    "            self.state = fn_extract_newsapi(state)\n",
    "        except KeyError:\n",
    "            log(\"NewsAPI download failed\")\n",
    "        return self.state\n",
    "\n",
    "    def filter_urls(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"filter to previously unseen urls and AI-related headlines only\"\"\"\n",
    "        self.state = fn_filter_urls(state, self.model_low)\n",
    "        return self.state\n",
    "\n",
    "    def topic_analysis(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"extract and assign topics for each headline\"\"\"\n",
    "        self.state = fn_topic_analysis(state, self.model_medium)\n",
    "        return self.state\n",
    "\n",
    "    def topic_clusters(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"identify clusters of similar stores\"\"\"\n",
    "        self.state = fn_topic_clusters(state, self.model_low)\n",
    "        return self.state\n",
    "\n",
    "    def download_pages(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"download individual news pages and save text\"\"\"\n",
    "        self.state = fn_download_pages(state, self.BROWSERS)\n",
    "        return self.state\n",
    "\n",
    "    def summarize_pages(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"summarize each page into bullet points\"\"\"\n",
    "        self.state = fn_summarize_pages(state, self.model_medium)\n",
    "        return self.state\n",
    "\n",
    "    def propose_topics(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"use LLM to identify most popular and important topics\"\"\"\n",
    "        self.state = fn_propose_cats(state, self.model_high)\n",
    "        return self.state\n",
    "\n",
    "    def compose_summary(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"compose the first draft of the summary using bullets and topics\"\"\"\n",
    "        self.state = fn_compose_summary(state, self.model_high)\n",
    "        return self.state\n",
    "\n",
    "    def rewrite_summary(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"edit the summary, combine and sharpen items, add and improve titles\"\"\"\n",
    "        self.state = fn_rewrite_summary(state, self.model_high)\n",
    "        return self.state\n",
    "\n",
    "    def is_revision_complete(self, state: AgentState) -> str:\n",
    "        \"\"\"check if summary should be revised\"\"\"\n",
    "        return fn_is_revision_complete(state)\n",
    "\n",
    "    def send_mail(self, state: AgentState) -> AgentState:\n",
    "        \"\"\"send final email with summary\"\"\"\n",
    "        self.state = fn_send_mail(state)\n",
    "        return self.state\n",
    "\n",
    "    def run(self, state, runconfig):\n",
    "        \"\"\"run the agent\"\"\"\n",
    "        # The config is the **second positional argument** to stream() or invoke()!\n",
    "        events = self.graph.stream(state, runconfig, stream_mode=\"values\")\n",
    "        for event in events:\n",
    "            try:\n",
    "                if event.get('summary'):\n",
    "                    print('summary created')\n",
    "                    display(event.get('summary').replace(\"$\", \"\\\\\\\\$\"))\n",
    "                elif event.get('bullets'):\n",
    "                    print('bullets created')\n",
    "                    display(\"\\n\\n\".join(\n",
    "                        event.get('bullets')).replace(\"$\", \"\\\\\\\\$\"))\n",
    "                elif event.get('cluster_topics'):\n",
    "                    print('cluster topics created')\n",
    "                    display(\"\\n\\n\".join(event.get('cluster_topics')))\n",
    "                elif event.get('AIdf'):\n",
    "                    display(pd.DataFrame(event.get('AIdf')).groupby(\n",
    "                        \"src\").count()[['id']])\n",
    "                elif event.get('sources'):\n",
    "                    print([k for k in event.get('sources').keys()])\n",
    "            except Exception as exc:\n",
    "                print('run exception')\n",
    "                print(exc)\n",
    "\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0dcbc7",
   "metadata": {},
   "source": [
    "# Instantiate agent and run LangGraph workflow graph end to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faccbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_date = None\n",
    "before_date = '2025-02-22 15:00'\n",
    "do_download = True\n",
    "\n",
    "state, lg_agent, thread_id = initialize_agent(do_download, before_date)\n",
    "log(f\"thread_id: {thread_id}\")\n",
    "\n",
    "display(Image(lg_agent.graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a5fc4-d89b-4181-8587-3a60d47a0537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "state = lg_agent.run(state, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c974d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try google anthropic\n",
    "# pass a parameter - model_low, model_medium, model_high , \n",
    "# make a function get_model, map string to google , openai, claude\n",
    "# get_model maps input, calls chatopenai, chatgoogle, chatanthropic with the model string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c8c8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# it will stop if check sources not passed\n",
    "# or if we force a stop compiling with interrupt_before=[\"filter_urls\"]\n",
    "# if something got a robot block, download manually and rerun from beginning\n",
    "\n",
    "last_state = lg_agent.graph.get_state(config).values\n",
    "sources_downloaded = len(pd.DataFrame(last_state[\"AIdf\"]).groupby(\"src\").count()[['id']])\n",
    "print(\"number of sources in AIdf\", sources_downloaded)\n",
    "display(pd.DataFrame(last_state[\"AIdf\"]).groupby(\"src\").count()[['id']])\n",
    "\n",
    "sources_downloaded = len(\n",
    "    pd.DataFrame(last_state[\"AIdf\"]).groupby(\"src\").count()[['id']])\n",
    "SOURCES_EXPECTED = 16\n",
    "missing_sources = SOURCES_EXPECTED-sources_downloaded\n",
    "print(\"number of missing sources\", missing_sources)\n",
    "set(last_state[\"sources\"].keys()) - set(pd.DataFrame(last_state[\"AIdf\"]).groupby(\"src\").count()[['id']].index )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89affd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_state = lg_agent.graph.get_state(config)\n",
    "\n",
    "aidf = pd.DataFrame(last_state.values[\"AIdf\"])\n",
    "aidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(state['summary'].replace(\"$\", \"\\\\\\\\$\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue, state=None proceeds from last state\n",
    "# last_state = lg_agent.graph.get_state(config)\n",
    "# state = lg_agent.run(None, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will stop again here if we compiled with interrupt_before=[\"filter_urls\", \"compose_summary\",]\n",
    "# last_state = lg_agent.graph.get_state(config)\n",
    "# print('next', last_state.next)\n",
    "# print('config', last_state.config)\n",
    "# print(last_state.values[\"topics_str\"])\n",
    "\n",
    "# update cluster_topics if desired\n",
    "# lg_agent.graph.update_state (\n",
    "#     last_state.config,\n",
    "#     {\n",
    "#         \"topics_str\": \"\"\"\n",
    "# African Healthcare & Agriculture\n",
    "# Anthropic & Palantir Defense Partnership\n",
    "# Apple iOS 18.2 Updates\n",
    "# China AI Chips\n",
    "# China Talent Race\n",
    "# Construction Industry Transformations\n",
    "# Credit Innovation at FinTech Festival\n",
    "# Doubao AI Video Generator\n",
    "# Google Gemini iOS Launch\n",
    "# Grok AI Free Plan\n",
    "# Grok API\n",
    "# Healthcare Applications\n",
    "# Hollywood's 'Heretic' AI Movie\n",
    "# Humanoid Robot Artwork Sale\n",
    "# Moore Threads Sanction IPO\n",
    "# NHS Doctor Assistant\n",
    "# Net Zero Emissions Target\n",
    "# Passenger Plane Flight Smoother\n",
    "# Restored Historical Photos\n",
    "# Scientific Data Fabrication\n",
    "# Sydney Opera House Image Hoax\n",
    "# TSMC Chip Exports Halted\n",
    "# UK Immigration Decision Tool\n",
    "# \"\"\"\n",
    "#     },\n",
    "#     as_node='propose_topics')\n",
    "\n",
    "# show updated state\n",
    "# last_state = lg_agent.graph.get_state(config)\n",
    "# print('next', last_state.next)\n",
    "# print('config', last_state.config)\n",
    "# last_state.values[\"topics_str\"]\n",
    "\n",
    "# resume running the graph\n",
    "# state = lg_agent.run(None, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finished, show output\n",
    "last_state = lg_agent.graph.get_state(config)\n",
    "display(Markdown(last_state.values[\"summary\"].replace(\"$\",\"\\\\\\\\$\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff0b02",
   "metadata": {},
   "source": [
    "# Run each step individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "932472db-2c6f-49e3-8c4a-298ce8e44a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:34:14,678 - AInewsbot - INFO - Initializing with before_date=2025-02-24 16:00, do_download=False, thread_id=6859f6df5a1e45a58a5d204b73695a80\n",
      "2025-02-25 10:34:17,690 - google.auth.compute_engine._metadata - WARNING - Compute Engine Metadata server unavailable on attempt 1 of 3. Reason: timed out\n",
      "2025-02-25 10:34:18,740 - google.auth.compute_engine._metadata - WARNING - Compute Engine Metadata server unavailable on attempt 2 of 3. Reason: [Errno 65] No route to host\n",
      "2025-02-25 10:34:20,794 - google.auth.compute_engine._metadata - WARNING - Compute Engine Metadata server unavailable on attempt 3 of 3. Reason: [Errno 64] Host is down\n",
      "2025-02-25 10:34:20,796 - google.auth._default - WARNING - Authentication failed using Compute Engine authentication due to unavailable metadata server.\n"
     ]
    },
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ml, mm, mh = 'gpt-4o-mini', 'gpt-4o-2024-11-20', 'o3-mini'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ml, mm, mh \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/gemini-2.0-flash\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/gemini-2.0-pro-exp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/gemini-2.0-flash-thinking-exp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m state, lg_agent, thread_id \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbefore_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m display(Image(lg_agent\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mget_graph()\u001b[38;5;241m.\u001b[39mdraw_mermaid_png()))\n",
      "File \u001b[0;32m~/projects/AInewsbot/AInewsbot_langgraph.py:1285\u001b[0m, in \u001b[0;36minitialize_agent\u001b[0;34m(do_download, before_date, model_low, model_medium, model_high)\u001b[0m\n\u001b[1;32m   1282\u001b[0m thread_id \u001b[38;5;241m=\u001b[39m uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex\n\u001b[1;32m   1283\u001b[0m log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing with before_date=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_date\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, do_download=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdo_download\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, thread_id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m     )\n\u001b[0;32m-> 1285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_low\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_medium\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_high\u001b[49m\u001b[43m)\u001b[49m, thread_id\n",
      "File \u001b[0;32m~/projects/AInewsbot/AInewsbot_langgraph.py:1102\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[0;34m(self, state, model_low, model_medium, model_high)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBROWSERS \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_low \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_low\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_medium \u001b[38;5;241m=\u001b[39m get_model(model_medium)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_high \u001b[38;5;241m=\u001b[39m get_model(model_high)\n",
      "File \u001b[0;32m~/projects/AInewsbot/AInewsbot_langgraph.py:172\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ChatOpenAI(model\u001b[38;5;241m=\u001b[39mmodel_name, request_timeout\u001b[38;5;241m=\u001b[39mREQUEST_TIMEOUT)\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 172\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREQUEST_TIMEOUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:838\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m         google_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoogle_api_key\n\u001b[1;32m    837\u001b[0m transport: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport\n\u001b[0;32m--> 838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mgenaix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_google_genai/_genai_extension.py:276\u001b[0m, in \u001b[0;36mbuild_generative_service\u001b[0;34m(credentials, api_key, client_options, client_info, transport)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_generative_service\u001b[39m(\n\u001b[1;32m    263\u001b[0m     credentials: Optional[credentials\u001b[38;5;241m.\u001b[39mCredentials] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    264\u001b[0m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m v1betaGenerativeServiceClient:\n\u001b[1;32m    269\u001b[0m     config \u001b[38;5;241m=\u001b[39m _prepare_config(\n\u001b[1;32m    270\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[1;32m    271\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m         client_info\u001b[38;5;241m=\u001b[39mclient_info,\n\u001b[1;32m    275\u001b[0m     )\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:687\u001b[0m, in \u001b[0;36mGenerativeServiceClient.__init__\u001b[0;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[1;32m    678\u001b[0m transport_init: Union[\n\u001b[1;32m    679\u001b[0m     Type[GenerativeServiceTransport],\n\u001b[1;32m    680\u001b[0m     Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, GenerativeServiceTransport],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, GenerativeServiceTransport], transport)\n\u001b[1;32m    685\u001b[0m )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:154\u001b[0m, in \u001b[0;36mGenerativeServiceGrpcTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[1;32m    150\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[1;32m    151\u001b[0m             )\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/base.py:100\u001b[0m, in \u001b[0;36mGenerativeServiceTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[1;32m     97\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[0;32m--> 100\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/google/auth/_default.py:697\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    689\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    690\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    691\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    692\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    693\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[1;32m    694\u001b[0m             )\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 697\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "# same as above but w/o using native langgraph runner, run state updates sequentially\n",
    "# langgraph runner does other stuff implicitly like checkpoint state in sqlite\n",
    "\n",
    "before_date = None\n",
    "before_date = '2025-02-24 16:00'\n",
    "do_download = False\n",
    "# ml, mm, mh = 'gpt-4o-mini', 'gpt-4o-2024-11-20', 'o3-mini'\n",
    "ml, mm, mh = 'models/gemini-2.0-flash', 'models/gemini-2.0-pro-exp', 'models/gemini-2.0-flash-thinking-exp'\n",
    "state, lg_agent, thread_id = initialize_agent(do_download, before_date, ml, mm, mh)\n",
    "\n",
    "display(Image(lg_agent.graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0eb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = lg_agent.initialize(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2477403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:29:34,004 - AInewsbot - INFO - Web fetch disabled, using existing files in htmldata\n",
      "2025-02-25 10:29:34,007 - AInewsbot - INFO - Found 16 previously downloaded files\n",
      "2025-02-25 10:29:34,007 - AInewsbot - INFO - htmldata/New York Times Technology (02_25_2025 10_08_34 AM).html\n",
      "2025-02-25 10:29:34,008 - AInewsbot - INFO - htmldata/Business Insider Tech (02_25_2025 10_08_11 AM).html\n",
      "2025-02-25 10:29:34,008 - AInewsbot - INFO - htmldata/Feedly AI (02_25_2025 10_09_31 AM).html\n",
      "2025-02-25 10:29:34,009 - AInewsbot - INFO - htmldata/Ars Technica (02_25_2025 10_08_13 AM).html\n",
      "2025-02-25 10:29:34,009 - AInewsbot - INFO - htmldata/Hacker News Page 1 (02_25_2025 10_08_22 AM).html\n",
      "2025-02-25 10:29:34,010 - AInewsbot - INFO - htmldata/HackerNoon (02_25_2025 10_08_27 AM).html\n",
      "2025-02-25 10:29:34,010 - AInewsbot - INFO - htmldata/The Register (02_25_2025 10_08_45 AM).html\n",
      "2025-02-25 10:29:34,012 - AInewsbot - INFO - htmldata/The Verge AI (02_25_2025 10_08_50 AM).html\n",
      "2025-02-25 10:29:34,013 - AInewsbot - INFO - htmldata/FT Technology (02_25_2025 10_08_11 AM).html\n",
      "2025-02-25 10:29:34,013 - AInewsbot - INFO - htmldata/WSJ Technology (02_25_2025 10_09_03 AM).html\n",
      "2025-02-25 10:29:34,014 - AInewsbot - INFO - htmldata/Bloomberg Technology (02_25_2025 10_08_16 AM).html\n",
      "2025-02-25 10:29:34,014 - AInewsbot - INFO - htmldata/Techmeme (02_25_2025 10_08_38 AM).html\n",
      "2025-02-25 10:29:34,018 - AInewsbot - INFO - htmldata/Hacker News Page 2 (02_25_2025 10_08_24 AM).html\n",
      "2025-02-25 10:29:34,021 - AInewsbot - INFO - htmldata/Washington Post Technology (02_25_2025 10_09_10 AM).html\n",
      "2025-02-25 10:29:34,022 - AInewsbot - INFO - htmldata/VentureBeat AI (02_25_2025 10_08_57 AM).html\n",
      "2025-02-25 10:29:34,022 - AInewsbot - INFO - htmldata/Reddit multiple subreddits (02_25_2025 10_08_55 AM).html\n"
     ]
    }
   ],
   "source": [
    "state = lg_agent.download_sources(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97f26caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:29:34,549 - AInewsbot - INFO - Parsing html files\n",
      "2025-02-25 10:29:34,550 - AInewsbot - INFO - Ars Technica -> htmldata/Ars Technica (02_25_2025 10_08_13 AM).html\n",
      "2025-02-25 10:29:34,605 - AInewsbot - INFO - parse_file - found 204 raw links\n",
      "2025-02-25 10:29:34,608 - AInewsbot - INFO - parse_file - found 35 filtered links\n",
      "2025-02-25 10:29:34,608 - AInewsbot - INFO - 35 links found\n",
      "2025-02-25 10:29:34,609 - AInewsbot - INFO - Bloomberg Tech -> htmldata/Bloomberg Technology (02_25_2025 10_08_16 AM).html\n",
      "2025-02-25 10:29:34,628 - AInewsbot - INFO - parse_file - found 200 raw links\n",
      "2025-02-25 10:29:34,631 - AInewsbot - INFO - parse_file - found 16 filtered links\n",
      "2025-02-25 10:29:34,631 - AInewsbot - INFO - 16 links found\n",
      "2025-02-25 10:29:34,631 - AInewsbot - INFO - Business Insider -> htmldata/Business Insider Tech (02_25_2025 10_08_11 AM).html\n",
      "2025-02-25 10:29:34,650 - AInewsbot - INFO - parse_file - found 207 raw links\n",
      "2025-02-25 10:29:34,653 - AInewsbot - INFO - parse_file - found 20 filtered links\n",
      "2025-02-25 10:29:34,654 - AInewsbot - INFO - 20 links found\n",
      "2025-02-25 10:29:34,654 - AInewsbot - INFO - FT Tech -> htmldata/FT Technology (02_25_2025 10_08_11 AM).html\n",
      "2025-02-25 10:29:34,682 - AInewsbot - INFO - parse_file - found 488 raw links\n",
      "2025-02-25 10:29:34,687 - AInewsbot - INFO - parse_file - found 121 filtered links\n",
      "2025-02-25 10:29:34,688 - AInewsbot - INFO - 121 links found\n",
      "2025-02-25 10:29:34,688 - AInewsbot - INFO - Feedly AI -> htmldata/Feedly AI (02_25_2025 10_09_31 AM).html\n",
      "2025-02-25 10:29:34,716 - AInewsbot - INFO - parse_file - found 109 raw links\n",
      "2025-02-25 10:29:34,718 - AInewsbot - INFO - parse_file - found 37 filtered links\n",
      "2025-02-25 10:29:34,718 - AInewsbot - INFO - 37 links found\n",
      "2025-02-25 10:29:34,719 - AInewsbot - INFO - Hacker News -> htmldata/Hacker News Page 1 (02_25_2025 10_08_22 AM).html\n",
      "2025-02-25 10:29:34,730 - AInewsbot - INFO - parse_file - found 261 raw links\n",
      "2025-02-25 10:29:34,732 - AInewsbot - INFO - parse_file - found 26 filtered links\n",
      "2025-02-25 10:29:34,732 - AInewsbot - INFO - 26 links found\n",
      "2025-02-25 10:29:34,733 - AInewsbot - INFO - Hacker News 2 -> htmldata/Hacker News Page 2 (02_25_2025 10_08_24 AM).html\n",
      "2025-02-25 10:29:34,744 - AInewsbot - INFO - parse_file - found 257 raw links\n",
      "2025-02-25 10:29:34,747 - AInewsbot - INFO - parse_file - found 20 filtered links\n",
      "2025-02-25 10:29:34,747 - AInewsbot - INFO - 20 links found\n",
      "2025-02-25 10:29:34,747 - AInewsbot - INFO - HackerNoon -> htmldata/HackerNoon (02_25_2025 10_08_27 AM).html\n",
      "2025-02-25 10:29:34,796 - AInewsbot - INFO - parse_file - found 585 raw links\n",
      "2025-02-25 10:29:34,804 - AInewsbot - INFO - parse_file - found 103 filtered links\n",
      "2025-02-25 10:29:34,804 - AInewsbot - INFO - 103 links found\n",
      "2025-02-25 10:29:34,804 - AInewsbot - INFO - NYT Tech -> htmldata/New York Times Technology (02_25_2025 10_08_34 AM).html\n",
      "2025-02-25 10:29:34,816 - AInewsbot - INFO - parse_file - found 77 raw links\n",
      "2025-02-25 10:29:34,817 - AInewsbot - INFO - parse_file - found 19 filtered links\n",
      "2025-02-25 10:29:34,818 - AInewsbot - INFO - 19 links found\n",
      "2025-02-25 10:29:34,818 - AInewsbot - INFO - Reddit -> htmldata/Reddit multiple subreddits (02_25_2025 10_08_55 AM).html\n",
      "2025-02-25 10:29:34,840 - AInewsbot - INFO - parse_file - found 432 raw links\n",
      "2025-02-25 10:29:34,845 - AInewsbot - INFO - parse_file - found 170 filtered links\n",
      "2025-02-25 10:29:34,846 - AInewsbot - INFO - 170 links found\n",
      "2025-02-25 10:29:34,846 - AInewsbot - INFO - Techmeme -> htmldata/Techmeme (02_25_2025 10_08_38 AM).html\n",
      "2025-02-25 10:29:34,862 - AInewsbot - INFO - parse_file - found 336 raw links\n",
      "2025-02-25 10:29:34,866 - AInewsbot - INFO - parse_file - found 136 filtered links\n",
      "2025-02-25 10:29:34,867 - AInewsbot - INFO - 136 links found\n",
      "2025-02-25 10:29:34,867 - AInewsbot - INFO - The Register -> htmldata/The Register (02_25_2025 10_08_45 AM).html\n",
      "2025-02-25 10:29:34,900 - AInewsbot - INFO - parse_file - found 200 raw links\n",
      "2025-02-25 10:29:34,904 - AInewsbot - INFO - parse_file - found 110 filtered links\n",
      "2025-02-25 10:29:34,904 - AInewsbot - INFO - 110 links found\n",
      "2025-02-25 10:29:34,904 - AInewsbot - INFO - The Verge -> htmldata/The Verge AI (02_25_2025 10_08_50 AM).html\n",
      "2025-02-25 10:29:34,937 - AInewsbot - INFO - parse_file - found 239 raw links\n",
      "2025-02-25 10:29:34,941 - AInewsbot - INFO - parse_file - found 6 filtered links\n",
      "2025-02-25 10:29:34,941 - AInewsbot - INFO - 6 links found\n",
      "2025-02-25 10:29:34,941 - AInewsbot - INFO - VentureBeat -> htmldata/VentureBeat AI (02_25_2025 10_08_57 AM).html\n",
      "2025-02-25 10:29:34,961 - AInewsbot - INFO - parse_file - found 336 raw links\n",
      "2025-02-25 10:29:34,965 - AInewsbot - INFO - parse_file - found 44 filtered links\n",
      "2025-02-25 10:29:34,966 - AInewsbot - INFO - 44 links found\n",
      "2025-02-25 10:29:34,966 - AInewsbot - INFO - WSJ Tech -> htmldata/WSJ Technology (02_25_2025 10_09_03 AM).html\n",
      "2025-02-25 10:29:34,999 - AInewsbot - INFO - parse_file - found 515 raw links\n",
      "2025-02-25 10:29:35,006 - AInewsbot - INFO - parse_file - found 47 filtered links\n",
      "2025-02-25 10:29:35,007 - AInewsbot - INFO - 47 links found\n",
      "2025-02-25 10:29:35,007 - AInewsbot - INFO - WaPo Tech -> htmldata/Washington Post Technology (02_25_2025 10_09_10 AM).html\n",
      "2025-02-25 10:29:35,029 - AInewsbot - INFO - parse_file - found 243 raw links\n",
      "2025-02-25 10:29:35,032 - AInewsbot - INFO - parse_file - found 62 filtered links\n",
      "2025-02-25 10:29:35,033 - AInewsbot - INFO - 62 links found\n",
      "2025-02-25 10:29:35,033 - AInewsbot - INFO - Saved 972 links\n"
     ]
    }
   ],
   "source": [
    "state = lg_agent.extract_web_urls(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af367c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sources in AIdf 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ars Technica</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bloomberg Tech</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT Tech</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feedly AI</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hacker News</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hacker News 2</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HackerNoon</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYT Tech</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reddit</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Techmeme</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Register</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Verge</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VentureBeat</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WSJ Tech</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WaPo Tech</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id\n",
       "src                  \n",
       "Ars Technica       29\n",
       "Bloomberg Tech     12\n",
       "Business Insider   20\n",
       "FT Tech            65\n",
       "Feedly AI          36\n",
       "Hacker News        23\n",
       "Hacker News 2      19\n",
       "HackerNoon        102\n",
       "NYT Tech           19\n",
       "Reddit            121\n",
       "Techmeme          126\n",
       "The Register      109\n",
       "The Verge           6\n",
       "VentureBeat        43\n",
       "WSJ Tech           24\n",
       "WaPo Tech          37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing sources 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s/b 16 check all sources downloaded, if any got hit by a bot block then download manually\n",
    "\n",
    "sources_downloaded = len(pd.DataFrame(state[\"AIdf\"]).groupby(\"src\").count()[['id']])\n",
    "print(\"number of sources in AIdf\", sources_downloaded)\n",
    "display(pd.DataFrame(state[\"AIdf\"]).groupby(\"src\").count()[['id']])\n",
    "\n",
    "sources_downloaded = len(\n",
    "    pd.DataFrame(state[\"AIdf\"]).groupby(\"src\").count()[['id']])\n",
    "SOURCES_EXPECTED = 16\n",
    "missing_sources = SOURCES_EXPECTED-sources_downloaded\n",
    "print(\"number of missing sources\", missing_sources)\n",
    "set(state[\"sources\"].keys()) - set(pd.DataFrame(state[\"AIdf\"]).groupby(\"src\").count()[['id']].index )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "791fd750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:29:37,981 - AInewsbot - INFO - verify_download passed, found 16 sources in AIdf, 0 missing\n"
     ]
    }
   ],
   "source": [
    "state = lg_agent.verify_download(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1651bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:29:39,521 - AInewsbot - INFO - Fetching top 100 stories matching artificial intelligence since 2025-02-24T10:29:39 from NewsAPI\n"
     ]
    }
   ],
   "source": [
    "state = lg_agent.extract_newsapi_urls(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "870a5d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:30:14,158 - AInewsbot - INFO - Querying SQLite with where_clause: WHERE timestamp < '2025-02-24 16:00'\n",
      "2025-02-25 10:30:14,650 - AInewsbot - INFO - URLs in orig_df: 889\n",
      "2025-02-25 10:30:14,653 - AInewsbot - INFO - Existing URLs in DB: 221618\n",
      "2025-02-25 10:30:14,705 - AInewsbot - INFO - New URLs in df filtered by URL: 386\n",
      "2025-02-25 10:30:14,814 - AInewsbot - INFO - Existing src+title: 24\n",
      "2025-02-25 10:30:14,815 - AInewsbot - INFO - New URLs in df filtered by src+title: 362\n",
      "2025-02-25 10:30:14,826 - AInewsbot - INFO - Found 361 unique new headlines\n",
      "2025-02-25 10:30:14,828 - AInewsbot - INFO - Found 359 unique new headlines\n",
      "2025-02-25 10:30:15,027 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type, a tuple of types, or a union",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# filter by headlines that we haven't seen and that look like AI, we don't want to summarize all before filtering\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mlg_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m display(pd\u001b[38;5;241m.\u001b[39mDataFrame(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIdf\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "File \u001b[0;32m~/projects/AInewsbot/AInewsbot_langgraph.py:1196\u001b[0m, in \u001b[0;36mAgent.filter_urls\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_urls\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: AgentState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentState:\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"filter to previously unseen urls and AI-related headlines only\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[43mfn_filter_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_low\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/projects/AInewsbot/AInewsbot_langgraph.py:544\u001b[0m, in \u001b[0;36mfn_filter_urls\u001b[0;34m(state, model_low)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# filter AI-related headlines using a prompt\u001b[39;00m\n\u001b[1;32m    543\u001b[0m pagelist \u001b[38;5;241m=\u001b[39m paginate_df(aidf[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m--> 544\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_dataframes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpagelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFILTER_PROMPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_low\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_list_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mitems\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_id_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# should return a list of Story\u001b[39;00m\n\u001b[1;32m    554\u001b[0m filter_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\n\u001b[1;32m    555\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: story\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misAI\u001b[39m\u001b[38;5;124m\"\u001b[39m: story\u001b[38;5;241m.\u001b[39misAI}\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m story \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    557\u001b[0m ])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/asyncio/tasks.py:279\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/AInewsbot/ainb_llm.py:401\u001b[0m, in \u001b[0;36mprocess_dataframes\u001b[0;34m(dataframes, input_prompt, output_class, model, input_vars, item_list_field, item_id_field)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    396\u001b[0m         filter_page_async(df, input_prompt, output_class,\n\u001b[1;32m    397\u001b[0m                           model, input_vars)\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dataframes\n\u001b[1;32m    399\u001b[0m     ]\n\u001b[0;32m--> 401\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# if each result is an object with items as a list of objects then flatten\u001b[39;00m\n\u001b[1;32m    404\u001b[0m flat_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/asyncio/tasks.py:349\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/asyncio/tasks.py:277\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:189\u001b[0m, in \u001b[0;36mAsyncRetrying.wraps.<locals>.async_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    188\u001b[0m async_wrapped\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m copy(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:111\u001b[0m, in \u001b[0;36mAsyncRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:153\u001b[0m, in \u001b[0;36mAsyncRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/tenacity/asyncio/__init__.py:129\u001b[0m, in \u001b[0;36mAsyncRetrying._run_retry\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_retry\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _utils\u001b[38;5;241m.\u001b[39mwrap_to_async_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry)(\n\u001b[1;32m    130\u001b[0m         retry_state\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/tenacity/_utils.py:99\u001b[0m, in \u001b[0;36mwrap_to_async_func.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/tenacity/retry.py:82\u001b[0m, in \u001b[0;36mretry_if_exception.__call__\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutcome failed but the exception is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/tenacity/retry.py:98\u001b[0m, in \u001b[0;36mretry_if_exception_type.__init__.<locals>.<lambda>\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     92\u001b[0m     exception_types: typing\u001b[38;5;241m.\u001b[39mUnion[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mException\u001b[39;00m,\n\u001b[1;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception_types \u001b[38;5;241m=\u001b[39m exception_types\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m e: \u001b[38;5;28misinstance\u001b[39m(e, exception_types))\n",
      "\u001b[0;31mTypeError\u001b[0m: isinstance() arg 2 must be a type, a tuple of types, or a union"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:30:15,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "2025-02-25 10:30:15,088 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "2025-02-25 10:30:15,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "2025-02-25 10:30:15,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "2025-02-25 10:30:15,089 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "2025-02-25 10:30:15,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "2025-02-25 10:30:15,090 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n"
     ]
    }
   ],
   "source": [
    "# filter by headlines that we haven't seen and that look like AI, we don't want to summarize all before filtering\n",
    "state = lg_agent.filter_urls(state)\n",
    "display(pd.DataFrame(state[\"AIdf\"]).groupby(\"src\").count()[['id']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772bc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = lg_agent.download_pages(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize downloaded pages\n",
    "state = lg_agent.summarize_pages(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2290c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(pd.DataFrame(state[\"AIdf\"]).iloc[0].summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract topics from summaries\n",
    "# AI prompt to free-form ask what topics are covered\n",
    "# followed by a series of structured AI prompts to ask if popular topics are covered \n",
    "state = lg_agent.topic_analysis(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c82131",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(pd.DataFrame(state[\"AIdf\"]).iloc[1].title_topic_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a346e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(pd.DataFrame(state[\"AIdf\"]).iloc[0].bullet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ab2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = lg_agent.topic_clusters(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = lg_agent.propose_topics(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0533b-b39f-4049-8aef-4c7b228be481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose using o3-mini and rewrite summary\n",
    "MAX_EDITS=2\n",
    "\n",
    "state = lg_agent.compose_summary(state)\n",
    "display(Markdown(state[\"summary\"].replace(\"$\",\"\\\\\\\\$\")))\n",
    "for _ in range(MAX_EDITS):\n",
    "    if lg_agent.is_revision_complete(state)=='complete' or len(state[\"summary\"])<5:\n",
    "        break\n",
    "    state = lg_agent.rewrite_summary(state)\n",
    "    display(Markdown(state[\"summary\"].replace(\"$\",\"\\\\\\\\$\")))\n",
    "state = lg_agent.send_mail(state)\n",
    "display(Markdown(state[\"summary\"].replace(\"$\", \"\\\\\\\\$\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f536fce-bb0c-47fe-ad9e-3ab6bac18497",
   "metadata": {},
   "source": [
    "# Re-run based on previously generated content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246407f0-98aa-4591-8c0a-0d8cc26e4c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('bullet_str.txt', 'r') as f:\n",
    "     bullet_str = f.read()\n",
    "\n",
    "print(bullet_str[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9491501-adaf-4282-a425-ca124998d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('topics.txt', 'r') as f:\n",
    "     cat_str = f.read()\n",
    "\n",
    "print(cat_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e766e3-9678-409f-bfd5-bc81cb69e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=HIGHCOST_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": FINAL_SUMMARY_PROMPT.format(cat_str=cat_str, bullet_str=bullet_str)\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ba05e-93ce-44d0-80a5-f4eb1eaf5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_str = response.choices[0].message.content\n",
    "display(Markdown(response_str.replace(\"$\",\"\\\\\\\\$\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9f40b-d27e-4bf8-b7b2-fae1441ed8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite\n",
    "\n",
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=HIGHCOST_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": REWRITE_PROMPT.format(summary=response_str)\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response_str = response.choices[0].message.content\n",
    "state['summary'] = response_str\n",
    "display(Markdown(response_str.replace(\"$\",\"\\\\\\\\$\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8fdec2",
   "metadata": {},
   "source": [
    "# Create AI-generated podcast from the summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d258d",
   "metadata": {},
   "source": [
    "- Uses Podcastfy by Tharzis Souza https://github.com/souzatharsis/podcastfy\n",
    "- IIUC it fetches the URLs and generates a very long prompt saying 'make a podcast script'\n",
    "- For my purpose I have sections and bullet points\n",
    "- I could probably send each section individually, something like\n",
    "    - prompt to do intro, let's dive in, do the first section with a title, bullet text, article texts via trafilatura\n",
    "    - iteratively loop with a complex prompt, the podcast script so far, the next items to add\n",
    "    - add a rewrite step after completion to clean it up, spice it up \n",
    "- try different elevenlabs options and maybe look for the google tts that notebooklm uses and try to get a more natural inflection\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c85e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save state summary to local file\n",
    "filename = 'summary.md'\n",
    "\n",
    "try:\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(state.get(\"summary\"))\n",
    "        print(f\"Markdown content successfully saved to {filename}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c82814",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summary.md', 'r') as f:\n",
    "     summary_content = f.read().replace(\"$\",\"\\\\\\\\$\")\n",
    "\n",
    "print(len(summary_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b4d11-17b2-4e5c-a211-78d6d6adb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('topics.txt', 'r') as f:\n",
    "     topics_str = f.read().replace(\"$\",\"\\\\\\\\$\")\n",
    "\n",
    "print(len(topics_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_config = {\n",
    "    \"word_count\": 3000,  # Longer content for in-depth discussions\n",
    "    \"conversation_style\": [\"conversational\", \"fast-paced\", \"informal\", \"engaging\", \"funny\", \"thoughtful\", \"analytical\", \"balanced\"],\n",
    "    \"roles_person1\": \"main summarizer\",\n",
    "    \"roles_person2\": \"questioner/clarifier\",\n",
    "    \"dialogue_structure\": [\"Introduction\", \"Discuss News of the day\", \"Conclusion\"],\n",
    "    \"podcast_name\": \"Skynet and Chill\",\n",
    "    \"podcast_tagline\": \"Today's AI news, lovingly curated by man and machine\",\n",
    "    \"output_language\": \"English\",\n",
    "    \"engagement_techniques\": [\"questions\", \"analogies\", \"humor\"],\n",
    "    \"creativity\": 0.5  # Lower creativity for more factual content\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa589c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transcript using podcastfy\n",
    "audio_file = process_content(text=summary_content,\n",
    "                             conversation_config=debate_config,\n",
    "                             longform=False,\n",
    "                             generate_audio=False,\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a36c4c-7e7d-4119-bf38-152b76d6123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show transcript\n",
    "# transcript_file = 'data/transcripts/transcript_ef2a25a7ad874eb2a29864c5c5aac309.txt'\n",
    "# get most recent file (I don't see a way to return it from podcastfy)\n",
    "import glob\n",
    "\n",
    "DATADIR = 'data/transcripts/'\n",
    "files = glob.glob(os.path.join(DATADIR, \"*.txt\"))\n",
    "transcript_file = max(files, key=os.path.getmtime)\n",
    "print(transcript_file)\n",
    "\n",
    "# can edit transcript/screenplay if desired\n",
    "with open(transcript_file, \"r\") as infile:\n",
    "    print(infile.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create audio file from transcript\n",
    "\n",
    "debate_config = {\n",
    "    \"word_count\": 3000,  # Longer content for in-depth discussions\n",
    "    \"conversation_style\": [\"conversational\", \"fast-paced\", \"informal\", \"engaging\", \"funny\", \"thoughtful\", \"analytical\", \"balanced\"],\n",
    "    \"roles_person1\": \"main summarizer\",\n",
    "    \"roles_person2\": \"questioner/clarifier\",\n",
    "    \"dialogue_structure\": [\"Introduction\", \"Discuss News of the day\", \"Conclusion\"],\n",
    "    \"podcast_name\": \"Skynet and Chill\",\n",
    "    \"podcast_tagline\": \"Today's AI news, lovingly curated by man and machine\",\n",
    "    \"output_language\": \"English\",\n",
    "    \"engagement_techniques\": [\"questions\", \"analogies\", \"humor\"],\n",
    "    \"creativity\": 0.5  # Lower creativity for more factual content\n",
    "}\n",
    "\n",
    "audio_file = process_content(transcript_file=transcript_file,\n",
    "                              conversation_config=debate_config,\n",
    "                              longform=False,\n",
    "                              generate_audio=True,\n",
    "                              tts_model='geminimulti'\n",
    "                             )\n",
    "\n",
    "\n",
    "def embed_audio(audio_file):\n",
    "    \"\"\"\n",
    "    Embeds an audio file in the notebook, making it playable.\n",
    "\n",
    "    Args:\n",
    "        audio_file (str): Path to the audio file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        display(Audio(audio_file))\n",
    "        print(f\"Audio player embedded for: {audio_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error embedding audio: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6db5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_audio(audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the file into ./podcast.mp3\n",
    "\n",
    "try:\n",
    "    # Extract the filename from the given path\n",
    "    filename = os.path.basename(audio_file)\n",
    "\n",
    "    # Define the destination path (current directory)\n",
    "    destination = os.path.join(os.getcwd(), 'podcast.mp3')\n",
    "\n",
    "    # Move the file to the current directory\n",
    "    shutil.move(audio_file, destination)\n",
    "    print(f\"File '{filename}' successfully moved to the current directory.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file '{pathname}' does not exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a video with ffmpeg and a static image\n",
    "\n",
    "!ffmpeg -y -loop 1 -i title.jpg -i podcast.mp3 -c:v mpeg4 -c:a aac -b:a 192k -shortest -pix_fmt yuv420p podcast.mp4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80bca24",
   "metadata": {},
   "source": [
    "# Add screenshots to the video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15888d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(summary_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad433964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the urls from the text\n",
    "markdown_link_pattern = r'\\[.*?\\]\\((https?://[^\\)]+)\\)'  # Matches Markdown-style links [text](url)\n",
    "bare_url_pattern = r'(https?://[^\\s]+)'  # Matches bare URLs\n",
    "\n",
    "# Find matches\n",
    "markdown_links = re.findall(markdown_link_pattern, summary_content)\n",
    "bare_urls = re.findall(bare_url_pattern, summary_content)\n",
    "\n",
    "# has some trailing commas and parens sometimes\n",
    "all_urls = markdown_links + bare_urls\n",
    "all_urls_clean = [re.sub(r\"[,)\\s]+$\", \"\", u) for u in all_urls]\n",
    "\n",
    "sorted(all_urls_clean)\n",
    "# # Combine and remove duplicates\n",
    "urls = set(all_urls_clean)\n",
    "\n",
    "print(len(urls))\n",
    "sorted(list(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa14a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIdf = pd.DataFrame(state[\"AIdf\"])\n",
    "len(AIdf.loc[AIdf['url'].isin(urls)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f483006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe with idx, title, url, png, path\n",
    "results = []\n",
    "for i, u in enumerate(urls):\n",
    "    try:\n",
    "        tempdf = AIdf.loc[AIdf['url'].str.startswith(u)]\n",
    "        title = tempdf.iloc[0]['title']\n",
    "        path = tempdf.iloc[0]['path']\n",
    "        root = path.removeprefix(\"htmlpages/\")\n",
    "        root = root.removesuffix(\".html\")\n",
    "        png = f\"screenshots/{root}.png\"\n",
    "        results.append((i, title, u, png, path))\n",
    "    except Exception as exc:\n",
    "        pass\n",
    "#         print(f\"---\\n---\\n{u}\")\n",
    "xdf = pd.DataFrame(results, columns=['idx', 'title', 'url', 'png', 'path'])\n",
    "xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ccb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy screenshots to tmp directory in proper size\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "def resize_and_crop(input_path, output_path, size=(1000, 1000)):\n",
    "    # Open the image\n",
    "    with pil_image.open(input_path) as img:\n",
    "        # Convert to RGB mode to ensure compatibility\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "        # Calculate the resize ratio to make smallest side 1000 pixels\n",
    "        ratio = max(size[0]/min(img.size), size[1]/min(img.size))\n",
    "        new_size = tuple(int(dim * ratio) for dim in img.size)\n",
    "\n",
    "        # Resize the image\n",
    "        resized_img = img.resize(new_size, pil_image.Resampling.LANCZOS)\n",
    "\n",
    "        # Crop from top-left to 1000x1000\n",
    "        cropped_img = resized_img.crop((0, 0, size[0], size[1]))\n",
    "\n",
    "        # Save as JPEG with high quality\n",
    "        cropped_img.save(output_path, 'JPEG', quality=95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = \"tmp\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "\n",
    "# Remove all files in the tmp directory\n",
    "for filename in os.listdir(tmp_dir):\n",
    "    file_path = os.path.join(tmp_dir, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)  # Remove the file or symlink\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)  # Remove directories if needed\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "# loop through pandas dataframe, convert images to jpeg\n",
    "for row in xdf.itertuples():\n",
    "    input_path = row.png\n",
    "    output_path = \"tmp/\" + row.png.removeprefix(\"screenshots/\")\n",
    "    output_path = output_path.removesuffix(\".png\") + \".jpg\"\n",
    "    resize_and_crop(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63413359-ee67-47eb-953a-90822b892bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to manually edit durations\n",
    "# should be a way to get timestamps from tts (even with AI) but do it manually here\n",
    "\n",
    "input_file = \"\"\"\n",
    "file 'title.jpg'\n",
    "duration 7\n",
    "file 'tmp/AI_Jesus_is_ready_to_dispense_advice_from_a_booth_in_historic_Swiss_churchPope__Depeche_Mode__silent_on_digital_second_comingBootnotes1_day_50.jpg'\n",
    "duration 24\n",
    "file 'tmp/Amazon_Invests_an_Additional__4_Billion_in_Anthropic__an_OpenAI_Rival.jpg'\n",
    "duration 20\n",
    "file 'tmp/Utilities__regulators__and_researchers_in_six_countries_say_the_power_demand_surge_caused_by_AI_and_data_centers_is_being_met_in_the_near-term_by_fossil_fuels__Reuters.jpg'\n",
    "duration 15\n",
    "file 'tmp/A_federal_court_allows_a_claim_by_The_Intercept_that_DMCA_prevents_OpenAI_from_stripping_a_story_s_title_or_byline_but_throws_out_its_claims_against_Microsoft.jpg'\n",
    "duration 22\n",
    "file 'tmp/Jim_Cramer_Doubles_Down_On_Nvidia___Demand_Is_Accelerating__As_AI_Customers__Have_No_Choice__But_To_Buy_Its_Chips.jpg'\n",
    "duration 12\n",
    "file 'title.jpg'\n",
    "\"\"\"\n",
    "\n",
    "with open(\"input.txt\", \"w\") as outfile:\n",
    "    outfile.write(input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c2bd4",
   "metadata": {},
   "source": [
    "Potentially make better screenshots for video with AI (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24998f19-cbe6-4e6c-878f-bdf4378b2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "CROP_PROMPT = \"\"\"You will act as an expert visual editor. Crop this image to a square image that contains the main headline,\n",
    "any main image, and story text. Crop out edge space containing whitespace sidebars, navigation elements, or boilerplate.\n",
    "ensure that you do not crop any of the main headline. ensure that the output is a square image with equal horizontal and vertical dimensions. if you expand the image, the added area should be white space.\n",
    "\"\"\"\n",
    "\n",
    "# Load the image\n",
    "image_src = 'Why_Your_AIs_Success_Doesnt_Depend_On_The_Algorithm_But_The_Data_That_Powers_It.png'\n",
    "image_target = image_src[:-4] + '_crop.png'\n",
    "image_path = f'{SCREENSHOT_DIR}/{image_src}'\n",
    "image = PIL.Image.open(image_path)\n",
    "image = image.convert('RGB')\n",
    "\n",
    "# Convert the image to bytes\n",
    "image_bytes = BytesIO()\n",
    "image.save(image_bytes, format='JPEG')\n",
    "image_bytes = image_bytes.getvalue()\n",
    "\n",
    "# Call the OpenAI API with the prompt and image\n",
    "response = openai.Image.create(\n",
    "    prompt=CROP_PROMPT,\n",
    "    n=1,\n",
    "    size=\"1000x100\",\n",
    "    image=image_bytes\n",
    ")\n",
    "\n",
    "# Retrieve the cropped image\n",
    "cropped_image_url = response['data'][0]['url']\n",
    "cropped_image_response = requests.get(cropped_image_url)\n",
    "cropped_image = Image.open(BytesIO(cropped_image_response.content))\n",
    "\n",
    "# Save the cropped image\n",
    "cropped_image.save(image_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c2885-7c59-462d-8a4f-89a0b6d9aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the prompt\n",
    "CROP_PROMPT = \"\"\"You will act as an expert visual editor.\n",
    "Crop this image to a square 1024x1024 image that contains the main headline,\n",
    "any main image, and story text.\n",
    "Crop out edge space containing whitespace sidebars, navigation elements, or boilerplate.\n",
    "Pad the image as needed with whitespace to reach 1024x1024.\n",
    "Ensure that you do not resize parts of the image, only crop and pad it.\n",
    "Ensure that you do not crop any part of the main headline.\n",
    "Ensure that the output is a square image with equal horizontal and vertical dimensions. \"\"\"\n",
    "\n",
    "# Load the image\n",
    "image_src = 'Why_Your_AIs_Success_Doesnt_Depend_On_The_Algorithm_But_The_Data_That_Powers_It.png'\n",
    "image_path = f'{SCREENSHOT_DIR}/{image_src}'\n",
    "image_target = image_path[:-4] + '_crop.png'\n",
    "image = PIL.Image.open(image_path)\n",
    "\n",
    "# Convert the image to RGB mode and save to BytesIO\n",
    "image = image.convert('RGBA')\n",
    "image_bytes = BytesIO()\n",
    "image.save(image_bytes, format='PNG')\n",
    "image_bytes.seek(0)  # Reset the pointer to the start of the BytesIO object\n",
    "\n",
    "# Call the OpenAI API with the prompt and image\n",
    "response = client.images.edit(\n",
    "    image=image_bytes,  # Pass the BytesIO object directly\n",
    "    prompt=CROP_PROMPT,\n",
    "    n=1,\n",
    "    size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "\n",
    "# Get the URL of the generated image\n",
    "image_url = response.data[0].url\n",
    "\n",
    "cropped_image_response = requests.get(image_url)\n",
    "cropped_image = PIL.Image.open(BytesIO(cropped_image_response.content))\n",
    "cropped_image.save(image_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cefd1-1148-493a-920f-dadfa7bb5923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(image_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8e6c0",
   "metadata": {},
   "source": [
    "# Post YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee38f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work in progress, worked one time anyway\n",
    "\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from google.cloud import texttospeech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latest transcript for subtitles\n",
    "# kind of wanted to get timings and generate a well-formed transcript file\n",
    "# but due to multiple calls to Google TTS it's hard\n",
    "# might be easier to do with elevenlabs, modify it to write timings to a file\n",
    "\n",
    "TRANSCRIPT_DIR = \"/Users/drucev/projects/AInewsbot/data/transcripts\"\n",
    "\n",
    "# get most rcent transcript\n",
    "transcript_files = [f for f in os.listdir(TRANSCRIPT_DIR) if f.lower().endswith('.txt') and os.path.isfile(os.path.join(TRANSCRIPT_DIR, f))]\n",
    "transcript_file = max(transcript_files, key=lambda f: os.path.getmtime(os.path.join(TRANSCRIPT_DIR, f)))\n",
    "with open(f'{TRANSCRIPT_DIR}/{transcript_file}', 'r') as f:\n",
    "     transcript_content = f.read()\n",
    "\n",
    "display(Markdown(transcript_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log in to youtube\n",
    "def get_authenticated_service():\n",
    "    credentials = None\n",
    "\n",
    "    # Load the token.pickle file if it exists\n",
    "    if os.path.exists(TOKEN_PICKLE_FILE):\n",
    "        with open(TOKEN_PICKLE_FILE, 'rb') as token:\n",
    "            credentials = pickle.load(token)\n",
    "\n",
    "    # If there are no valid credentials available, prompt the user to log in\n",
    "    if not credentials or not credentials.valid:\n",
    "        if credentials and credentials.expired and credentials.refresh_token:\n",
    "            credentials.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRETS_FILE, SCOPES)\n",
    "            credentials = flow.run_local_server(port=0)\n",
    "\n",
    "        # Save the credentials for the next run\n",
    "        with open(TOKEN_PICKLE_FILE, 'wb') as token:\n",
    "            pickle.dump(credentials, token)\n",
    "\n",
    "    return build('youtube', 'v3', credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a59b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_srt(input_text):\n",
    "    \"\"\"Converts plain text to basic SRT format with estimated timing.\"\"\"\n",
    "    lines = input_text.strip().split('\\n')\n",
    "    srt_content = []\n",
    "    words_per_second = 2  # Adjust this value based on speaking speed\n",
    "\n",
    "    current_time = 0\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        words = len(line.split())\n",
    "        duration = words / words_per_second\n",
    "\n",
    "        start_time = current_time\n",
    "        end_time = current_time + duration\n",
    "\n",
    "        # Convert times to SRT format (HH:MM:SS,mmm)\n",
    "        start_str = f\"{int(start_time//3600):02d}:{int((start_time%3600)//60):02d}:{int(start_time%60):02d},000\"\n",
    "        end_str = f\"{int(end_time//3600):02d}:{int((end_time%3600)//60):02d}:{int(end_time%60):02d},000\"\n",
    "\n",
    "        srt_content.append(f\"{i}\\n{start_str} --> {end_str}\\n{line}\\n\")\n",
    "\n",
    "        current_time = end_time + 0.5  # Add a small gap between entries\n",
    "\n",
    "    return \"\\n\".join(srt_content)\n",
    "\n",
    "def prepare_transcript(transcript_file):\n",
    "    \"\"\"Converts a plain text transcript to SRT format if needed.\"\"\"\n",
    "    with open(transcript_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Check if it's already in SRT format\n",
    "    if not text.strip().startswith('1\\n00:'):\n",
    "        srt_content = convert_text_to_srt(text)\n",
    "        output_srt_file = transcript_file.rsplit('.', 1)[0] + '.srt'\n",
    "        with open(output_srt_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(srt_content)\n",
    "        return output_srt_file\n",
    "    return transcript_file\n",
    "\n",
    "# transcript_file = 'data/transcripts/transcript_01f2ab14fa2048fa998c577f9f2c944c.txt'\n",
    "# prepare_transcript(transcript_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2885ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_caption(youtube, video_id, transcript_file, language=\"en\"):\n",
    "    \"\"\"Uploads a caption track to YouTube video.\"\"\"\n",
    "    try:\n",
    "        # Read the caption content\n",
    "        with open(transcript_file, 'r', encoding='utf-8') as file:\n",
    "            caption_content = file.read()\n",
    "\n",
    "        # Create the caption insert request\n",
    "        insert_request = youtube.captions().insert(\n",
    "            part=\"snippet\",\n",
    "            body={\n",
    "                \"snippet\": {\n",
    "                    \"videoId\": video_id,\n",
    "                    \"language\": language,\n",
    "                    \"name\": \"English\",\n",
    "                    \"isDraft\": False\n",
    "                }\n",
    "            },\n",
    "            # Include the media upload with the caption content\n",
    "            media_body=MediaFileUpload(\n",
    "                transcript_file,\n",
    "                mimetype='application/x-subrip',  # for SRT files\n",
    "                resumable=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Execute the request\n",
    "        response = insert_request.execute()\n",
    "        print(f'Caption track uploaded successfully for video {video_id}')\n",
    "        return response\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f'An HTTP error {e.resp.status} occurred: {e.content}')\n",
    "    except Exception as e:\n",
    "        print(f'A general error occurred: {e}')\n",
    "\n",
    "def upload_video(video_file, title, description, tags, category_id, privacy_status, transcript_file=None):\n",
    "    \"\"\"Uploads a video to YouTube and optionally adds captions.\"\"\"\n",
    "\n",
    "    try:\n",
    "        youtube = get_authenticated_service()\n",
    "\n",
    "        # Define video metadata\n",
    "        body = {\n",
    "            'snippet': {\n",
    "                'title': title,\n",
    "                'description': description,\n",
    "                'tags': tags,\n",
    "                'categoryId': category_id\n",
    "            },\n",
    "            'status': {\n",
    "                'privacyStatus': privacy_status\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Upload the video file\n",
    "        media_body = MediaFileUpload(video_file,\n",
    "                                   chunksize=-1,\n",
    "                                   resumable=True,\n",
    "                                   mimetype='video/mp4')\n",
    "\n",
    "        request = youtube.videos().insert(\n",
    "            part='snippet,status',\n",
    "            body=body,\n",
    "            media_body=media_body\n",
    "        )\n",
    "\n",
    "        # Create a progress callback that prints the current progress\n",
    "        response = None\n",
    "        while response is None:\n",
    "            status, response = request.next_chunk()\n",
    "            if status:\n",
    "                print(f'Uploaded {int(status.progress() * 100)}%')\n",
    "\n",
    "        video_id = response[\"id\"]\n",
    "        print(f'Video upload complete! Video ID: {video_id}')\n",
    "\n",
    "        # If transcript file is provided, ensure it's in SRT format and upload it\n",
    "        if transcript_file and os.path.exists(transcript_file):\n",
    "            print(\"Converting transcript to SRT format...\")\n",
    "            srt_file = prepare_transcript(transcript_file)\n",
    "            print(\"Uploading caption track...\")\n",
    "            upload_caption(youtube, video_id, srt_file)\n",
    "\n",
    "        return video_id\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f'An HTTP error {e.resp.status} occurred: {e.content}')\n",
    "    except Exception as e:\n",
    "        print(f'A general error occurred: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca079f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if token expired\n",
    "# !rm token.pickle\n",
    "# I think this worked one time\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/youtube.upload',\n",
    "    'https://www.googleapis.com/auth/youtube.force-ssl',\n",
    "    'https://www.googleapis.com/auth/youtubepartner'\n",
    "]\n",
    "\n",
    "CLIENT_SECRETS_FILE = \"client_secret.json\"  # Download this from Google Cloud Console\n",
    "TOKEN_PICKLE_FILE = 'token.pickle'  # This will store the user's credentials\n",
    "\n",
    "# Replace placeholders with your actual video and transcript data\n",
    "today = datetime.today()\n",
    "formatted_date = today.strftime(\"%A, %B %d, %Y\")\n",
    "video_file = 'podcast2.mp4'\n",
    "title = f'Skynet and Chill Podcast for {formatted_date}'\n",
    "description = f'Skynet and Chill Podcast for {formatted_date}'\n",
    "tags = ['News','Artificial Intelligence']\n",
    "category_id = '28'  # Find your category ID here: https://developers.google.com/youtube/v3/docs/videoCategories/list\n",
    "privacy_status = 'public'  # Can be 'private', 'unlisted', or 'public'\n",
    "transcript_file = 'data/transcripts/transcript_01f2ab14fa2048fa998c577f9f2c944c.txt'\n",
    "\n",
    "vcode = upload_video(video_file, title, description, tags, category_id, privacy_status)\n",
    "vcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Image, Markdown, display\n",
    "display(Markdown(f'[https://www.youtube.com/watch?v={vcode}](https://www.youtube.com/watch?v={vcode})'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_text(text):\n",
    "    #\n",
    "    try:\n",
    "        # Initialize the client\n",
    "        client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "        # Set the text input to be synthesized\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "\n",
    "        # Build the voice request\n",
    "        voice = texttospeech.VoiceSelectionParams(\n",
    "            language_code=\"en-US\",\n",
    "            ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    "        )\n",
    "\n",
    "        # Select the type of audio file\n",
    "        audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "        )\n",
    "\n",
    "        # Perform the text-to-speech request\n",
    "        response = client.synthesize_speech(\n",
    "            input=synthesis_input,\n",
    "            voice=voice,\n",
    "            audio_config=audio_config\n",
    "        )\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce42090",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize_text(\"what's up doc?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849d094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ainewsbot",
   "language": "python",
   "name": "ainewsbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
