{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb072688",
   "metadata": {},
   "source": [
    "# Test LLM calling\n",
    "- test different ways of calling LLMS, native API, LangChain, sync/async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74032f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to selectively re-import as needed\n",
    "import sys\n",
    "# del sys.modules['ainb_llm']\n",
    "# del sys.modules['ainb_const']\n",
    "# del sys.modules['ainb_utilities']\n",
    "# del sys.modules['ainb_webscrape']\n",
    "# del sys.modules['AInewsbot_langgraph']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562be45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# import dotenv\n",
    "# import subprocess\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "import uuid\n",
    "import re\n",
    "# import operator\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import (ChatPromptTemplate, PromptTemplate,\n",
    "                                    SystemMessagePromptTemplate, HumanMessagePromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.errors import NodeInterrupt\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import bs4\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_exponential,\n",
    "    retry_if_exception_type\n",
    ")\n",
    "\n",
    "import asyncio\n",
    "from asyncio import Semaphore\n",
    "\n",
    "from IPython.display import HTML, Image, Markdown, display\n",
    "\n",
    "# import pyperclip\n",
    "# import shlex\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "import google.generativeai as genai\n",
    "\n",
    "import anthropic\n",
    "from anthropic import Anthropic\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, TypedDict, Annotated, Any\n",
    "\n",
    "import httpx\n",
    "\n",
    "import trafilatura   # web scrape uses this to get clean news stories w/o a lot of js and boilerplate\n",
    "\n",
    "from ainb_const import (\n",
    "                        \n",
    "                        REWRITE_PROMPT, FINAL_SUMMARY_PROMPT,\n",
    "                        SCREENSHOT_DIR, SUMMARIZE_SYSTEM_PROMPT, SUMMARIZE_USER_PROMPT\n",
    "                       )\n",
    "\n",
    "from ainb_utilities import log\n",
    "\n",
    "from AInewsbot_langgraph import (newscatcher_sources, fn_initialize, fn_download_sources, fn_extract_urls,\n",
    "                                 fn_verify_download, fn_extract_newscatcher, fn_filter_urls, fn_topic_clusters,\n",
    "                                 fn_topic_analysis, fn_download_pages, fn_summarize_pages, fn_propose_cats,\n",
    "                                 fn_compose_summary, fn_rewrite_summary, fn_is_revision_complete, fn_send_mail\n",
    "                                )\n",
    "\n",
    "\n",
    "import podcastfy\n",
    "from podcastfy.client import generate_podcast, process_content\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from IPython.display import Audio, display, Markdown\n",
    "\n",
    "import pdb\n",
    "\n",
    "# need this to run async in jupyter since it already has an asyncio event loop running\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Activate global verbose logging\n",
    "set_debug(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ba13ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python            3.11.11 | packaged by conda-forge | (main, Dec  5 2024, 14:21:42) [Clang 18.1.8 ]\n",
      "LangChain         0.3.18\n",
      "OpenAI            1.63.1\n",
      "Anthropic         0.45.2\n",
      "trafilatura       2.0.0\n",
      "numpy             1.26.4\n",
      "pandas            2.2.3\n",
      "sklearn           1.6.1\n",
      "umap              0.5.7\n",
      "podcastfy         0.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python            {sys.version}\")\n",
    "print(f\"LangChain         {langchain.__version__}\")\n",
    "print(f\"OpenAI            {openai.__version__}\")\n",
    "print(f\"Anthropic         {anthropic.__version__}\")\n",
    "# print(f\"smtplib           {smtplib.sys.version}\")\n",
    "print(f\"trafilatura       {trafilatura.__version__}\")\n",
    "# print(f\"bs4               {bs4.__version__}\")\n",
    "print(f\"numpy             {np.__version__}\")\n",
    "print(f\"pandas            {pd.__version__}\")\n",
    "print(f\"sklearn           {sklearn.__version__}\")\n",
    "print(f\"umap              {umap.__version__}\")\n",
    "print(f\"podcastfy         {podcastfy.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ebdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LOWCOST_MODEL, MODEL, HIGHCOST_MODEL = 'gpt-4o-mini', 'gpt-4o-2024-11-20', 'o3-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ed3b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:00,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ascoltami. Sei bellissima. Sei perfetta e ti amo.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 39, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7fcd609668', 'finish_reason': 'stop', 'logprobs': None}, id='run-1c2a9760-8483-46fa-9c04-b0cb530255fc-0', usage_metadata={'input_tokens': 39, 'output_tokens': 17, 'total_tokens': 56, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a basic LLM call with langchain\\\n",
    "openai_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "response = openai_model.invoke([\n",
    "    SystemMessage(content=\"You are a translator. Translate the following from English into Italian\"),\n",
    "    HumanMessage(content='Listen to me. You are beautiful. You are perfect and I love you.'),\n",
    "])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa52d702-271a-4caf-96dc-e8a47700fc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 17,\n",
       "  'prompt_tokens': 39,\n",
       "  'total_tokens': 56,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_7fcd609668',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8451135-7b09-4b78-9d7e-dab8d43cdbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 39,\n",
       " 'output_tokens': 17,\n",
       " 'total_tokens': 56,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata\n",
    "# no rate limit info like tokens remaining, available in headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c0bd0f-b529-4786-b325-2eae57835ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:03,760 - httpx - INFO - HTTP Request: GET https://api.openai.com/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage-002\n",
      "chatgpt-4o-latest\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini-audio-preview\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "o1\n",
      "o1-2024-12-17\n",
      "o1-mini\n",
      "o1-mini-2024-09-12\n",
      "o1-preview\n",
      "o1-preview-2024-09-12\n",
      "o3-mini\n",
      "o3-mini-2025-01-31\n",
      "omni-moderation-2024-09-26\n",
      "omni-moderation-latest\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "# Retrieve the list of available models\n",
    "models = client.models.list()\n",
    "\n",
    "# Print out the model IDs\n",
    "models = [model.id for model in models.data]\n",
    "models.sort()\n",
    "print(\"\\n\".join(models))\n",
    "# yay, we got o3-mini API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9357cdc3-c02a-499f-9ef2-c8d725173ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Gemini Models:\n",
      "-----------------------\n",
      "Name: models/gemini-1.0-pro-latest\n",
      "Description: The original Gemini 1.0 Pro model. This model will be discontinued on February 15th, 2025. Move to a newer Gemini version.\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.0-pro\n",
      "Description: The best model for scaling across a wide range of tasks\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-pro\n",
      "Description: The best model for scaling across a wide range of tasks\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.0-pro-001\n",
      "Description: The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 Pro will be discontinued on February 15th, 2025. Move to a newer Gemini version.\n",
      "Generation Methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
      "-----------------------\n",
      "Name: models/gemini-1.0-pro-vision-latest\n",
      "Description: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-pro-vision\n",
      "Description: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-pro-latest\n",
      "Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-pro-001\n",
      "Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-pro-002\n",
      "Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\n",
      "Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-pro\n",
      "Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-latest\n",
      "Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-001\n",
      "Description: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-001-tuning\n",
      "Description: Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "Generation Methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash\n",
      "Description: Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-002\n",
      "Description: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\n",
      "Generation Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-8b\n",
      "Description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-8b-001\n",
      "Description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-8b-latest\n",
      "Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "Generation Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-8b-exp-0827\n",
      "Description: Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-1.5-flash-8b-exp-0924\n",
      "Description: Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-flash-exp\n",
      "Description: Gemini 2.0 Flash Experimental\n",
      "Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-flash\n",
      "Description: Gemini 2.0 Flash\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-flash-001\n",
      "Description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-flash-lite-preview\n",
      "Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-flash-lite-preview-02-05\n",
      "Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-pro-exp\n",
      "Description: Experimental release (February 5th, 2025) of Gemini 2.0 Pro\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-pro-exp-02-05\n",
      "Description: Experimental release (February 5th, 2025) of Gemini 2.0 Pro\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-exp-1206\n",
      "Description: Experimental release (February 5th, 2025) of Gemini 2.0 Pro\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-flash-thinking-exp-01-21\n",
      "Description: Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-flash-thinking-exp\n",
      "Description: Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n",
      "Name: models/gemini-2.0-flash-thinking-exp-1219\n",
      "Description: Gemini 2.0 Flash Thinking Experimental\n",
      "Generation Methods: ['generateContent', 'countTokens']\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "def list_gemini_models():\n",
    "    try:\n",
    "        # Configure the library\n",
    "        genai.configure()\n",
    "\n",
    "        # List available models\n",
    "        models = genai.list_models()\n",
    "\n",
    "        print(\"Available Gemini Models:\")\n",
    "        print(\"-----------------------\")\n",
    "        for m in models:\n",
    "            if \"gemini\" in m.name.lower():\n",
    "                print(f\"Name: {m.name}\")\n",
    "                print(f\"Description: {m.description}\")\n",
    "                print(f\"Generation Methods: {m.supported_generation_methods}\")\n",
    "                print(\"-----------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "list_gemini_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82d1c0b-342e-49db-b311-f4a141e73db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascoltami. Sei bellissima. Sei perfetto/a e ti amo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try Gemini\n",
    "# GEMINI_MODEL = \"gemini-1.5-pro\"  # or \"flash\" depending on the desired model\n",
    "GEMINI_MODEL = \"gemini-2.0-flash-exp\"\n",
    "\n",
    "gmodel = ChatGoogleGenerativeAI(\n",
    "    model=GEMINI_MODEL,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a translator. Translate the following from English into Italian without explanation or comment.\"),\n",
    "    HumanMessage(content=\"Listen to me. You are beautiful. You are perfect and I love you.\"),\n",
    "]\n",
    "\n",
    "# Invoke the model\n",
    "response = gmodel.invoke(messages)\n",
    "\n",
    "# Print the response\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893686e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:09,271 - httpx - INFO - HTTP Request: GET https://api.anthropic.com/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Anthropic Models:\n",
      "- claude-3-7-sonnet-20250219\n",
      "  Description: Claude 3.7 Sonnet\n",
      "  Created: 2025-02-19 00:00:00+00:00\n",
      "\n",
      "- claude-3-5-sonnet-20241022\n",
      "  Description: Claude 3.5 Sonnet (New)\n",
      "  Created: 2024-10-22 00:00:00+00:00\n",
      "\n",
      "- claude-3-5-haiku-20241022\n",
      "  Description: Claude 3.5 Haiku\n",
      "  Created: 2024-10-22 00:00:00+00:00\n",
      "\n",
      "- claude-3-5-sonnet-20240620\n",
      "  Description: Claude 3.5 Sonnet (Old)\n",
      "  Created: 2024-06-20 00:00:00+00:00\n",
      "\n",
      "- claude-3-haiku-20240307\n",
      "  Description: Claude 3 Haiku\n",
      "  Created: 2024-03-07 00:00:00+00:00\n",
      "\n",
      "- claude-3-opus-20240229\n",
      "  Description: Claude 3 Opus\n",
      "  Created: 2024-02-29 00:00:00+00:00\n",
      "\n",
      "- claude-3-sonnet-20240229\n",
      "  Description: Claude 3 Sonnet\n",
      "  Created: 2024-02-29 00:00:00+00:00\n",
      "\n",
      "- claude-2.1\n",
      "  Description: Claude 2.1\n",
      "  Created: 2023-11-21 00:00:00+00:00\n",
      "\n",
      "- claude-2.0\n",
      "  Description: Claude 2.0\n",
      "  Created: 2023-07-11 00:00:00+00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Anthropic client with your API key\n",
    "client = Anthropic(api_key=os.environ.get(\"CLAUDE_API_KEY\"))\n",
    "\n",
    "# List available models\n",
    "models = client.models.list()\n",
    "\n",
    "# Print model information\n",
    "print(\"Available Anthropic Models:\")\n",
    "for model in models.data:\n",
    "    print(f\"- {model.id}\")\n",
    "    print(f\"  Description: {model.display_name}\")\n",
    "    print(f\"  Created: {model.created_at}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ceaee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:10,706 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascoltami. Sei bellissima. Sei perfetta e ti amo.\n"
     ]
    }
   ],
   "source": [
    "# anthropic\n",
    "\n",
    "# Initialize the ChatAnthropic model\n",
    "claude_model = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    anthropic_api_key=os.environ[\"CLAUDE_API_KEY\"],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Create the messages\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a translator. Translate the following from English into Italian without explanation or comment.\"),\n",
    "    HumanMessage(content=\"Listen to me. You are beautiful. You are perfect and I love you.\"),\n",
    "]\n",
    "\n",
    "# Invoke the model\n",
    "response = claude_model.invoke(messages)\n",
    "\n",
    "# Print the response\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ff6dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:11,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ciao! Come posso aiutarti oggi?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a langchain template\n",
    "system_template = \"You are a translator. Translate the following from English into {language}:\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt_template | openai_model | parser\n",
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6382e44e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:12,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Écoute-moi. Tu es parfaite. Tu es belle et je t'aime.\n",
      "Écoute-moi. Tu es parfait(e). Tu es magnifique et je t'aime.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:14,057 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Écoute-moi. Tu es parfait(e). Tu es magnifique et je t'aime.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:14,728 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hör mir zu. Du bist makellos. Du bist exquisit und ich liebe dich.\n",
      "Hör mir zu. Du bist makellos. Du bist exquisit und ich liebe dich.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:22,387 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hör mir zu. Du bist makellos. Du bist wunderschön und ich liebe dich.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:23,131 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escúchame. Eres perfecta. Eres hermosa y te amo.\n",
      "Escúchame. Eres perfecto/perfecta. Eres precioso/preciosa y te amo/quiero.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:24,488 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escúchame. Eres perfecta. Eres preciosa y te amo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:25,327 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascoltami. Sei straordinario. Sei magnifico e ti amo.\n",
      "Ascoltami. Sei fantastico/a. Sei magnifico/a e ti amo.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:26,411 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ascoltami. Sei fantastico/a. Sei magnifico/a e ti amo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:27,381 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figyelj rám. Elbűvölő vagy. Lélegzetelállító vagy és szeretlek.\n",
      "Hallgass rám. Elragadó vagy. Lenyűgöző vagy, és szeretlek.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:29,058 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figyelj rám. Elragadó vagy. Gyönyörű vagy és szeretlek.\n",
      "\n",
      "\n",
      "Elapsed seconds: 17.386070\n"
     ]
    }
   ],
   "source": [
    "# time multiple templates (single-threaded)\n",
    "prompt_inputs = [\n",
    "    {\"language\": \"French\", \"adjective1\": \"flawless\", \"adjective2\": \"beautiful\"},\n",
    "    {\"language\": \"German\", \"adjective1\": \"immaculate\", \"adjective2\": \"exquisite\"},\n",
    "    {\"language\": \"Spanish\", \"adjective1\": \"perfect\", \"adjective2\": \"gorgeous\"},\n",
    "    {\"language\": \"Italian\", \"adjective1\": \"amazing\", \"adjective2\": \"magnificent\"},\n",
    "    {\"language\": \"Hungarian\", \"adjective1\": \"ravishing\", \"adjective2\": \"stunning\"},\n",
    "]\n",
    "system_template = 'You are a translator. Translate the following text from English into {language}. Provide only the translation, no other information:'\n",
    "user_template = 'Listen to me. You are {adjective1}. You are {adjective2} and I love you.'\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template),\n",
    "     (\"user\", user_template)]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "ochain = prompt_template | openai_model | parser\n",
    "gchain = prompt_template | gmodel | parser\n",
    "cchain = prompt_template | claude_model | parser\n",
    "\n",
    "start_time = datetime.now()\n",
    "for tpl in prompt_inputs:\n",
    "    for chain in [ochain, gchain, cchain]:\n",
    "        response = \"\"\n",
    "        #     print()\n",
    "        #     print(prompt_template.format(**tpl))\n",
    "        # stream tokens as they are generated\n",
    "        for r in chain.stream(tpl):\n",
    "            print(r, end=\"\")\n",
    "            response += r\n",
    "        print()\n",
    "end_time = datetime.now()\n",
    "\n",
    "difference = end_time - start_time\n",
    "total_seconds = difference.total_seconds()\n",
    "print(f\"\\n\\nElapsed seconds: {total_seconds:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe2d99b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queuing French translations...\n",
      "Queuing German translations...\n",
      "Queuing Spanish translations...\n",
      "Queuing Italian translations...\n",
      "Queuing Hungarian translations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:29,598 - langchain_google_genai.chat_models - WARNING - Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "2025-02-25 10:56:29,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:29,867 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:29,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:29,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:29,912 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:29,925 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:29,943 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:30,047 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:30,077 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:30,092 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai: Écoute-moi. Tu es parfaite. Tu es belle et je t'aime.\n",
      "\n",
      "google: Écoute-moi. Tu es parfait(e). Tu es magnifique et je t'aime.\n",
      "\n",
      "\n",
      "claude: Écoute-moi. Tu es parfait(e). Tu es magnifique et je t'aime.\n",
      "\n",
      "openai: Hör mir zu. Du bist makellos. Du bist exquisit und ich liebe dich.\n",
      "\n",
      "google: Hör mir zu. Du bist makellos. Du bist exquisit und ich liebe dich.\n",
      "\n",
      "\n",
      "claude: Hör mir zu. Du bist makellos. Du bist wunderschön und ich liebe dich.\n",
      "\n",
      "openai: Escúchame. Eres perfecto. Eres hermosa y te amo.\n",
      "\n",
      "google: Escúchame. Eres perfecto/a. Eres precioso/a y te amo.\n",
      "\n",
      "\n",
      "claude: Escúchame. Eres perfecta. Eres preciosa y te amo.\n",
      "\n",
      "openai: Ascoltami. Sei fantastico. Sei magnifico e ti amo.\n",
      "\n",
      "google: Ascoltami. Sei fantastico/a. Sei magnifico/a e ti amo.\n",
      "\n",
      "\n",
      "claude: Ascoltami. Sei fantastico. Sei magnifico e ti amo.\n",
      "\n",
      "openai: Figyelj rám. Elbűvölő vagy. Lélegzetelállító vagy, és szeretlek.\n",
      "\n",
      "google: Hallgass rám. Elbűvölő vagy. Lenyűgöző vagy, és szeretlek.\n",
      "\n",
      "\n",
      "claude: Figyelj rám. Elragadó vagy. Gyönyörű vagy és szeretlek.\n",
      "\n",
      "\n",
      "Elapsed seconds: 2.651842\n"
     ]
    }
   ],
   "source": [
    "# Retry decorator with exponential backoff\n",
    "# if I run google too fast I get a 429 error, need to update something in gcp probably\n",
    "\n",
    "def should_retry_exception(exception):\n",
    "    \"\"\"Determine if the exception should trigger a retry. (always retry)\"\"\"\n",
    "    print(type(exception))\n",
    "    print(exception)\n",
    "    return True\n",
    "\n",
    "\n",
    "# @retry(\n",
    "#     stop=stop_after_attempt(8),  # Maximum 8 attempts\n",
    "#     wait=wait_exponential(multiplier=1, min=2, max=128),  # Wait 2^x * multiplier seconds between retries\n",
    "#     retry=retry_if_exception_type(should_retry_exception),\n",
    "#     before_sleep=lambda retry_state: print(f\"Retrying after {retry_state.outcome.exception()}, attempt {retry_state.attempt_number}\")\n",
    "# )\n",
    "async def process_translation(chain, inputs, name):\n",
    "    response = \"\"\n",
    "    async for chunk in chain.astream(inputs):\n",
    "        response += chunk\n",
    "    return response, name\n",
    "\n",
    "\n",
    "async def main():\n",
    "    prompt_inputs = [\n",
    "        {\"language\": \"French\", \"adjective1\": \"flawless\", \"adjective2\": \"beautiful\"},\n",
    "        {\"language\": \"German\", \"adjective1\": \"immaculate\", \"adjective2\": \"exquisite\"},\n",
    "        {\"language\": \"Spanish\", \"adjective1\": \"perfect\", \"adjective2\": \"gorgeous\"},\n",
    "        {\"language\": \"Italian\", \"adjective1\": \"amazing\", \"adjective2\": \"magnificent\"},\n",
    "        {\"language\": \"Hungarian\", \"adjective1\": \"ravishing\", \"adjective2\": \"stunning\"},\n",
    "    ]\n",
    "\n",
    "    system_template = 'You are a translator. Translate the following text into {language}. Provide only the translation, no other information:'\n",
    "    user_template = 'Listen to me. You are {adjective1}. You are {adjective2} and I love you.'\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_template),\n",
    "        (\"user\", user_template)\n",
    "    ])\n",
    "\n",
    "    parser = StrOutputParser()\n",
    "    ochain = prompt_template | openai_model | parser\n",
    "    gchain = prompt_template | gmodel | parser\n",
    "    cchain = prompt_template | claude_model | parser\n",
    "    chains = {'openai': ochain, 'google': gchain, 'claude': cchain}\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    tasks = []\n",
    "    for tpl in prompt_inputs:\n",
    "        print(f\"Queuing {tpl['language']} translations...\")\n",
    "        for name, chain in chains.items():\n",
    "            task = asyncio.create_task(process_translation(chain, tpl, name))\n",
    "            tasks.append(task)\n",
    "\n",
    "    try:\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        for response, name in responses:\n",
    "            print(f\"{name}: {response}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {str(e)}\")\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    difference = end_time - start_time\n",
    "    total_seconds = difference.total_seconds()\n",
    "    print(f\"\\nElapsed seconds: {total_seconds:.6f}\")\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "659782d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:35,020 - langchain_google_genai.chat_models - WARNING - Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "2025-02-25 10:56:35,021 - langchain_google_genai.chat_models - WARNING - Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "2025-02-25 10:56:35,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:35,603 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:35,613 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:35,677 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:35,699 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:35,797 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:35,814 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:35,825 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:35,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-25 10:56:36,847 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai: Écoute-moi. Tu es parfaite. Tu es belle et je t'aime.\n",
      "google: Écoute-moi. Tu es parfait(e). Tu es magnifique et je t'aime.\n",
      "\n",
      "claude: Écoute-moi. Tu es parfait(e). Tu es magnifique et je t'aime.\n",
      "openai: Hör mir zu. Du bist makellos. Du bist exquisit und ich liebe dich.\n",
      "google: Hör mir zu. Du bist makellos. Du bist exquisit und ich liebe dich.\n",
      "\n",
      "claude: Hör mir zu. Du bist makellos. Du bist wunderschön und ich liebe dich.\n",
      "openai: Escúchame. Eres perfecto. Eres hermosa y te amo.\n",
      "google: Escúchame. Eres perfecto/perfecta. Eres precioso/preciosa y te amo/quiero.\n",
      "\n",
      "claude: Escúchame. Eres perfecta. Eres preciosa y te amo.\n",
      "openai: Ascoltami. Sei straordinario. Sei magnifico e ti amo.\n",
      "google: Ascoltami. Sei fantastico/a. Sei magnifico/a e ti amo.\n",
      "\n",
      "claude: Ascoltami. Sei fantastico/a. Sei magnifico/a e ti amo.\n",
      "openai: Hallgass rám. Elbűvölő vagy. Lenyűgöző vagy, és szeretlek.\n",
      "google: Hallgass rám. Elbűvölő vagy. Lenyűgöző vagy, és szeretlek.\n",
      "\n",
      "claude: Figyelj rám. Elragadó vagy. Gyönyörű vagy és szeretlek.\n",
      "\n",
      "\n",
      "Elapsed seconds: 2.571748\n"
     ]
    }
   ],
   "source": [
    "# same but use ainvoke, no stream\n",
    "# Rate limit settings\n",
    "# CALLS_PER_MINUTE = 60  # Adjust based on your quota\n",
    "# MAX_CONCURRENT = 5     # Maximum concurrent requests\n",
    "# sem = Semaphore(MAX_CONCURRENT) # semaphore for controlling concurrent requests\n",
    "\n",
    "# @sleep_and_retry\n",
    "# @limits(calls=CALLS_PER_MINUTE, period=60)\n",
    "@retry(\n",
    "    stop=stop_after_attempt(8),  # Maximum 8 attempts\n",
    "    wait=wait_exponential(multiplier=1, min=2, max=128),  # Wait 2^x * multiplier seconds between retries\n",
    "    retry=retry_if_exception_type(should_retry_exception),\n",
    "    before_sleep=lambda retry_state: print(f\"Retrying after {retry_state.outcome.exception()}, attempt {retry_state.attempt_number}\")\n",
    ")\n",
    "async def async_langchain(chain, input_dict, name=\"\"):\n",
    "#     async with sem:\n",
    "        response = await chain.ainvoke(input_dict)\n",
    "        return response, name\n",
    "\n",
    "prompt_templates = [\n",
    "    {\"language\": \"French\", \"adjective1\": \"flawless\", \"adjective2\": \"beautiful\"},\n",
    "    {\"language\": \"German\", \"adjective1\": \"immaculate\", \"adjective2\": \"exquisite\"},\n",
    "    {\"language\": \"Spanish\", \"adjective1\": \"perfect\", \"adjective2\": \"gorgeous\"},\n",
    "    {\"language\": \"Italian\", \"adjective1\": \"amazing\", \"adjective2\": \"magnificent\"},\n",
    "    {\"language\": \"Hungarian\", \"adjective1\": \"ravishing\", \"adjective2\": \"stunning\"},\n",
    "]\n",
    "\n",
    "chains = {'openai': ochain, \n",
    "          'google': gchain, \n",
    "          'claude': cchain}\n",
    "\n",
    "start_time = datetime.now()\n",
    "tasks = []\n",
    "for d in prompt_templates:\n",
    "    for name, chain in chains.items():\n",
    "        task = asyncio.create_task(async_langchain(chain, d, name))\n",
    "        tasks.append(task)\n",
    "responses = await asyncio.gather(*tasks)\n",
    "end_time = datetime.now()\n",
    "\n",
    "difference = end_time - start_time\n",
    "total_seconds = difference.total_seconds()\n",
    "for response, name in responses:\n",
    "    print(f\"{name}: {response}\")\n",
    "print(f\"\\n\\nElapsed seconds: {total_seconds:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "203ddd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:56:53,330 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is one way to write a Python script that accomplishes this task:\n",
      "\n",
      "---------------------------\n",
      "\n",
      "#!/usr/bin/env python3\n",
      "import sys\n",
      "\n",
      "def parse_matrix(matrix_str):\n",
      "    # First, remove spaces and then split on '],'\n",
      "    # Remove leading and trailing square brackets if present\n",
      "    matrix_str = matrix_str.strip()\n",
      "    # Remove any outer brackets - if the string was something like '[[1,2],[3,4]]'\n",
      "    if matrix_str.startswith('[') and matrix_str.endswith(']'):\n",
      "        matrix_str = matrix_str[1:-1]\n",
      "    # Now split along '],'\n",
      "    rows = []\n",
      "    # A simple approach: split by '],'\n",
      "    parts = matrix_str.split('],')\n",
      "    for part in parts:\n",
      "        # cleanup part\n",
      "        part = part.strip('[] ')\n",
      "        if part:\n",
      "            # convert each number to an integer\n",
      "            numbers = [int(x.strip()) for x in part.split(',')]\n",
      "            rows.append(numbers)\n",
      "    return rows\n",
      "\n",
      "def transpose(matrix):\n",
      "    # Use zip(*matrix) to produce the transpose.\n",
      "    return list(map(list, zip(*matrix)))\n",
      "\n",
      "def format_matrix(matrix):\n",
      "    # Format matrix as '[a,b],[c,d],...'\n",
      "    formatted_rows = []\n",
      "    for row in matrix:\n",
      "        row_str = ','.join(str(x) for x in row)\n",
      "        formatted_rows.append(f'[{row_str}]')\n",
      "    return ','.join(formatted_rows)\n",
      "\n",
      "def main():\n",
      "    # For demonstration, let the input string be given as an argument.\n",
      "    if len(sys.argv) != 2:\n",
      "        print(\"Usage: {} '<matrix_string>'\".format(sys.argv[0]))\n",
      "        print(\"Example: {} '[1,2],[3,4],[5,6]'\".format(sys.argv[0]))\n",
      "        sys.exit(1)\n",
      "        \n",
      "    input_str = sys.argv[1]\n",
      "    try:\n",
      "        matrix = parse_matrix(input_str)\n",
      "    except Exception as e:\n",
      "        print(\"Error parsing matrix:\", e)\n",
      "        sys.exit(1)\n",
      "    \n",
      "    # Check if the matrix is well-formed (all rows having equal numbers of columns)\n",
      "    if not matrix:\n",
      "        print(\"Error: The matrix is empty.\")\n",
      "        sys.exit(1)\n",
      "    num_cols = len(matrix[0])\n",
      "    for row in matrix:\n",
      "        if len(row) != num_cols:\n",
      "            print(\"Error: All rows must have the same number of elements.\")\n",
      "            sys.exit(1)\n",
      "    \n",
      "    transposed = transpose(matrix)\n",
      "    output_str = format_matrix(transposed)\n",
      "    print(output_str)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "\n",
      "---------------------------\n",
      "\n",
      "Explanation:\n",
      "\n",
      "1. The script takes a single command line argument: a string representing the matrix in the format \"[1,2],[3,4],[5,6]\".  \n",
      "2. The parse_matrix() function splits this string into rows, removes the extra brackets, and converts each element to an integer.\n",
      "3. The transpose() function uses Python’s built-in zip function to transpose the matrix.\n",
      "4. The format_matrix() function converts the transposed matrix back into the same string format.\n",
      "5. The main() function parses the input, verifies that the matrix is well-formed, computes the transpose, prints the output, and handles possible errors.\n",
      "\n",
      "You can run the script like so:  \n",
      "$ python3 script.py \"[1,2],[3,4],[5,6]\"\n",
      "\n",
      "Expected output:  \n",
      "[1,3,5],[2,4,6]\n"
     ]
    }
   ],
   "source": [
    "# test o3-mini\n",
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    reasoning_effort = \"low\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will act as an expert Python developer.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a Python script that takes a matrix represented as a string with format '[1,2],[3,4],[5,6]' and prints the transpose in the same format.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c736089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:57:13,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is one solution that reads the matrix from a string, computes its transpose, and prints the result in the same format:\n",
      "\n",
      "------------------------------------------------------------\n",
      "#!/usr/bin/env python3\n",
      "import sys\n",
      "\n",
      "def parse_matrix(matrix_str):\n",
      "    \"\"\"\n",
      "    Given a string like \"[1,2],[3,4],[5,6]\",\n",
      "    convert it to a list of lists [[1, 2], [3, 4], [5, 6]].\n",
      "    \"\"\"\n",
      "    # Surround the string with brackets to create a valid literal\n",
      "    try:\n",
      "        # Use eval safely by controlling globals and locals\n",
      "        matrix = eval(f'[{matrix_str}]', {\"__builtins__\":None}, {})\n",
      "    except Exception as e:\n",
      "        print(\"Error parsing matrix:\", e)\n",
      "        sys.exit(1)\n",
      "    return matrix\n",
      "\n",
      "def transpose(matrix):\n",
      "    \"\"\"\n",
      "    Transpose the given matrix.\n",
      "    \"\"\"\n",
      "    if not matrix:\n",
      "        return []\n",
      "    # Use zip(*matrix) to extract the columns as rows\n",
      "    return [list(row) for row in zip(*matrix)]\n",
      "\n",
      "def format_matrix(matrix):\n",
      "    \"\"\"\n",
      "    Format the matrix as a string in the form \"[a,b],[c,d],...\"\n",
      "    \"\"\"\n",
      "    row_strings = []\n",
      "    for row in matrix:\n",
      "        # Convert each element to string and join with commas\n",
      "        row_str = \"[\" + \",\".join(map(str, row)) + \"]\"\n",
      "        row_strings.append(row_str)\n",
      "    return \",\".join(row_strings)\n",
      "\n",
      "def main():\n",
      "    # For demonstration, you can use command line argument or input.\n",
      "    # For example, if a matrix is passed as the first command-line argument:\n",
      "    if len(sys.argv) > 1:\n",
      "        matrix_str = sys.argv[1]\n",
      "    else:\n",
      "        matrix_str = input(\"Enter matrix (e.g. '[1,2],[3,4],[5,6]'): \")\n",
      "\n",
      "    # Parse, compute transpose, and format the result.\n",
      "    matrix = parse_matrix(matrix_str)\n",
      "    transposed = transpose(matrix)\n",
      "    output = format_matrix(transposed)\n",
      "    print(output)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "------------------------------------------------------------\n",
      "\n",
      "How it works:\n",
      "1. The function parse_matrix() adds outer square brackets around your input string so that it becomes a valid list literal (e.g. turning \"[1,2],[3,4],[5,6]\" into \"[[1,2],[3,4],[5,6]]\"). It then uses eval in a restricted context.\n",
      "2. The transpose() function uses Python’s built‑in zip(*) function.\n",
      "3. The format_matrix() function converts the list of lists back into the given string format.\n",
      "4. The script reads the matrix either from the command-line arguments or from standard input, computes its transpose, and prints it.\n",
      "\n",
      "For the input \"[1,2],[3,4],[5,6]\", the output will be: \n",
      "[1,3,5],[2,4,6]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You will act as an expert Python developer.\"),\n",
    "     (\"user\", \"{input}\")]\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "openai_model = ChatOpenAI(model=\"o3-mini\", reasoning_effort=\"low\")\n",
    "ochain = prompt_template | openai_model | parser\n",
    "response = ochain.invoke(\"Write a Python script that takes a matrix represented as a string with format '[1,2],[3,4],[5,6]' and prints the transpose in the same format.\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "085e0db6-a2f1-4faa-b0e0-ebdf5a638e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:57:14,661 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"chatcmpl-B4razvoi1wanjloNgST3PfijerAsr\",\n",
      "   \"object\": \"chat.completion\",\n",
      "   \"created\": 1740499033,\n",
      "   \"model\": \"gpt-4o-2024-08-06\",\n",
      "   \"choices\": [\n",
      "      {\n",
      "         \"index\": 0,\n",
      "         \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"The question about the airspeed velocity of an unladen swallow is a humorous reference from the movie \\\"Monty Python and the\",\n",
      "            \"refusal\": null\n",
      "         },\n",
      "         \"logprobs\": null,\n",
      "         \"finish_reason\": \"length\"\n",
      "      }\n",
      "   ],\n",
      "   \"usage\": {\n",
      "      \"prompt_tokens\": 18,\n",
      "      \"completion_tokens\": 25,\n",
      "      \"total_tokens\": 43,\n",
      "      \"prompt_tokens_details\": {\n",
      "         \"cached_tokens\": 0,\n",
      "         \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "         \"reasoning_tokens\": 0,\n",
      "         \"audio_tokens\": 0,\n",
      "         \"accepted_prediction_tokens\": 0,\n",
      "         \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "   },\n",
      "   \"service_tier\": \"default\",\n",
      "   \"system_fingerprint\": \"fp_eb9dce56a8\"\n",
      "}\n",
      "\n",
      "Headers starting with 'x-':\n",
      "x-ratelimit-limit-requests: 10000\n",
      "x-ratelimit-limit-tokens: 30000000\n",
      "x-ratelimit-remaining-requests: 9999\n",
      "x-ratelimit-remaining-tokens: 29999961\n",
      "x-ratelimit-reset-requests: 0.006\n",
      "x-ratelimit-reset-tokens: 0\n",
      "x-request-id: req_ea4023d4bf801f132c35ae09596ef840\n",
      "x-content-type-options: nosniff\n"
     ]
    }
   ],
   "source": [
    "# could use the metadata to saturate the OpenAI API and use as many tokens per second as available\n",
    "# but not supported by langchain across multiple models so exponential backoff seems to be the best alternative\n",
    "\n",
    "apikey = os.environ.get(\"OPENAI_API_KEY\")\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"OpenAI-Beta\": \"assistants=v2\",\n",
    "    \"Authorization\": f\"Bearer {apikey}\"\n",
    "}\n",
    "body = {\n",
    "    \"model\": \"gpt-4o-2024-08-06\", \"max_tokens\": 25, \"top_p\": 0.8,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": [{\"type\": \"text\", \"text\": \"What is the airspeed velocity of an unladen swallow\"}]\n",
    "        }\n",
    "    ]}\n",
    "\n",
    "try:\n",
    "    response = httpx.post(url, headers=headers, json=body)\n",
    "    response_json = response.json()\n",
    "    print(json.dumps(response_json, indent=3))\n",
    "\n",
    "    # Extract headers starting with 'x-' and load them into a dictionary\n",
    "    x_headers = {k: v for k, v in response.headers.items() if k.lower().startswith('x-')}\n",
    "\n",
    "    # Convert time values into seconds\n",
    "    time_multipliers = {'h': 3600, 'm': 60, 's': 1, 'ms': 0.001}\n",
    "    rate_headers = ['x-ratelimit-limit-requests', 'x-ratelimit-limit-tokens',\n",
    "                    'x-ratelimit-remaining-requests', 'x-ratelimit-remaining-tokens',\n",
    "                    'x-ratelimit-reset-requests', 'x-ratelimit-reset-tokens']\n",
    "    for key in rate_headers:\n",
    "        if key in x_headers:\n",
    "            if 'reset' in key:\n",
    "                total_time = 0\n",
    "                for time_part in re.findall(r'(\\d+)([hms]+)', x_headers[key]):\n",
    "                    total_time += int(time_part[0]) * time_multipliers[time_part[1]]\n",
    "                x_headers[key] = total_time\n",
    "            else:\n",
    "                x_headers[key] = int(x_headers[key])\n",
    "\n",
    "    # Print the headers\n",
    "    print(\"\\nHeaders starting with 'x-':\")\n",
    "    for key, value in x_headers.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f51a7b3-5aae-4021-8a5e-55e213d95757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:57:17,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Science Fair\",\n",
      "  \"date\": \"Friday\",\n",
      "  \"participants\": [\n",
      "    \"Alice\",\n",
      "    \"Bob\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structured response from openai using pydantic and openai api\n",
    "client = OpenAI()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information in JSON format.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "\n",
    "print(json.dumps(json.loads(event.json()), indent=2))\n",
    "\n",
    "event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d95dad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 10:57:23,245 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Science Fair\",\n",
      "  \"date\": \"2025-02-28\",\n",
      "  \"participants\": [\n",
      "    \"Alice\",\n",
      "    \"Bob\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='Science Fair', date='2025-02-28', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using langchain and with_structured_output\n",
    "formatted_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "system_prompt = f\"\"\"You are a precise calendar event extractor. Your task is to extract event details from natural language and format them as structured data.\n",
    "\n",
    "TASK REQUIREMENTS:\n",
    "1. Extract exactly three pieces of information:\n",
    "   - Event name (be specific and descriptive)\n",
    "   - Event date (convert relative dates to YYYY-MM-DD format)\n",
    "   - List of all participants mentioned\n",
    "\n",
    "RULES:\n",
    "- Convert relative dates using today's date ({formatted_date}) as reference\n",
    "- Include a descriptive event name even if only implied\n",
    "- List ALL participants mentioned, even in passing\n",
    "- Never include participants who aren't explicitly mentioned\n",
    "- If any required information is missing, make reasonable assumptions based on context\n",
    "\n",
    "Example Input: \"Alice and Bob are going to a science fair on Friday\"\n",
    "\n",
    "Example Output:\n",
    "{{{{\n",
    "    \"name\": \"Science Fair\",\n",
    "    \"date\": \"2024-02-02\",\n",
    "    \"participants\": [\"Alice\", \"Bob\"]\n",
    "}}}}\n",
    "\n",
    "FORMAT INSTRUCTIONS:\n",
    "The output should be a JSON object with the following schema:\n",
    "{{{{\n",
    "    \"name\": string,       // The name or title of the event\n",
    "    \"date\": string,       // The date in YYYY-MM-DD format\n",
    "    \"participants\": [     // Array of participant names\n",
    "        string,\n",
    "        ...\n",
    "    ]\n",
    "}}}}\n",
    "\"\"\"\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str = Field(description=\"The name or title of the event\")\n",
    "    date: str = Field(description=\"The date of the event in ISO format (YYYY-MM-DD)\")\n",
    "    participants: List[str] = Field(description=\"List of people participating in the event\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=CalendarEvent)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{input_text}\")\n",
    "])\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt | openai_model.with_structured_output(CalendarEvent)\n",
    "\n",
    "# Run the chain\n",
    "response = chain.invoke({\n",
    "    \"input_text\": \"Alice and Bob are going to a science fair on Friday.\"\n",
    "})\n",
    "\n",
    "# Print the formatted result\n",
    "print(json.dumps(response.dict(), indent=2))\n",
    "\n",
    "# The response is a CalendarEvent object\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1cc1a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.json import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "698abd91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "20 validation errors for TopicSpecList\nitems.0.extracted_topics\n  Field required [type=missing, input_value={'id': 0.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.1.extracted_topics\n  Field required [type=missing, input_value={'id': 1.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.2.extracted_topics\n  Field required [type=missing, input_value={'id': 2.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.3.extracted_topics\n  Field required [type=missing, input_value={'id': 3.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.4.extracted_topics\n  Field required [type=missing, input_value={'id': 4.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.5.extracted_topics\n  Field required [type=missing, input_value={'id': 5.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.6.extracted_topics\n  Field required [type=missing, input_value={'id': 6.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.7.extracted_topics\n  Field required [type=missing, input_value={'id': 7.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.8.extracted_topics\n  Field required [type=missing, input_value={'id': 8.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.9.extracted_topics\n  Field required [type=missing, input_value={'id': 9.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.10.extracted_topics\n  Field required [type=missing, input_value={'id': 11.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.11.extracted_topics\n  Field required [type=missing, input_value={'id': 12.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.12.extracted_topics\n  Field required [type=missing, input_value={'id': 13.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.13.extracted_topics\n  Field required [type=missing, input_value={'id': 14.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.14.extracted_topics\n  Field required [type=missing, input_value={'id': 15.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.15.extracted_topics\n  Field required [type=missing, input_value={'id': 16.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.16.extracted_topics\n  Field required [type=missing, input_value={'id': 17.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.17.extracted_topics\n  Field required [type=missing, input_value={'id': 18.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.18.extracted_topics\n  Field required [type=missing, input_value={'id': 19.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.19.extracted_topics\n  Field required [type=missing, input_value={'id': 20.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 187\u001b[0m\n\u001b[1;32m    184\u001b[0m input_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_text}\n\u001b[1;32m    186\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt_template \u001b[38;5;241m|\u001b[39m model\u001b[38;5;241m.\u001b[39mwith_structured_output(TopicSpecList)\n\u001b[0;32m--> 187\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m resp \u001b[38;5;241m=\u001b[39m (response\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m8\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m    190\u001b[0m resp_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(resp\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:193\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage],\n\u001b[1;32m    189\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    204\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    205\u001b[0m             config,\n\u001b[1;32m    206\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/runnables/base.py:1922\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1918\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1919\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1920\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1921\u001b[0m         Output,\n\u001b[0;32m-> 1922\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1925\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1930\u001b[0m     )\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1932\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:194\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage],\n\u001b[1;32m    189\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 194\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    197\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    198\u001b[0m             config,\n\u001b[1;32m    199\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    204\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    205\u001b[0m             config,\n\u001b[1;32m    206\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/langchain_core/output_parsers/openai_tools.py:294\u001b[0m, in \u001b[0;36mPydanticToolsParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     pydantic_objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mname_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m partial:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ainewsbot/lib/python3.11/site-packages/pydantic/main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 20 validation errors for TopicSpecList\nitems.0.extracted_topics\n  Field required [type=missing, input_value={'id': 0.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.1.extracted_topics\n  Field required [type=missing, input_value={'id': 1.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.2.extracted_topics\n  Field required [type=missing, input_value={'id': 2.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.3.extracted_topics\n  Field required [type=missing, input_value={'id': 3.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.4.extracted_topics\n  Field required [type=missing, input_value={'id': 4.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.5.extracted_topics\n  Field required [type=missing, input_value={'id': 5.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.6.extracted_topics\n  Field required [type=missing, input_value={'id': 6.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.7.extracted_topics\n  Field required [type=missing, input_value={'id': 7.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.8.extracted_topics\n  Field required [type=missing, input_value={'id': 8.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.9.extracted_topics\n  Field required [type=missing, input_value={'id': 9.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.10.extracted_topics\n  Field required [type=missing, input_value={'id': 11.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.11.extracted_topics\n  Field required [type=missing, input_value={'id': 12.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.12.extracted_topics\n  Field required [type=missing, input_value={'id': 13.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.13.extracted_topics\n  Field required [type=missing, input_value={'id': 14.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.14.extracted_topics\n  Field required [type=missing, input_value={'id': 15.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.15.extracted_topics\n  Field required [type=missing, input_value={'id': 16.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.16.extracted_topics\n  Field required [type=missing, input_value={'id': 17.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.17.extracted_topics\n  Field required [type=missing, input_value={'id': 18.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.18.extracted_topics\n  Field required [type=missing, input_value={'id': 19.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nitems.19.extracted_topics\n  Field required [type=missing, input_value={'id': 20.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing"
     ]
    }
   ],
   "source": [
    "input_prompt = \"\"\"As a specialized research assistant, your task is to perform detailed topic analysis\n",
    "of news item summaries. You will process news items summaries provided as a JSON object according to  \n",
    "the input specification below. You will extract topics of the news item summaries according to the \n",
    "output specification below and return a raw JSON object without any additional formatting or markdown syntax. \n",
    "\n",
    "Input Specification:\n",
    "You will receive an array of JSON objects representing news summaries.\n",
    "Each headline object contains exactly two fields:\n",
    "'id': A unique numeric identifier\n",
    "'summary': The news summmary item\n",
    "\n",
    "Example input:\n",
    "[\n",
    " {{\n",
    "    \"id\": 29,\n",
    "    \"summary\": \"• Elon Musk's xAI launched Grok 3, a new family of AI models trained using 100,000 Nvidia H100 GPUs at the Colossus Supercluster; benchmarks show it outperforms competitors like GPT-4o and Claude 3.5 Sonnet in areas such as math, science, and coding.\n",
    "\n",
    "• Grok 3 includes advanced features like reasoning models for step-by-step logical problem-solving and a DeepSearch function that synthesizes internet-sourced information into single answers; it is initially available to X Premium+ subscribers, with advanced features under a paid \"SuperGrok\" plan.\n",
    "\n",
    "• Former Tesla AI director Andrej Karpathy and others have confirmed Grok 3's strong performance, with Karpathy noting it is comparable to and slightly better than leading AI models from OpenAI and other competitors.\"\n",
    "  }},\n",
    "{{\n",
    "    \"id\": 34,\n",
    "    \"summary\": \"• Google Gemini has received a memory upgrade that allows it to recall past conversations and summarize previous chats, enhancing its ability to remember user preferences such as interests and professional details. This feature is currently available only to Google One AI Premium subscribers in English, with broader language support expected soon.\n",
    "\n",
    "• Users retain control over their data with options to delete past conversations, prevent chats from being saved, or set them to auto-delete, although discussions can still be used for AI training unless deleted.\n",
    "\n",
    "• Similar to OpenAI's ChatGPT persistent memory feature, Gemini's upgrade aims to make chats more practical, though users are advised not to input sensitive information as conversations may be reviewed for quality control.\"\n",
    "  }},\n",
    " {{\n",
    "    \"id\": 47,\n",
    "    \"summary\": \"• Major tech companies like OpenAI, Google, and Meta are competing to dominate generative AI, though the path to profitability remains uncertain.  \n",
    "\n",
    "• Chinese start-up DeepSeek has introduced a cost-effective way to build powerful AI, disrupting the market and pressuring established players.\n",
    "\n",
    "• OpenAI aims to reach 1 billion users, while Meta continues to invest heavily in AI despite market disruptions caused by DeepSeek.\"\n",
    "  }},\n",
    "{{\n",
    "    \"id\": 56,\n",
    "    \"summary\": \"- OpenAI is exploring new measures to protect itself from a potential hostile takeover by Elon Musk.  \n",
    "- The company is in discussions to empower its non-profit board to maintain control as it transitions into a for-profit business model.\"\n",
    "  }},\n",
    " {{\n",
    "    \"id\": 63,\n",
    "    \"summary\": \"- The New York Times has approved the use of select AI tools, such as GitHub Copilot, Google Vertex AI, and their in-house summarization tool Echo, to assist with tasks like content summarization, editing, and enhancing product development, while reinforcing the tools as aids rather than replacements for journalistic work.\n",
    "\n",
    "- Strict guidelines and safeguards have been implemented, including prohibitions on using AI to draft full articles, revise them significantly, or generate images and videos, with a mandatory training video to prevent misuse and protect journalistic integrity.\n",
    "\n",
    "- Some staff members have expressed concerns about AI potentially compromising creativity and accuracy, leading to skepticism about universal adoption, although the guidelines align with standard industry practices.\"\n",
    "  }},\n",
    "]\n",
    "\n",
    "Output Specification:\n",
    "Return a raw JSON object containing 'items', a list of JSON objects, each containing:\n",
    "'id': Matching the input item's id field.\n",
    "'extracted_topics': An array of relevant topic strings\n",
    "Topics should capture:\n",
    "- The main subject matter\n",
    "- Key entities (companies, people, products)\n",
    "- Technical domains, industry sectors, event types\n",
    "\n",
    "Output Example:\n",
    "{{items:\n",
    " [{{\"id\": 29, \"extracted_topics\": ['AI model development', 'xAI Grok capabilities', 'AI advancements']}},\n",
    "  {{\"id\": 34, \"extracted_topics\": ['Google Gemini', 'Interactive AI advancements', 'Digital assistants']}},\n",
    "  {{\"id\": 47, \"extracted_topics\": ['OpenAI', 'Google', 'Meta', 'DeepSeek']}},\n",
    "  {{\"id\": 56, \"extracted_topics\": ['OpenAI', 'non-profit oversight', 'anti-takeover strategies', 'Elon Musk']}},\n",
    "  {{\"id\": 63, \"extracted_topics\": ['New York Times', 'AI in journalism', 'GitHub Copilot', 'Google Vertex AI']}},\n",
    " ]\n",
    "}}\n",
    "\n",
    "Detailed Guidelines:\n",
    "The output must strictly adhere to the output specification.\n",
    "Do not return markdown, return a raw JSON string.\n",
    "For each input item, output a valid JSON object for each news item in the exact schema provided.\n",
    "Extract 3-6 relevant topics per news item.\n",
    "Avoid duplicate or redundant topics.\n",
    "Use topics which are as specific as possible.\n",
    "Please analyze the following news items and provide topic classifications according to these specifications:\n",
    "\"\"\"\n",
    "\n",
    "input_text = \\\n",
    "[\n",
    "  {\n",
    "    \"id\": 0,\n",
    "    \"summary\": \"4 days left to save up to $325 at TechCrunch Sessions: AI\\n* TechCrunch Sessions: AI will take place on June 5 at UC Berkeley's Zellerbach Hall, featuring speakers like Twelve Labs CEO Jae Lee, CapitalG partner Jill Chase, and Khosla Ventures partner Kanu Gulati.  One session will focus on how small companies can stay relevant in the rapidly changing AI space.\\n* The event will include main stage talks, breakout sessions, and demos of the latest AI advancements.  It's aimed at AI leaders, VCs, and tech enthusiasts.\\n* A discount of up to $325 on select tickets is available until March 2 at 11:59 p.m. PT.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 1,\n",
    "    \"summary\": \"57% of enterprise employees input confidential data into AI tools, survey reveals\\n* 57% of enterprise employees at companies with 5,000+ staff admitted to inputting confidential company data into publicly available generative AI tools like ChatGPT, according to a TELUS Digital Experience survey of 1,000 US-based employees.\\n* 68% of surveyed employees use personal AI accounts for work, indicating a rise in \\\"shadow AI\\\" practices that bypass IT and security oversight, increasing data exposure and compliance violation risks.\\n* While 29% of respondents confirmed their organizations have AI guidelines, enforcement is weak, with only 24% receiving AI training and 42% reporting no consequences for not following guidelines.  TELUS Digital Fuel iX general manager Bret Kinsella emphasized the need for secure, company-approved AI solutions to address the security risks associated with employees using personal AI accounts for work tasks.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 2,\n",
    "    \"summary\": \"A New Machine Learning Approach Answers What-If Questions\\n* Causal ML, an emerging machine learning technique, helps managers make better decisions by analyzing potential outcomes of different choices, unlike traditional ML which relies on correlations and may provide flawed insights for decision-making.\\n* Causal ML allows for exploring \\\"what-if\\\" scenarios, considering various factors and their influence on outcomes, such as determining the optimal R&D budget by considering its impact on revenue alongside other economic variables.\\n* While traditional ML remains suitable for predictions like stock prices or customer preferences, Causal ML is valuable for exploring cause-and-effect relationships and informing actions in various business functions like product development, finance, and marketing.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 3,\n",
    "    \"summary\": \"A major AI company filed accounts months late and pointed the finger at its Big Four auditor\\n* Supermicro filed delayed financial reports, blaming former auditor EY's resignation over concerns about financial reporting governance and senior management integrity.\\n* EY dropped Supermicro as a client in October 2024 after raising these concerns, prompting an internal review and the hiring of a new accounting firm, BDO.\\n* BDO found no material issues with Supermicro's financials, and the company's stock rebounded after the filings were submitted.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 4,\n",
    "    \"summary\": \"AI CAPTCHA Fails Are the Internets New Comedy Show!\\n* AI struggles with CAPTCHA challenges, particularly image-based ones, often misidentifying objects or failing to interpret blurred text.  Examples include AI misidentifying a painted bicycle symbol as a real bicycle and failing to transcribe blurred text.\\n* While AI can solve some simpler text-based CAPTCHAs, the increasing complexity of CAPTCHAs, including puzzle-based ones, poses a significant challenge even for advanced AI models.\\n* Dedicated CAPTCHA-solving tools, unlike AI, are specifically designed to bypass CAPTCHAs and are more effective for this purpose.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 5,\n",
    "    \"summary\": \"AI Overview jokes\\n* Google's AI Overview feature is producing humorous and inaccurate results for certain queries, including questions about elements ending in \\\"um\\\" and the kosher status of tripe.  The inaccuracies seem to stem from the LLMs' difficulty with spelling and counting, as well as a \\\"lossy-compressed summary of the internet.\\\"\\n* Users report Google is proactively suggesting these flawed queries in the search dropdown, raising questions about whether a human or an algorithm selected them as examples of AI Overview's capabilities.\\n*  Several users provided additional examples of inaccurate or nonsensical responses from Google's AI Overview, ranging from incorrect information about surnames of African origin to illogical hyphenation advice and flawed explanations of linguistic history.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 6,\n",
    "    \"summary\": \"AI startup Bridgetown Research raises $19 million in latest funding\\n* Bridgetown Research, a Seattle-based AI startup, raised $19 million in Series A funding, led by Lightspeed Venture Partners and Accel, with participation from a research university.  The funding round values the company at $250 million.\\n* Unlike many AI companies focused on LLMs, Bridgetown Research develops AI agents that collect and analyze proprietary data from experts and customer surveys to provide insights for strategic decision-making.\\n* The company plans to use the funding to expand the capabilities of its AI agents and broaden access to sector-specific intelligence through partnerships.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 7,\n",
    "    \"summary\": \"AI-Powered Ransomware Attacks\\n* AI is being used to enhance ransomware attacks, automating processes like vulnerability analysis, malware deployment, and lateral movement within networks, making them more sophisticated and harder to detect.\\n* AI-powered phishing attacks are becoming more targeted and convincing, leveraging publicly available data to create personalized messages and dynamically adjusting content based on recipient behavior.\\n* Defending against AI-powered ransomware requires a multi-layered approach including AI-driven security systems, firewalls, updated anti-malware software, intrusion detection systems, end-point detection and response tools, employee training, and robust incident response plans with regular data backups.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 8,\n",
    "    \"summary\": \"Akool unleashes enhancements to its AI human 3D avatars connected to LLMs\\n* Akool Inc. enhanced its AI-driven 3D human avatars to connect with large language models (LLMs), enabling dynamic conversational experiences.  The avatars can display emotions, movements, and hand gestures, creating a lifelike interaction similar to a video call.\\n* Akool offers two avatar types: talking avatars for scripted messages and streaming avatars for real-time conversations, suitable for customer service and guidance.  Users can customize LLMs or integrate with existing models like OpenAI's.\\n* Akool CEO Jiajun Lu highlighted the avatars' success in customer service and language education, citing the improved user experience from interacting with a lifelike figure. He also sees potential in government and healthcare.  Low latency and full-body motion capabilities are key differentiators for Akool's technology.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 9,\n",
    "    \"summary\": \"Alibaba And DeepSeek Intensify AI Showdown, Challenge OpenAI Market Dominance\\n* Chinese AI startup DeepSeek has reopened its core programming interface after a three-week suspension.\\n* DeepSeek had previously suspended service due to capacity issues, according to Bloomberg.\\n* DeepSeek's reopening intensifies the AI competition with OpenAI and other major players.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 11,\n",
    "    \"summary\": \"Amazon's $25 Billion Robotics Push Targets Cost Savings, AI Growth And Temu Competition: Report\\n* Amazon has committed up to $25 billion to its retail network, including robotics, aiming for cost savings and AI growth.\\n* The investment is partly driven by competition from Temu and the increasing costs of artificial intelligence.\\n* The robotics investment has the potential to generate near-term savings for Amazon.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 12,\n",
    "    \"summary\": \"Amazons subscription-based Alexa+ looks highly capableand questionable\\n* Amazon is launching Alexa+, a more conversational and capable version of its voice assistant, powered by large language models.  It will be free for Prime members and $20/month for non-Prime subscribers.\\n* Alexa+ will initially be available on Echo Show 8, 10, 15, and 21 smart displays.  Amazon demonstrated features like personalized recipe recommendations, ticket price monitoring, and seamless integration with other Amazon services like Amazon Music and Fire TV.\\n* This upgrade aims to revitalize Amazon's voice assistant business, which has struggled to be profitable, especially in the face of competition from generative AI chatbots.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 13,\n",
    "    \"summary\": \"Anthropic's Claude 3.7 Sonnet reportedly cost a few tens of millions of dollars to train, similar to Claude 3.5 and cheaper than GPT-4, which cost over $100M\\n* Anthropic's latest AI model, Claude 3.7 Sonnet, reportedly cost \\\"a few tens of millions of dollars\\\" to train, using less than 10^26 FLOPs of computing power.\\n* This cost is comparable to Claude 3.5 and significantly lower than the reported training costs of OpenAI's GPT-4 (over $100 million) and Google's Gemini Ultra (close to $200 million).\\n* While current costs are relatively low, Anthropic CEO Dario Amodei predicts future AI model training will cost billions of dollars.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 14,\n",
    "    \"summary\": \"Apple AI tool transcribed the word 'racist' as 'Trump'\\n* Apple's speech-to-text tool incorrectly transcribed \\\"racist\\\" as \\\"Trump,\\\" a problem the company claims is due to difficulty distinguishing words with \\\"r.\\\"  A fix is being rolled out.\\n* Experts dispute Apple's explanation, citing the distinct phonetic differences and vast training data used for such models.  One expert suggested potential software manipulation, while a former Apple employee called it a \\\"serious prank.\\\"\\n* This follows another incident where Apple's AI-generated news summaries displayed false information, leading to suspension of the feature.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 15,\n",
    "    \"summary\": \"Artificial Intelligence (AI) and the Metaverse Intellectual Property (IP), Standards and Policies Training Course (ONLINE EVENT: March 11, 2025 & ON-DEMAND)\\n* A training course titled \\\"Artificial Intelligence (AI) and the Metaverse: Intellectual Property (IP) and standards and policies\\\" has been launched by ResearchAndMarkets.com, covering legal and commercial aspects of AI and Metaverse technologies.\\n* The course addresses intellectual property issues arising from AI and Metaverse use, AI standards' role in policy development, and the latest UK and EU legislation.  It includes a practical workshop on negotiating IP clauses.\\n*  The speakers include Mark Weston, a partner at Hill Dickinson LLP specializing in commercial, IP, and IT law, and Henry Rivero, founder of Riveroconsult with expertise in TV and digital media.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 16,\n",
    "    \"summary\": \"Balancing Power With Caution: AIs Impact On Breast Cancer\\n* AI is showing promise in breast cancer care, particularly in mammography, potentially increasing detection rates by 20% without increasing false positives.  However, access to AI-enhanced mammography is currently uneven, and research is ongoing to determine if AI can match the effectiveness of dual radiologist readings.\\n* While AI can accelerate analysis and personalize treatment, challenges remain, including biased datasets and cost barriers for patients.  Advocacy for insurance coverage and diverse participation in clinical trials are needed to ensure equitable access.\\n*  The human element in healthcare must be preserved alongside AI advancements. Technology should complement, not replace, compassionate patient care.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 17,\n",
    "    \"summary\": \"Big bang Nvidia Q4 earnings today; here's what you need to watch out for\\n* Nvidia's Q4 FY2025 earnings are projected at $38.32 billion in revenue and $21.08 billion in net income, representing significant year-over-year growth driven by increasing demand for AI infrastructure.\\n*  Analysts are optimistic about Nvidia's performance, with a majority giving \\\"buy\\\" ratings and an average price target of $175.  The company's success is attributed to the rising demand for its data center chips, particularly in the AI sector.\\n*  Investors are also keenly awaiting Nvidia's FY2026 guidance, with projected revenue of approximately $42 billion.  The performance and guidance will be key indicators of the overall AI market's trajectory.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 18,\n",
    "    \"summary\": \"Billionaire Ray Dalio Says AI Risks 'Totalitarian Control Or Anarchy' As It Could Reshape World In Next 5 Years: Here Are AI-Linked ETFs For Investors To Consider\\n* Billionaire Ray Dalio warns that the development of artificial intelligence (AI) could lead to totalitarian control or anarchy in the next five years.\\n* Dalio shared his concerns during a recent podcast interview with Tucker Carlson.\\n* He emphasized the unpredictable nature of AI's development and its potential societal impact. \\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 19,\n",
    "    \"summary\": \"Bluesky Dubs AI Video of Trump Sucking Elon Musk's Toes 'Non-Consensual Explicit Material'\\n* Bluesky removed an AI-generated video depicting Trump engaging in explicit acts with Elon Musk, citing it as \\\"non-consensual explicit material.\\\"\\n* The video, shared by journalist Marisa Kabas, was originally displayed on hacked TV screens within the Department of Housing and Urban Development (HUD) as a protest.\\n* After Kabas appealed the removal, citing the video's political context, Bluesky reinstated it, acknowledging their moderators initially missed the newsworthy context.\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 20,\n",
    "    \"summary\": \"Cash torrent pouring into Nvidia slows  despite booming Blackwell adoptionMay we all have problems like annual revenue growth dropping from 126 to 114 percentSystems11 hrs|6\\n* Nvidia's fiscal year 2025 revenue reached $130 billion (114% growth), slightly lower than the previous year's 126% growth, with Q4 2025 revenue at $39.3 billion, including $11 billion from Blackwell GPUs.  Profits for FY 2025 were $72.9 billion (145% growth).\\n*  The company forecasts Q1 2026 revenue around $43 billion, driven by anticipated demand for AI infrastructure, particularly large GPU clusters, and the shift towards widespread inferencing deployments.\\n*  While facing geopolitical pressures like export controls and potential tariffs, Nvidia remains optimistic about growth, citing strong demand for Blackwell accelerators, NVLink interconnects, and networking products, and partnerships like the one with Cisco for Spectrum-X.\\n\"\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "class TopicSpec(BaseModel):\n",
    "    \"\"\"TopicSpec class for structured output of story topics\"\"\"\n",
    "    id: int = Field(description=\"The id of the story\")\n",
    "    extracted_topics: List[str] = Field(\n",
    "        description=\"List of topics covered in the story\")\n",
    "\n",
    "\n",
    "class TopicSpecList(BaseModel):\n",
    "    \"\"\"List of TopicSpec class for structured output\"\"\"\n",
    "    items: List[TopicSpec] = Field(description=\"List of TopicSpec\")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', request_timeout=60, verbose=True)\n",
    "langchain.verbose = True\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", input_prompt),\n",
    "        (\"user\", \"{input_text}\")\n",
    "    ])\n",
    "input_dict = {\"input_text\": input_text}\n",
    "\n",
    "chain = prompt_template | model.with_structured_output(TopicSpecList)\n",
    "response = chain.invoke(input_dict)\n",
    "resp = (response.content[8:-3])\n",
    "    \n",
    "resp_dict = json.loads(resp.replace(\"'\", '\"'))\n",
    "\n",
    "# Validate with TopicSpecList\n",
    "try:\n",
    "    validated_response = TopicSpecList(**resp_dict)\n",
    "    print(validated_response)\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation Error: {e.json()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eccfbedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'items': [{'id': 0, 'extracted_topics': ['TechCrunch Sessions: AI', 'AI event', 'AI advancements', 'UC Berkeley', 'AI leaders', 'VCs']}, {'id': 1, 'extracted_topics': ['Enterprise AI usage', 'Data security risks', 'Shadow AI', 'TELUS Digital Experience survey', 'ChatGPT', 'AI training']}, {'id': 2, 'extracted_topics': ['Causal ML', 'Machine learning', 'Decision-making', 'What-if scenarios', 'R&D budget optimization', 'Business applications of ML']}, {'id': 3, 'extracted_topics': ['Supermicro', 'Financial reporting', 'EY', 'BDO', 'Auditing', 'Corporate governance']}, {'id': 4, 'extracted_topics': ['AI CAPTCHA failures', 'CAPTCHA challenges', 'Image recognition', 'Text transcription', 'AI limitations', 'CAPTCHA-solving tools']}, {'id': 5, 'extracted_topics': ['Google AI Overview', 'LLM inaccuracies', 'Search engine results', 'Humorous AI responses', 'Algorithm flaws', 'Information retrieval']}, {'id': 6, 'extracted_topics': ['Bridgetown Research', 'AI startup funding', 'AI agents', 'Lightspeed Venture Partners', 'Accel', 'Strategic decision-making']}, {'id': 7, 'extracted_topics': ['AI-powered ransomware', 'Cybersecurity', 'Phishing attacks', 'Vulnerability analysis', 'Malware deployment', 'Intrusion detection systems']}, {'id': 8, 'extracted_topics': ['Akool', 'AI 3D avatars', 'LLM integration', 'Conversational AI', 'Customer service', 'Language education']}, {'id': 9, 'extracted_topics': ['DeepSeek', 'Alibaba', 'AI competition', 'OpenAI', 'Programming interface', 'AI market dominance']}, {'id': 11, 'extracted_topics': ['Amazon', 'Robotics investment', 'Cost savings', 'AI growth', 'Temu competition', 'Retail network']}, {'id': 12, 'extracted_topics': ['Amazon Alexa+', 'Voice assistant', 'LLMs', 'Subscription service', 'Echo Show', 'Amazon services integration']}, {'id': 13, 'extracted_topics': ['Anthropic', 'Claude 3.7 Sonnet', 'AI model training costs', 'GPT-4', 'Gemini Ultra', 'FLOPs']}, {'id': 14, 'extracted_topics': ['Apple AI', 'Speech-to-text', 'Transcription errors', 'Racist/Trump misinterpretation', 'Software manipulation', 'AI-generated news summaries']}, {'id': 15, 'extracted_topics': ['AI and Metaverse training course', 'Intellectual property', 'AI standards', 'UK and EU legislation', 'ResearchAndMarkets.com', 'Online event']}, {'id': 16, 'extracted_topics': ['AI in breast cancer care', 'Mammography', 'Detection rates', 'Biased datasets', 'Equitable access', 'Patient care']}, {'id': 17, 'extracted_topics': ['Nvidia Q4 earnings', 'AI infrastructure demand', 'Data center chips', 'FY2026 guidance', 'AI market trajectory', 'Financial analysis']}, {'id': 18, 'extracted_topics': ['Ray Dalio', 'AI risks', 'Totalitarian control', 'Anarchy', 'Societal impact', 'Tucker Carlson interview']}, {'id': 19, 'extracted_topics': ['Bluesky', 'AI-generated video', 'Trump', 'Elon Musk', 'Non-consensual explicit material', 'Content moderation']}, {'id': 20, 'extracted_topics': ['Nvidia revenue', 'Blackwell GPUs', 'AI infrastructure demand', 'Geopolitical pressures', 'Spectrum-X', 'Financial performance']}]}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0100cfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"id\": 0,\n",
      "      \"extracted_topics\": [\n",
      "        \"TechCrunch Sessions: AI\",\n",
      "        \"AI event\",\n",
      "        \"UC Berkeley\",\n",
      "        \"AI advancements\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"extracted_topics\": [\n",
      "        \"Enterprise AI security risks\",\n",
      "        \"Confidential data exposure\",\n",
      "        \"Shadow AI\",\n",
      "        \"TELUS Digital Experience survey\",\n",
      "        \"ChatGPT\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"extracted_topics\": [\n",
      "        \"Causal ML\",\n",
      "        \"Machine learning\",\n",
      "        \"Decision-making\",\n",
      "        \"What-if scenarios\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"extracted_topics\": [\n",
      "        \"Supermicro\",\n",
      "        \"EY\",\n",
      "        \"Financial reporting\",\n",
      "        \"Auditing\",\n",
      "        \"BDO\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"extracted_topics\": [\n",
      "        \"AI CAPTCHA failures\",\n",
      "        \"Image recognition\",\n",
      "        \"AI limitations\",\n",
      "        \"CAPTCHA-solving tools\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"extracted_topics\": [\n",
      "        \"Google AI Overview\",\n",
      "        \"LLM inaccuracies\",\n",
      "        \"Search engine results\",\n",
      "        \"AI humor\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"extracted_topics\": [\n",
      "        \"Bridgetown Research\",\n",
      "        \"AI agents\",\n",
      "        \"Series A funding\",\n",
      "        \"Lightspeed Venture Partners\",\n",
      "        \"Accel\",\n",
      "        \"Strategic decision-making\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"extracted_topics\": [\n",
      "        \"AI-powered ransomware\",\n",
      "        \"Cybersecurity\",\n",
      "        \"Phishing attacks\",\n",
      "        \"Vulnerability analysis\",\n",
      "        \"Malware deployment\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"extracted_topics\": [\n",
      "        \"Akool Inc.\",\n",
      "        \"AI human 3D avatars\",\n",
      "        \"LLMs\",\n",
      "        \"Conversational AI\",\n",
      "        \"Customer service\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 9,\n",
      "      \"extracted_topics\": [\n",
      "        \"DeepSeek\",\n",
      "        \"Alibaba\",\n",
      "        \"AI competition\",\n",
      "        \"OpenAI\",\n",
      "        \"AI programming interface\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 11,\n",
      "      \"extracted_topics\": [\n",
      "        \"Amazon\",\n",
      "        \"Robotics\",\n",
      "        \"AI growth\",\n",
      "        \"Temu\",\n",
      "        \"Retail network\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 12,\n",
      "      \"extracted_topics\": [\n",
      "        \"Amazon Alexa+\",\n",
      "        \"Voice assistant\",\n",
      "        \"LLMs\",\n",
      "        \"Subscription service\",\n",
      "        \"Echo Show\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 13,\n",
      "      \"extracted_topics\": [\n",
      "        \"Anthropic\",\n",
      "        \"Claude 3.7 Sonnet\",\n",
      "        \"AI model training costs\",\n",
      "        \"GPT-4\",\n",
      "        \"Gemini Ultra\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 14,\n",
      "      \"extracted_topics\": [\n",
      "        \"Apple AI tool\",\n",
      "        \"Speech-to-text\",\n",
      "        \"Transcription error\",\n",
      "        \"Software bug\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 15,\n",
      "      \"extracted_topics\": [\n",
      "        \"AI and Metaverse training course\",\n",
      "        \"Intellectual property\",\n",
      "        \"AI standards\",\n",
      "        \"Legal aspects\",\n",
      "        \"ResearchAndMarkets.com\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 16,\n",
      "      \"extracted_topics\": [\n",
      "        \"AI in breast cancer care\",\n",
      "        \"Mammography\",\n",
      "        \"Healthcare AI\",\n",
      "        \"AI bias\",\n",
      "        \"Equitable access\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 17,\n",
      "      \"extracted_topics\": [\n",
      "        \"Nvidia Q4 earnings\",\n",
      "        \"AI infrastructure demand\",\n",
      "        \"Data center chips\",\n",
      "        \"Financial performance\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 18,\n",
      "      \"extracted_topics\": [\n",
      "        \"Ray Dalio\",\n",
      "        \"AI risks\",\n",
      "        \"Totalitarian control\",\n",
      "        \"Anarchy\",\n",
      "        \"Societal impact\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 19,\n",
      "      \"extracted_topics\": [\n",
      "        \"Bluesky\",\n",
      "        \"AI-generated video\",\n",
      "        \"Trump\",\n",
      "        \"Elon Musk\",\n",
      "        \"Content moderation\",\n",
      "        \"Political context\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 20,\n",
      "      \"extracted_topics\": [\n",
      "        \"Nvidia\",\n",
      "        \"Blackwell GPUs\",\n",
      "        \"Revenue growth\",\n",
      "        \"AI infrastructure\",\n",
      "        \"Geopolitical pressures\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = (response.content[8:-3])\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0aea5916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items=[TopicSpec(id=0, extracted_topics=['TechCrunch Sessions: AI', 'AI event', 'UC Berkeley', 'AI advancements']), TopicSpec(id=1, extracted_topics=['Enterprise AI security risks', 'Confidential data exposure', 'Shadow AI', 'TELUS Digital Experience survey', 'ChatGPT']), TopicSpec(id=2, extracted_topics=['Causal ML', 'Machine learning', 'Decision-making', 'What-if scenarios']), TopicSpec(id=3, extracted_topics=['Supermicro', 'EY', 'Financial reporting', 'Auditing', 'BDO']), TopicSpec(id=4, extracted_topics=['AI CAPTCHA failures', 'Image recognition', 'AI limitations', 'CAPTCHA-solving tools']), TopicSpec(id=5, extracted_topics=['Google AI Overview', 'LLM inaccuracies', 'Search engine results', 'AI humor']), TopicSpec(id=6, extracted_topics=['Bridgetown Research', 'AI agents', 'Series A funding', 'Lightspeed Venture Partners', 'Accel', 'Strategic decision-making']), TopicSpec(id=7, extracted_topics=['AI-powered ransomware', 'Cybersecurity', 'Phishing attacks', 'Vulnerability analysis', 'Malware deployment']), TopicSpec(id=8, extracted_topics=['Akool Inc.', 'AI human 3D avatars', 'LLMs', 'Conversational AI', 'Customer service']), TopicSpec(id=9, extracted_topics=['DeepSeek', 'Alibaba', 'AI competition', 'OpenAI', 'AI programming interface']), TopicSpec(id=11, extracted_topics=['Amazon', 'Robotics', 'AI growth', 'Temu', 'Retail network']), TopicSpec(id=12, extracted_topics=['Amazon Alexa+', 'Voice assistant', 'LLMs', 'Subscription service', 'Echo Show']), TopicSpec(id=13, extracted_topics=['Anthropic', 'Claude 3.7 Sonnet', 'AI model training costs', 'GPT-4', 'Gemini Ultra']), TopicSpec(id=14, extracted_topics=['Apple AI tool', 'Speech-to-text', 'Transcription error', 'Software bug']), TopicSpec(id=15, extracted_topics=['AI and Metaverse training course', 'Intellectual property', 'AI standards', 'Legal aspects', 'ResearchAndMarkets.com']), TopicSpec(id=16, extracted_topics=['AI in breast cancer care', 'Mammography', 'Healthcare AI', 'AI bias', 'Equitable access']), TopicSpec(id=17, extracted_topics=['Nvidia Q4 earnings', 'AI infrastructure demand', 'Data center chips', 'Financial performance']), TopicSpec(id=18, extracted_topics=['Ray Dalio', 'AI risks', 'Totalitarian control', 'Anarchy', 'Societal impact']), TopicSpec(id=19, extracted_topics=['Bluesky', 'AI-generated video', 'Trump', 'Elon Musk', 'Content moderation', 'Political context']), TopicSpec(id=20, extracted_topics=['Nvidia', 'Blackwell GPUs', 'Revenue growth', 'AI infrastructure', 'Geopolitical pressures'])]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import ValidationError\n",
    "\n",
    "# Convert the string to a dictionary\n",
    "resp = (response.content[8:-3])\n",
    "    \n",
    "resp_dict = json.loads(resp.replace(\"'\", '\"'))\n",
    "\n",
    "# Validate with TopicSpecList\n",
    "try:\n",
    "    validated_response = TopicSpecList(**resp_dict)\n",
    "    print(validated_response)\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation Error: {e.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df4d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ainewsbot",
   "language": "python",
   "name": "ainewsbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
